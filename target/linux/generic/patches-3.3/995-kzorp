Index: linux-3.3.8/include/linux/netfilter/Kbuild
===================================================================
--- linux-3.3.8.orig/include/linux/netfilter/Kbuild	2013-11-18 17:12:29.239269379 +0100
+++ linux-3.3.8/include/linux/netfilter/Kbuild	2013-11-18 17:12:30.151285665 +0100
@@ -21,6 +21,7 @@
 header-y += xt_CT.h
 header-y += xt_DSCP.h
 header-y += xt_IDLETIMER.h
+header-y += xt_KZORP.h
 header-y += xt_LED.h
 header-y += xt_MARK.h
 header-y += xt_nfacct.h
Index: linux-3.3.8/include/linux/netfilter/nfnetlink.h
===================================================================
--- linux-3.3.8.orig/include/linux/netfilter/nfnetlink.h	2012-06-01 09:16:13.000000000 +0200
+++ linux-3.3.8/include/linux/netfilter/nfnetlink.h	2013-11-18 17:12:30.151285665 +0100
@@ -48,7 +48,7 @@
 #define NFNL_SUBSYS_ULOG		4
 #define NFNL_SUBSYS_OSF			5
 #define NFNL_SUBSYS_IPSET		6
-#define NFNL_SUBSYS_ACCT		7
+#define NFNL_SUBSYS_KZORP		7
 #define NFNL_SUBSYS_COUNT		8
 
 #ifdef __KERNEL__
Index: linux-3.3.8/include/linux/netfilter_ipv4.h
===================================================================
--- linux-3.3.8.orig/include/linux/netfilter_ipv4.h	2012-06-01 09:16:13.000000000 +0200
+++ linux-3.3.8/include/linux/netfilter_ipv4.h	2013-11-18 17:12:30.151285665 +0100
@@ -61,9 +61,12 @@
 	NF_IP_PRI_SELINUX_FIRST = -225,
 	NF_IP_PRI_CONNTRACK = -200,
 	NF_IP_PRI_MANGLE = -150,
+	NF_IP_PRI_KZORP_PRE = -140,
 	NF_IP_PRI_NAT_DST = -100,
 	NF_IP_PRI_FILTER = 0,
+	NF_IP_PRI_KZORP_FORWARD = 10,
 	NF_IP_PRI_SECURITY = 50,
+	NF_IP_PRI_KZORP_POST = 90,
 	NF_IP_PRI_NAT_SRC = 100,
 	NF_IP_PRI_SELINUX_LAST = 225,
 	NF_IP_PRI_CONNTRACK_CONFIRM = INT_MAX,
Index: linux-3.3.8/net/netfilter/Kconfig
===================================================================
--- linux-3.3.8.orig/net/netfilter/Kconfig	2013-11-18 17:12:29.275270021 +0100
+++ linux-3.3.8/net/netfilter/Kconfig	2013-11-25 08:36:14.245468652 +0100
@@ -337,6 +337,18 @@
 	  This is required if you intend to use any of ip_tables,
 	  ip6_tables or arp_tables.
 
+config NETFILTER_KZORP
+	depends on NETFILTER_ADVANCED
+	depends on NETFILTER_XTABLES
+	depends on NF_CONNTRACK_IPV4
+	depends on NF_CONNTRACK_IPV6
+	depends on NF_NAT
+	depends on NETFILTER_TPROXY
+    select XFRM
+	 tristate "Netfilter KZorp support"
+	 help
+	  Netfilter KZorp core
+
 if NETFILTER_XTABLES
 
 comment "Xtables combined modules"
@@ -499,6 +511,14 @@
 
 	  To compile it as a module, choose M here.  If unsure, say N.
 
+config NETFILTER_XT_TARGET_KZORP
+	tristate '"KZORP" target support'
+	depends on NETFILTER_KZORP
+	default m if NETFILTER_KZORP=m
+	help
+	  KZORP target makes the necessary decision by your policy
+	  settings performs redirection, DAC decisions, and forwards services.
+
 config NETFILTER_XT_TARGET_LED
 	tristate '"LED" target support'
 	depends on LEDS_CLASS && LEDS_TRIGGERS
@@ -1023,6 +1043,15 @@
 	  If you want to compile it as a module, say M here and read
 	  <file:Documentation/kbuild/modules.txt>.  If unsure, say `N'.
 
+config NETFILTER_XT_MATCH_SERVICE
+	tristate "service match support"
+	depends on NETFILTER_KZORP
+	help
+	  This option adds a new iptables `service' match. The `service'
+	  match can be used to match packets based on KZorp services
+
+	  If unsure, say N.
+
 config NETFILTER_XT_MATCH_RECENT
 	tristate '"recent" match support'
 	depends on NETFILTER_ADVANCED
@@ -1139,6 +1168,15 @@
 
 	  Details and examples are in the kernel module source.
 
+config NETFILTER_XT_MATCH_ZONE
+	tristate "zone match support"
+	depends on NETFILTER_KZORP
+	help
+	  This option adds a new iptables `zone' match. The `zone' match
+	  can be used to match packets based on the KZorp zone structure.
+ 
+	  If unsure, say N.
+
 endif # NETFILTER_XTABLES
 
 endmenu
Index: linux-3.3.8/net/netfilter/Makefile
===================================================================
--- linux-3.3.8.orig/net/netfilter/Makefile	2013-11-18 17:12:29.235269307 +0100
+++ linux-3.3.8/net/netfilter/Makefile	2013-11-18 17:12:30.151285665 +0100
@@ -14,6 +14,10 @@
 # connection tracking
 obj-$(CONFIG_NF_CONNTRACK) += nf_conntrack.o
 
+# KZorp
+kzorp-objs := kzorp_core.o kzorp_lookup.o kzorp_sockopt.o kzorp_netlink.o
+obj-$(CONFIG_NETFILTER_KZORP) += kzorp.o
+
 # SCTP protocol connection tracking
 obj-$(CONFIG_NF_CT_PROTO_DCCP) += nf_conntrack_proto_dccp.o
 obj-$(CONFIG_NF_CT_PROTO_GRE) += nf_conntrack_proto_gre.o
@@ -57,6 +61,7 @@
 obj-$(CONFIG_NETFILTER_XT_TARGET_CT) += xt_CT.o
 obj-$(CONFIG_NETFILTER_XT_TARGET_DSCP) += xt_DSCP.o
 obj-$(CONFIG_NETFILTER_XT_TARGET_HL) += xt_HL.o
+obj-$(CONFIG_NETFILTER_XT_TARGET_KZORP) += xt_KZORP.o
 obj-$(CONFIG_NETFILTER_XT_TARGET_LED) += xt_LED.o
 obj-$(CONFIG_NETFILTER_XT_TARGET_NFLOG) += xt_NFLOG.o
 obj-$(CONFIG_NETFILTER_XT_TARGET_NFQUEUE) += xt_NFQUEUE.o
@@ -103,6 +108,7 @@
 obj-$(CONFIG_NETFILTER_XT_MATCH_REALM) += xt_realm.o
 obj-$(CONFIG_NETFILTER_XT_MATCH_RECENT) += xt_recent.o
 obj-$(CONFIG_NETFILTER_XT_MATCH_SCTP) += xt_sctp.o
+obj-$(CONFIG_NETFILTER_XT_MATCH_SERVICE) += xt_service.o
 obj-$(CONFIG_NETFILTER_XT_MATCH_SOCKET) += xt_socket.o
 obj-$(CONFIG_NETFILTER_XT_MATCH_STATE) += xt_state.o
 obj-$(CONFIG_NETFILTER_XT_MATCH_LAYER7) += xt_layer7.o
@@ -111,6 +117,7 @@
 obj-$(CONFIG_NETFILTER_XT_MATCH_TCPMSS) += xt_tcpmss.o
 obj-$(CONFIG_NETFILTER_XT_MATCH_TIME) += xt_time.o
 obj-$(CONFIG_NETFILTER_XT_MATCH_U32) += xt_u32.o
+obj-$(CONFIG_NETFILTER_XT_MATCH_ZONE) += xt_zone.o
 
 # ipset
 obj-$(CONFIG_IP_SET) += ipset/
Index: linux-3.3.8/include/linux/netfilter/kzorp.h
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ linux-3.3.8/include/linux/netfilter/kzorp.h	2013-11-18 17:12:30.151285665 +0100
@@ -0,0 +1,685 @@
+/*
+ * KZorp data structures
+ *
+ * Copyright (C) 2006-2010, BalaBit IT Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#ifndef _KZORP_H
+#define _KZORP_H
+
+#include <asm/atomic.h>
+#include <linux/list.h>
+#include <linux/mutex.h>
+#include <linux/netdevice.h>
+#include <linux/rcupdate.h>
+#include <linux/netfilter_ipv4.h>
+#include <net/netfilter/nf_nat.h>
+#include <net/netfilter/nf_conntrack_extend.h>
+#include <linux/netfilter/kzorp_netlink.h>
+#include <net/xfrm.h>
+#include <linux/if.h>
+#include <linux/netdevice.h>
+
+#include <net/netfilter/kzorp_internal.h>
+
+#define KZ_MAJOR_VERSION  4
+#define KZ_COMPAT_VERSION 1
+
+enum KZ_ALLOC_TYPE
+{
+	KZALLOC,
+	VMALLOC
+};
+
+void *kz_big_alloc(size_t size, enum KZ_ALLOC_TYPE *alloc_type);
+void kz_big_free(void *ptr, enum KZ_ALLOC_TYPE alloc_type);
+
+/***********************************************************
+ * Core data structures
+ ***********************************************************/
+
+typedef unsigned int kz_generation_t; /* integral with suitable size */
+typedef __be32 netlink_port_t;
+
+struct nf_conntrack_kzorp {
+	unsigned long sid;
+	/*  "lookup data" from here to end */
+	kz_generation_t generation; /* config version */
+	struct kz_zone *czone;		/* client zone */
+	struct kz_zone *szone;		/* server zone */
+	struct kz_dispatcher *dpt;	/* dispatcher */
+	struct kz_service *svc;		/* service */
+};
+
+enum kzf_instance_flags {
+	KZF_INSTANCE_DELETED = 1 << 0,
+	KZF_INSTANCE_TRANS   = 1 << 1,
+};
+
+struct kz_bind {
+	struct list_head list;
+	union nf_inet_addr addr;
+	netlink_port_t peer_pid;
+	sa_family_t family;
+	__u16 port;
+	__u8 proto;
+};
+
+enum kz_bind_l3proto {
+	KZ_BIND_L3PROTO_IPV4,
+	KZ_BIND_L3PROTO_IPV6,
+	KZ_BIND_L3PROTO_COUNT
+};
+
+enum kz_bind_l4proto {
+	KZ_BIND_L4PROTO_TCP,
+	KZ_BIND_L4PROTO_UDP,
+	KZ_BIND_L4PROTO_COUNT
+};
+
+struct kz_bind_lookup {
+	struct rcu_head rcu;
+	struct list_head list_bind;
+
+	/* cache of binds by l3 and l4 proto */
+
+	/*
+	 * The binds and binds_by_type look something like this:
+	 *
+	 *	 +-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+
+	 *	 |  Bind 1     |  Bind 2     |	...	   |  Bind X	 |  Bind X + 1 | ...	     |	Bind Y	   | ...	 |
+	 *	 |  (IPv4/TCP) |  (IPv4/TCP) |		   |  (IPv4/UDP) |  (IPv6/TCP) |	     |	(IPv6/UDP) |		 |
+	 *	 +-------------+-------------+-------------+------/------+-----/-------+-------------+------/------+-------------+
+	 *	       |                                  /-------     /-------		        /-----------
+	 *	       |                          /-------      /------		    /-----------
+	 *	       |                  /-------	/-------        /-----------
+	 *       +-----+-------+-------------+-------------+-------------+
+	 *       | IPv4/TCP    | IPv4/UDP    | IPv6/TCP    | IPv6/UDP    |
+	 *       +-------------+-------------+-------------+-------------+
+	 */
+
+	/* array of pointers to all bind structures, ordered by l3proto and l4proto */
+	const struct kz_bind const **binds;
+	/* array of pointers to the appropriate element of the binds array */
+	const struct kz_bind const **binds_by_type[KZ_BIND_L3PROTO_COUNT][KZ_BIND_L4PROTO_COUNT];
+	unsigned int bind_nums[KZ_BIND_L3PROTO_COUNT][KZ_BIND_L4PROTO_COUNT];
+};
+
+struct kz_instance {
+	struct list_head list;
+	struct kz_bind_lookup *bind_lookup;
+	unsigned int id;
+	unsigned int flags;
+	netlink_port_t peer_pid;
+	char name[0];
+};
+
+enum kzf_transaction_flags {
+	KZF_TRANSACTION_FLUSH_ZONES		= 1 << 0,
+	KZF_TRANSACTION_FLUSH_SERVICES		= 1 << 1,
+	KZF_TRANSACTION_FLUSH_DISPATCHERS	= 1 << 2,
+	KZF_TRANSACTION_FLUSH_BIND		= 1 << 3,
+};
+
+struct kz_transaction {
+	unsigned int instance_id;
+	netlink_port_t peer_pid;
+	unsigned int flags;
+	u_int64_t cookie;
+	const struct kz_config * cfg;
+	struct list_head op;
+};
+
+enum kznl_op_data_type {
+	KZNL_OP_ZONE,
+	KZNL_OP_SERVICE,
+	KZNL_OP_DISPATCHER,
+	KZNL_OP_BIND,
+};
+
+struct kz_operation {
+	struct list_head list;
+	enum kznl_op_data_type type;
+	void *data;
+	void (*data_destroy)(void *);
+};
+
+struct kz_port_range {
+	u_int16_t from;
+	u_int16_t to;
+};
+
+struct kz_in_subnet {
+	struct in_addr addr;
+	struct in_addr mask;
+};
+
+struct kz_in6_subnet {
+	struct in6_addr addr;
+	struct in6_addr mask;
+};
+
+struct kz_dispatcher_n_dimension_rule_entry_params {
+	u_int32_t rule_id;
+
+#define DECLARE_RULE_ENTRY_PARAM(DIM_NAME, _, TYPE, ...) \
+	bool has_##DIM_NAME; \
+	TYPE DIM_NAME
+
+	KZORP_DIM_LIST(DECLARE_RULE_ENTRY_PARAM, ;);
+
+#undef DECLARE_RULE_ENTRY_PARAM
+};
+
+struct kz_dispatcher_n_dimension_rule {
+	u_int32_t id;
+
+	struct kz_service *service;
+	struct kz_dispatcher *dispatcher;
+
+#define DECLARE_RULE_ENTRY(DIM_NAME, _, TYPE, ...) \
+	u_int32_t alloc_##DIM_NAME; \
+	u_int32_t num_##DIM_NAME; \
+	TYPE *DIM_NAME
+
+	KZORP_DIM_LIST(DECLARE_RULE_ENTRY, ;);
+
+#undef DECLARE_RULE_ENTRY
+};
+
+struct kz_reqids {
+  u32 vec[XFRM_MAX_DEPTH];
+  int len;
+};
+
+typedef struct {
+	struct work_struct my_work;
+	void *p;
+} kz_vfree_work_t;
+
+struct kz_dispatcher {
+	struct list_head list;
+	atomic_t refcnt;
+	struct kz_instance *instance;
+
+	unsigned int alloc_rule;
+	unsigned int num_rule;
+	struct kz_dispatcher_n_dimension_rule *rule;
+	enum KZ_ALLOC_TYPE rule_allocator;
+
+	char *name;
+};
+
+struct kz_service_nat_entry {
+	struct list_head list;
+	struct nf_nat_ipv4_range src;
+	struct nf_nat_ipv4_range dst;
+	struct nf_nat_ipv4_range map;
+};
+
+struct kz_service_info_fwd {
+	struct list_head snat;
+	struct list_head dnat;
+
+	sa_family_t router_dst_addr_family;
+	union nf_inet_addr router_dst_addr;
+	__be16 router_dst_port;
+};
+
+struct kz_service_info_deny {
+	enum kz_service_ipv4_deny_method ipv4_reject_method;
+	enum kz_service_ipv6_deny_method ipv6_reject_method;
+};
+
+#define KZ_SERVICE_CNT_LOCKED_BIT 16
+
+enum kzf_service_internal_flags {
+	KZF_SERVICE_CNT_LOCKED = 1 << KZ_SERVICE_CNT_LOCKED_BIT,
+};
+
+struct kz_service {
+	struct list_head list;
+	atomic_t refcnt;
+	unsigned int id;
+	unsigned int instance_id;
+	unsigned int flags;
+	atomic_t session_cnt;
+	enum kz_service_type type;
+	union {
+		struct kz_service_info_fwd fwd;
+		struct kz_service_info_deny deny;
+	} a;
+	char *name;
+};
+
+enum kzf_zone_internal_flags {
+	KZF_ZONE_HAS_RANGE = 1 << 16,
+};
+
+struct kz_zone {
+	struct list_head list;
+	struct hlist_node hlist;
+	atomic_t refcnt;
+	unsigned int flags;
+	/* static lookup helper data */
+	int depth;
+	unsigned int index;
+	/* range */
+	sa_family_t family;
+	union nf_inet_addr addr;
+	union nf_inet_addr mask;
+
+	/* NOTE: name and unique_name can be the same, in this case
+	 * KZorp tries to save some memory and just set unique_name to
+	 * the same pointer as name. Because of this, we have to be
+	 * extra careful when cloning and freeing zone structures. On
+	 * the other hand, we can rely on the names not being the same
+	 * if the pointers differ -- this saves us a few strcmp()
+	 * calls here and there. */
+	char *name;
+	char *unique_name;
+
+	struct kz_zone *admin_parent;
+};
+
+/***********************************************************
+ * Lookup data structures
+ ***********************************************************/
+
+#define DISPATCHER_INET_HASH_SIZE 256
+
+#define KZ_ZONE_HASH_SIZE 32
+#define KZ_ZONE_MAX 16384
+#define KZ_ZONE_BF_SIZE (KZ_ZONE_MAX / 8)
+
+struct kz_lookup_ipv6_node;
+
+struct kz_zone_lookup {
+	struct hlist_head hash[33][KZ_ZONE_HASH_SIZE];
+	struct kz_lookup_ipv6_node *root;
+};
+
+/* config holder for zones */
+struct kz_head_z {
+	struct list_head head;
+	/* lookup data structures */
+	struct kz_zone_lookup luzone;
+};
+
+/* config holder for dispatchers */
+struct kz_head_d {
+	struct list_head head;
+	/* lookup data structures */
+	struct kz_rule_lookup_data *lookup_data;
+	enum KZ_ALLOC_TYPE lookup_data_allocator;
+};
+
+/* config holder for services */
+struct kz_head_s {
+	struct list_head head;
+	/* no lookup data for now */
+};
+
+/* config holder for instances */
+struct kz_head_i {
+	struct list_head head;
+	/* no lookup data for now */
+};
+
+/* full config of kzorp
+   we have one global instance with rcu protection
+   functions may access it vis usual cru API
+
+   CONVENTION: if passed in as function parameter,
+   the caller ensures the content is stable!
+*/
+struct kz_config {
+	struct rcu_head rcu;
+	struct kz_head_z zones;
+	struct kz_head_s services;
+	struct kz_head_d dispatchers;
+	struct kz_head_i instances;
+	u_int64_t cookie;
+	kz_generation_t generation;
+};
+
+/***********************************************************
+ * Shared data
+ ***********************************************************/
+
+#define INSTANCE_MAX_NUM 256
+
+extern struct mutex kz_instance_mutex;
+extern struct list_head kz_instances;
+
+/* NOTE: shared for nfnetlink transactions in nfnetlink module */
+#define LOCK_INSTANCES(...) do {mutex_lock(&kz_instance_mutex);} while (0)
+#define UNLOCK_INSTANCES(...) do {mutex_unlock(&kz_instance_mutex);} while (0)
+/* we share mutex of instances in core -- no point to use multiples */
+#define LOCK_TRANSACTIONS LOCK_INSTANCES
+#define UNLOCK_TRANSACTIONS UNLOCK_INSTANCES
+
+#define KZ_KFREE(p) do {if (p) {kfree(p); p = NULL;} } while (0)
+
+/* rcu-protected pointer; can never be NULL
+   the generation in the structure is unique in module lifetime
+*/
+extern struct kz_config *kz_config_rcu;
+
+/* installs the new version, schedules rcu-free on the old one
+   generation is handled internally
+*/
+void kz_config_swap(struct kz_config * new_cfg);
+
+struct kz_config *kz_config_new(void);
+void kz_config_destroy(struct kz_config * cfg);
+
+static inline kz_generation_t
+kz_generation_get(const struct kz_config *cfg) {
+	return cfg ? cfg->generation : 0;
+}
+
+static inline int
+kz_generation_valid(const struct kz_config *cfg, kz_generation_t generation) {
+	return (generation == kz_generation_get(cfg));
+}
+
+/***********************************************************
+ * Core functions
+ ***********************************************************/
+
+extern char *kz_name_dup(const char * const name);
+
+extern void kz_head_destroy_zone(struct kz_head_z *h);
+extern void kz_head_destroy_service(struct kz_head_s *h);
+extern void kz_head_destroy_dispatcher(struct kz_head_d *h);
+
+struct kz_bind * kz_bind_new(void);
+struct kz_bind * kz_bind_clone(const struct kz_bind const *_bind);
+void kz_bind_destroy(struct kz_bind *bind);
+
+const struct kz_bind * const
+kz_instance_bind_lookup_v4(const struct kz_instance const *instance, u8 l4proto,
+			   __be32 saddr, __be16 sport,
+			   __be32 daddr, __be16 dport);
+
+const struct kz_bind * const
+kz_instance_bind_lookup_v6(const struct kz_instance const *instance, u8 l4proto,
+			   const struct in6_addr const *saddr, __be16 sport,
+			   const struct in6_addr const *daddr, __be16 dport);
+void kz_instance_remove_bind(struct kz_instance *instance, const netlink_port_t pid_to_remove, const struct kz_transaction const *tr);
+
+extern struct kz_instance *kz_instance_lookup_nocheck(const char *name);
+extern struct kz_instance *kz_instance_lookup(const char *name);
+extern struct kz_instance *kz_instance_lookup_id(const unsigned int id);
+extern struct kz_instance *kz_instance_create(const char *name, const unsigned int len, const netlink_port_t peer_pid);
+
+extern struct kz_zone *kz_zone_new(void);
+extern void kz_zone_destroy(struct kz_zone *zone);
+extern struct kz_zone *__kz_zone_lookup_name(const struct list_head * const head, const char *name);
+extern struct kz_zone *kz_zone_lookup_name(const struct kz_config *cfg, const char *name);
+
+extern struct kz_zone *kz_zone_clone(const struct kz_zone * const zone);
+
+static inline struct kz_zone *kz_zone_get(struct kz_zone *zone)
+{
+	atomic_inc(&zone->refcnt);
+	return zone;
+}
+
+static inline void kz_zone_put(struct kz_zone *zone)
+{
+	if (atomic_dec_and_test(&zone->refcnt))
+		kz_zone_destroy(zone);
+}
+
+extern struct kz_service *kz_service_new(void);
+extern void service_destroy(struct kz_service *service);
+extern void kz_service_destroy(struct kz_service *service);
+extern struct kz_service *__kz_service_lookup_name(const struct list_head * const head,
+						   const char *name);
+extern struct kz_service *kz_service_lookup_name(const struct kz_config *cfg, const char *name);
+extern int kz_service_add_nat_entry(struct list_head *head, struct nf_nat_ipv4_range *src,
+				    struct nf_nat_ipv4_range *dst, struct nf_nat_ipv4_range *map);
+extern struct kz_service *kz_service_clone(const struct kz_service * const o);
+extern int kz_service_lock(struct kz_service * const service);
+extern void kz_service_unlock(struct kz_service * const service);
+
+static inline struct kz_service *kz_service_get(struct kz_service *service)
+{
+	atomic_inc(&service->refcnt);
+	return service;
+}
+
+static inline void kz_service_put(struct kz_service *service)
+{
+	if (atomic_dec_and_test(&service->refcnt))
+		kz_service_destroy(service);
+}
+
+extern int kz_rule_copy(struct kz_dispatcher_n_dimension_rule *dst,
+			const struct kz_dispatcher_n_dimension_rule * const src);
+
+extern struct kz_dispatcher *kz_dispatcher_new(void);
+extern void kz_dispatcher_destroy(struct kz_dispatcher *);
+extern struct kz_dispatcher *kz_dispatcher_lookup_name(const struct kz_config *cfg, const char *name);
+extern int kz_dispatcher_add_css(struct kz_dispatcher *d, struct kz_zone *client,
+				 struct kz_zone *server, struct kz_service *service);
+extern int kz_dispatcher_add_rule(struct kz_dispatcher *d, struct kz_service *service,
+				  const struct kz_dispatcher_n_dimension_rule * const rule_params);
+extern int kz_dispatcher_add_rule_entry(struct kz_dispatcher_n_dimension_rule *rule,
+					const struct kz_dispatcher_n_dimension_rule_entry_params * const rule_entry_params);
+extern int kz_dispatcher_alloc_rule_array(struct kz_dispatcher *dispatcher, size_t alloc_rules);
+extern int kz_dispatcher_copy_rules(struct kz_dispatcher *dst, const struct kz_dispatcher * const src);
+extern struct kz_dispatcher *kz_dispatcher_clone(const struct kz_dispatcher * const o);
+extern struct kz_dispatcher *kz_dispatcher_clone_pure(const struct kz_dispatcher * const o);
+extern void kz_dispatcher_relink(struct kz_dispatcher *d, const struct list_head * zonelist, const struct list_head * servicelist);
+
+static inline struct kz_dispatcher *
+kz_dispatcher_get(struct kz_dispatcher *dispatcher)
+{
+	atomic_inc(&dispatcher->refcnt);
+	return dispatcher;
+}
+
+static inline void
+kz_dispatcher_put(struct kz_dispatcher *dispatcher)
+{
+	if (atomic_dec_and_test(&dispatcher->refcnt))
+		kz_dispatcher_destroy(dispatcher);
+}
+
+int kz_log_ratelimit(void);
+
+/***********************************************************
+ * Conntrack structure extension
+ ***********************************************************/
+
+static inline struct nf_conntrack_kzorp *nfct_kz(const struct nf_conn *ct)
+{
+	return nf_ct_ext_find(ct, NF_CT_EXT_KZ);
+}
+
+
+/* handle kzorp extension in conntrack record
+   an earlier version had the kzorp structure directly in nf_conn
+   we changed that to use the extension API and add only on request
+   this makes it possible to actually run without kzorp, and carry
+   ne weight.
+   The downside is that extensions can not be added after certain point
+   (basicly, it must happen at the start of a session, not at second
+    or a further packet...).
+   If the kzorp extension can't be added, we still can do zone/svc
+   lookup on the fly -- only losing the cache.
+   The other thing we lose is the session id assignment.
+
+   So a proper ruleset that wants to use those facilities shall make
+   sure to have have the first packet meet KZORP related lookup.
+
+*/
+
+/* returns consolidated kzorp lookup info; caches it in ct, and uses
+   the cache if valid;
+   returns NULL only if it's not possible to add kzorp extension to ct
+   rcu_dereferenced config is stored in p_cfg
+  call under rcu_read_lock() even if p_cfg==NULL!
+
+   the returned structure is placed in ct, and destroy will happen
+   when ct gets destroyed
+*/
+extern const struct nf_conntrack_kzorp * nfct_kzorp_cached_lookup_rcu(
+	struct nf_conn *ct,
+	enum ip_conntrack_info ctinfo,
+	const struct sk_buff *skb,
+	const struct net_device * const in,
+	u8 l3proto,
+	const struct kz_config **p_cfg);
+
+/* fills kzorp structure with lookup data
+   rcu_dereferenced config is stored in p_cfg
+   call under rcu_read_lock() even if p_cfg==NULL!
+   leaves non-lookup fields untouched!
+   pointers in the passed structure must be valid/NULL,
+   as they are released while the new ones addrefed
+
+   make sure to call kz_destroy_kzorp on pkzorp eventually
+*/
+extern void nfct_kzorp_lookup_rcu(struct nf_conntrack_kzorp * pkzorp,
+	enum ip_conntrack_info ctinfo,
+	const struct sk_buff *skb,
+	const struct net_device * const in,
+	const u8 l3proto,
+	const struct kz_config **p_cfg);
+
+/* unreferences stuff inside
+*/
+extern void kz_destroy_kzorp(struct nf_conntrack_kzorp *kzorp);
+
+/***********************************************************
+ * Hook functions
+ ***********************************************************/
+
+extern int kz_hooks_init(void);
+extern void kz_hooks_cleanup(void);
+
+/***********************************************************
+ * Lookup functions
+ ***********************************************************/
+
+extern int kz_lookup_init(void);
+extern void kz_lookup_cleanup(void);
+
+extern void kz_head_dispatcher_init(struct kz_head_d *h);
+extern int kz_head_dispatcher_build(struct kz_head_d *h);
+extern void kz_head_dispatcher_destroy(struct kz_head_d *h);
+
+extern void kz_head_zone_init(struct kz_head_z *h);
+extern int kz_head_zone_build(struct kz_head_z *h);
+extern void kz_head_zone_destroy(struct kz_head_z *h);
+extern struct kz_zone *kz_head_zone_ipv4_lookup(const struct kz_head_z *h, const struct in_addr * const addr);
+
+extern const struct nf_nat_ipv4_range *kz_service_nat_lookup(const struct list_head * const head,
+						    const __be32 saddr, const __be32 daddr,
+						    const __be16 sport, const __be16 dport,
+						    const u_int8_t proto);
+
+struct kz_traffic_props {
+	sa_family_t l3proto;
+
+	const struct kz_reqids *reqids;
+
+	const struct net_device *iface;
+
+	const union nf_inet_addr * src_addr;
+	const union nf_inet_addr * dst_addr;
+
+	struct kz_zone * src_zone;
+	struct kz_zone * dst_zone;
+
+	u_int16_t src_port;
+	u_int16_t dst_port;
+
+	u_int8_t  proto;
+	u_int32_t proto_type;
+	u_int32_t proto_subtype;
+};
+
+static inline void
+kz_traffic_props_init(struct kz_traffic_props *traffic_props)
+{
+	memset(traffic_props, 0, sizeof(struct kz_traffic_props));
+	traffic_props->proto_type = -1;
+	traffic_props->proto_subtype = -1;
+}
+
+extern void kz_lookup_session(const struct kz_config *cfg,
+			      struct kz_traffic_props * const traffic_props,
+			      struct kz_dispatcher **dispatcher,
+			      struct kz_zone **clientzone, struct kz_zone **serverzone,
+			      struct kz_service **service, int reply);
+
+/***********************************************************
+ * Netlink functions
+ ***********************************************************/
+
+extern int kz_nfnetlink_init(void);
+extern void kz_nfnetlink_cleanup(void);
+
+
+/***********************************************************
+ * Logging
+ ***********************************************************/
+
+#define kz_debug(format, args...) pr_debug("%s: " format, __FUNCTION__, ##args)
+#define kz_err(format, args...) pr_err("kzorp:%s: " format, __FUNCTION__, ##args)
+
+#define kz_bind_debug(bind, msg) \
+{ \
+	switch (bind->family) { \
+	case NFPROTO_IPV4: \
+		kz_debug("%s; address='%pI4', port='%d', proto='%d' pid='%d'\n", msg, &bind->addr.in, bind->port, bind->proto, bind->peer_pid); \
+		break; \
+	case NFPROTO_IPV6: \
+		kz_debug("%s; address='%pI6', port='%d', proto='%d' pid='%d'\n", msg, &bind->addr.in6, bind->port, bind->proto, bind->peer_pid); \
+		break; \
+	default: \
+		BUG(); \
+	} \
+}
+
+/* Bitfield */
+enum {
+	KZL_NONE		= 0,    /* supress log message */
+	KZL_NORMAL		= 1,
+	KZL_DROPPED_PACKETS	= 2,	/* silently dropped packets */
+	KZL_PACKET_INFO		= 4,	/* source and destination */
+	KZL_LOOKUP		= 8,	/* Main parts used by lookup_session */
+	KZL_POINTERS		= 16,	/*service etc. pointers (debug) */
+	KZL_FUNC_DEBUG		= 32,	/* function startup, control path  */
+	KZL_FUNC_EXTRA_DEBUG    = 64,   /* basically same as KZL_FUNC_DEBUG, lots of log */
+};
+
+/***********************************************************
+ * getsockopt() interface
+ ***********************************************************/
+
+extern int kz_sockopt_init(void);
+extern void kz_sockopt_cleanup(void);
+
+/***********************************************************
+ * Netlink interface
+ ***********************************************************/
+
+extern int kz_netlink_init(void);
+extern void kz_netlink_cleanup(void);
+
+static inline void ipv6_addr_copy(struct in6_addr *a1, const struct in6_addr *a2)
+{
+	memcpy(a1, a2, sizeof(struct in6_addr));
+}
+#endif
Index: linux-3.3.8/include/linux/netfilter/kzorp_netlink.h
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ linux-3.3.8/include/linux/netfilter/kzorp_netlink.h	2013-11-18 17:12:30.151285665 +0100
@@ -0,0 +1,198 @@
+/*
+ * KZorp netfilter netlink interface
+ *
+ * Copyright (C) 2006-2010, BalaBit IT Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#ifndef _KZORP_NETLINK_H
+#define _KZORP_NETLINK_H
+
+#include <linux/types.h>
+
+typedef char ifname_t[IFNAMSIZ];
+
+enum kznl_msg_types {
+	KZNL_MSG_INVALID,
+	KZNL_MSG_GET_VERSION,
+	KZNL_MSG_START,
+	KZNL_MSG_COMMIT,
+	KZNL_MSG_FLUSH_ZONE,
+	KZNL_MSG_ADD_ZONE,
+	KZNL_MSG_GET_ZONE,
+	KZNL_MSG_FLUSH_SERVICE,
+	KZNL_MSG_ADD_SERVICE,
+	KZNL_MSG_ADD_SERVICE_NAT_SRC,
+	KZNL_MSG_ADD_SERVICE_NAT_DST,
+	KZNL_MSG_GET_SERVICE,
+	KZNL_MSG_FLUSH_DISPATCHER,
+	KZNL_MSG_ADD_DISPATCHER,
+	KZNL_MSG_GET_DISPATCHER,
+	KZNL_MSG_QUERY,
+	KZNL_MSG_ADD_RULE,
+	KZNL_MSG_ADD_RULE_ENTRY,
+	KZNL_MSG_ADD_BIND,
+	KZNL_MSG_GET_BIND,
+	KZNL_MSG_FLUSH_BIND,
+	KZNL_MSG_QUERY_REPLY,
+	KZNL_MSG_TYPE_COUNT
+};
+
+enum kznl_attr_types {
+	KZNL_ATTR_INVALID,
+	KZNL_ATTR_INSTANCE_NAME,
+	KZNL_ATTR_ZONE_NAME,
+	KZNL_ATTR_ZONE_UNAME,
+	KZNL_ATTR_ZONE_PNAME,
+	KZNL_ATTR_ZONE_RANGE,
+	KZNL_ATTR_SERVICE_PARAMS,
+	KZNL_ATTR_SERVICE_NAME,
+	KZNL_ATTR_SERVICE_ROUTER_DST_ADDR,
+	KZNL_ATTR_SERVICE_NAT_SRC,
+	KZNL_ATTR_SERVICE_NAT_DST,
+	KZNL_ATTR_SERVICE_NAT_MAP,
+	KZNL_ATTR_SERVICE_SESSION_CNT,
+	KZNL_ATTR_DISPATCHER_NAME,
+	KZNL_ATTR_QUERY_PARAMS,
+	KZNL_ATTR_QUERY_REPLY_CLIENT_ZONE,
+	KZNL_ATTR_QUERY_REPLY_SERVER_ZONE,
+	KZNL_ATTR_DISPATCHER_N_DIMENSION_PARAMS,
+	KZNL_ATTR_N_DIMENSION_RULE_ID,
+	KZNL_ATTR_N_DIMENSION_RULE_SERVICE,
+	KZNL_ATTR_N_DIMENSION_IFACE,
+	KZNL_ATTR_N_DIMENSION_PROTO,
+	KZNL_ATTR_N_DIMENSION_SRC_PORT,
+	KZNL_ATTR_N_DIMENSION_DST_PORT,
+	KZNL_ATTR_N_DIMENSION_SRC_IP,
+	KZNL_ATTR_N_DIMENSION_SRC_ZONE,
+	KZNL_ATTR_N_DIMENSION_DST_IP,
+	KZNL_ATTR_N_DIMENSION_DST_ZONE,
+	KZNL_ATTR_N_DIMENSION_IFGROUP,
+	KZNL_ATTR_CONFIG_COOKIE,
+	KZNL_ATTR_INET_ADDR,
+	KZNL_ATTR_INET_SUBNET,
+	KZNL_ATTR_INET6_ADDR,
+	KZNL_ATTR_INET6_SUBNET,
+	KZNL_ATTR_N_DIMENSION_SRC_IP6,
+	KZNL_ATTR_N_DIMENSION_DST_IP6,
+	KZNL_ATTR_QUERY_PARAMS_SRC_IP,
+	KZNL_ATTR_QUERY_PARAMS_DST_IP,
+	KZNL_ATTR_SERVICE_ROUTER_DST_PORT,
+	KZNL_ATTR_BIND_ADDR,
+	KZNL_ATTR_BIND_PORT,
+	KZNL_ATTR_BIND_PROTO,
+	KZNL_ATTR_MAJOR_VERSION,
+	KZNL_ATTR_COMPAT_VERSION,
+	KZNL_ATTR_SERVICE_DENY_IPV4_METHOD,
+	KZNL_ATTR_SERVICE_DENY_IPV6_METHOD,
+	KZNL_ATTR_N_DIMENSION_DST_IFACE,
+	KZNL_ATTR_N_DIMENSION_DST_IFGROUP,
+	KZNL_ATTR_N_DIMENSION_REQID,
+	KZNL_ATTR_QUERY_PARAMS_REQID,
+	KZNL_ATTR_N_DIMENSION_PROTO_TYPE,
+	KZNL_ATTR_N_DIMENSION_PROTO_SUBTYPE,
+	KZNL_ATTR_QUERY_PARAMS_SRC_PORT,
+	KZNL_ATTR_QUERY_PARAMS_DST_PORT,
+	KZNL_ATTR_QUERY_PARAMS_PROTO_TYPE,
+	KZNL_ATTR_QUERY_PARAMS_PROTO_SUBTYPE,
+	KZNL_ATTR_TYPE_COUNT
+};
+
+#define KZ_ATTR_NAME_MAX_LENGTH 1023
+
+/* global instance name */
+#define KZ_INSTANCE_GLOBAL ".global"
+#define KZ_INSTANCE_GLOBAL_STRLEN 7
+
+/* generic attributes */
+struct kza_name {
+	__be16 length;
+	char name[0];
+} __attribute__ ((packed));
+
+struct kza_port_range {
+	__be16 from;
+	__be16 to;
+} __attribute__ ((packed));
+
+/* service attributes */
+enum kz_service_type {
+	KZ_SERVICE_INVALID,
+	KZ_SERVICE_PROXY,
+	KZ_SERVICE_FORWARD,
+	KZ_SERVICE_DENY,
+	KZ_SERVICE_TYPE_COUNT
+};
+
+enum kzf_service_params_flags {
+	KZF_SERVICE_TRANSPARENT  = 1 << 0,
+	KZF_SERVICE_FORGE_ADDR   = 1 << 1,
+	KZF_SERVICE_LOGGING      = 1 << 2,
+	KZF_SERVICE_PUBLIC_FLAGS = KZF_SERVICE_TRANSPARENT |
+				   KZF_SERVICE_FORGE_ADDR |
+				   KZF_SERVICE_LOGGING
+};
+
+struct kza_service_params {
+	__be32 flags;
+	__u8 type;
+} __attribute__ ((packed));
+
+enum kzf_service_nat_params_flags {
+	KZF_SERVICE_NAT_MAP_IPS		   = 1 << 0,
+	KZF_SERVICE_NAT_MAP_PROTO_SPECIFIC = 1 << 1,
+	KZF_SERVICE_NAT_MAP_PUBLIC_FLAGS   = KZF_SERVICE_NAT_MAP_IPS |
+					     KZF_SERVICE_NAT_MAP_PROTO_SPECIFIC
+};
+
+struct kza_service_nat_params {
+	__be32 flags;
+	__be32 min_ip, max_ip;
+	__be16 min_port, max_port;
+} __attribute__ ((packed));
+
+struct kza_service_session_cnt {
+	__be32 count;
+} __attribute__ ((packed));
+
+enum kz_service_ipv4_deny_method {
+	KZ_SERVICE_DENY_METHOD_V4_DROP,
+	KZ_SERVICE_DENY_METHOD_V4_TCP_RESET,
+	KZ_SERVICE_DENY_METHOD_ICMP_NET_UNREACHABLE,
+	KZ_SERVICE_DENY_METHOD_ICMP_HOST_UNREACHABLE,
+	KZ_SERVICE_DENY_METHOD_ICMP_PROTO_UNREACHABLE,
+	KZ_SERVICE_DENY_METHOD_ICMP_PORT_UNREACHABLE,
+	KZ_SERVICE_DENY_METHOD_ICMP_NET_PROHIBITED,
+	KZ_SERVICE_DENY_METHOD_ICMP_HOST_PROHIBITED,
+	KZ_SERVICE_DENY_METHOD_ICMP_ADMIN_PROHIBITED,
+	KZ_SERVICE_DENY_METHOD_V4_COUNT
+};
+
+enum kz_service_ipv6_deny_method {
+	KZ_SERVICE_DENY_METHOD_V6_DROP,
+	KZ_SERVICE_DENY_METHOD_V6_TCP_RESET,
+	KZ_SERVICE_DENY_METHOD_ICMPV6_NO_ROUTE,
+	KZ_SERVICE_DENY_METHOD_ICMPV6_ADMIN_PROHIBITED,
+	KZ_SERVICE_DENY_METHOD_ICMPV6_ADDR_UNREACHABLE,
+	KZ_SERVICE_DENY_METHOD_ICMPV6_PORT_UNREACHABLE,
+	KZ_SERVICE_DENY_METHOD_V6_COUNT
+};
+
+struct kza_dispatcher_n_dimension_params {
+	__be32 num_rules;
+} __attribute__ ((packed));
+
+struct kza_n_dimension_rule_params {
+	__be32 id;
+} __attribute__ ((packed));
+
+struct kza_query_params {
+	char ifname[IFNAMSIZ];
+	__u8 proto;
+} __attribute__ ((packed));
+
+#endif
Index: linux-3.3.8/include/linux/netfilter/kzorp_sockopt.h
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ linux-3.3.8/include/linux/netfilter/kzorp_sockopt.h	2013-11-18 17:12:30.151285665 +0100
@@ -0,0 +1,27 @@
+/*
+ * KZorp getsockopt() interface
+ *
+ * Copyright (C) 2006-2010, BalaBit IT Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#ifndef _KZORP_SOCKOPT_H
+#define _KZORP_SOCKOPT_H
+
+#include <linux/netfilter/kzorp_netlink.h>
+
+#define SO_KZORP_RESULT 1678333
+
+struct kz_lookup_result {
+	u_int64_t cookie;
+	char czone_name[KZ_ATTR_NAME_MAX_LENGTH + 1];
+	char szone_name[KZ_ATTR_NAME_MAX_LENGTH + 1];
+	char dispatcher_name[KZ_ATTR_NAME_MAX_LENGTH + 1];
+	char service_name[KZ_ATTR_NAME_MAX_LENGTH + 1];
+};
+
+#endif
Index: linux-3.3.8/include/linux/netfilter/xt_KZORP.h
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ linux-3.3.8/include/linux/netfilter/xt_KZORP.h	2013-11-18 17:12:30.151285665 +0100
@@ -0,0 +1,14 @@
+#ifndef _XT_KZORP_H_target
+#define _XT_KZORP_H_target
+
+/*
+* KZORP target makes the necessary decision by your policy settings performs
+* redirection, DAC decisions, and forwards services.
+*/
+struct xt_kzorp_target_info {
+	u_int32_t mark_mask; /* same as in xt_tproxy_target_info */
+	u_int32_t mark_value; /* same as in xt_tproxy_target_info */
+	u_int32_t flags; /*  for future expansion; must be set to 0! */
+};
+
+#endif /* _XT_KZORP_H_target */
Index: linux-3.3.8/include/net/netfilter/kzorp_internal.h
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ linux-3.3.8/include/net/netfilter/kzorp_internal.h	2013-11-18 17:12:30.151285665 +0100
@@ -0,0 +1,30 @@
+#ifndef _KZORP_INTERNAL_H
+#define _KZORP_INTERNAL_H
+
+/*
+ * Contains some definitions common to all kzorp compilation unit.
+ */
+
+//         DIM_NAME        NL_ATTR_NAME TYPE                  NL_TYPE     LOOKUP_TYPE
+
+#define KZORP_DIM_LIST(ACTION, _) \
+  ACTION ( reqid,          REQID,         u_int32_t,            value,         u_int32_t            )_ \
+  ACTION ( ifname,         IFACE,         ifname_t,             ifname,        ifname_t             )_ \
+  ACTION ( ifgroup,        IFGROUP,       u_int32_t,            value,         u_int32_t            )_ \
+  ACTION ( proto,          PROTO,         u_int8_t,             value,         u_int8_t             )_ \
+  ACTION ( proto_type,     PROTO_TYPE,    u_int32_t,            value,         u_int32_t            )_ \
+  ACTION ( proto_subtype,  PROTO_SUBTYPE, u_int32_t,            value,         u_int32_t            )_ \
+  ACTION ( src_port,       SRC_PORT,      struct kz_port_range, portrange,     struct kz_port_range )_ \
+  ACTION ( dst_port,       DST_PORT,      struct kz_port_range, portrange,     struct kz_port_range )_ \
+  ACTION ( src_in_subnet,  SRC_IP,        struct kz_in_subnet,  in_subnet,     struct kz_in_subnet  )_ \
+  ACTION ( src_in6_subnet, SRC_IP6,       struct kz_in6_subnet, in6_subnet,    struct kz_in6_subnet )_ \
+  ACTION ( src_zone,       SRC_ZONE,      struct kz_zone *,     string,        struct zone_lookup_t )_ \
+  ACTION ( dst_in_subnet,  DST_IP,        struct kz_in_subnet,  in_subnet,     struct kz_in_subnet  )_ \
+  ACTION ( dst_in6_subnet, DST_IP6,       struct kz_in6_subnet, in6_subnet,    struct kz_in6_subnet )_ \
+  ACTION ( dst_ifname,     DST_IFACE,     ifname_t,             ifname,        ifname_t             )_ \
+  ACTION ( dst_ifgroup,    DST_IFGROUP,   u_int32_t,            value,         u_int32_t            )_ \
+  ACTION ( dst_zone,       DST_ZONE,      struct kz_zone *,     string,        struct zone_lookup_t )
+
+#define KZORP_COMMA_SEPARATOR ,
+
+#endif /* _KZORP_INTERNAL_H */
Index: linux-3.3.8/include/net/netfilter/kzorp_lookup_internal.h
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ linux-3.3.8/include/net/netfilter/kzorp_lookup_internal.h	2013-11-18 17:12:30.151285665 +0100
@@ -0,0 +1,124 @@
+#ifndef _KZORP_LOOKUP_INTERNAL_H
+#define _KZORP_LOOKUP_INTERNAL_H
+
+/*
+ * KZorp lookup internal function declarations and struct definitions.
+ * It enables to test originally static functions.
+ * The File containing the definitions of the functions must include this file.
+ */
+
+#include <linux/netfilter/kzorp.h>
+
+#ifdef KZ_USERSPACE
+#define KZ_PROTECTED
+#else
+#define KZ_PROTECTED static
+#endif
+
+#define KZ_NOT_MATCHING_SCORE ((u_int64_t)-1)
+
+struct kz_lookup_ipv6_node {
+  struct kz_lookup_ipv6_node *parent;
+  struct kz_lookup_ipv6_node *left;
+  struct kz_lookup_ipv6_node *right;
+  struct in6_addr addr;
+  struct kz_zone *zone;
+  __u16 prefix_len;
+};
+
+/* header of the lookup data. After dimension_map there are additional data,
+ * for the dimensions in the rule, as specified by the dimension_map. */
+struct kz_rule_lookup_data {
+	/* back-pointer to original rule structure so that we have the
+	 * service and dispatcher pointers */
+	const struct kz_dispatcher_n_dimension_rule *orig;
+
+	u_int32_t bytes_to_next; /* number of bytes to the next rule (includes
+				  * the full kz_rule_lookup_data header size),
+				  * 0 if there are no more rules */
+	u_int32_t dimension_map;
+
+	/* additional bytes here for dimension data. See also KZORP_DIMENSION */
+};
+
+struct kz_rule_lookup_cursor {
+	struct kz_rule_lookup_data *rule;
+	u_int32_t pos;
+};
+
+KZ_PROTECTED struct kz_rule_lookup_data*
+kz_rule_lookup_cursor_next_rule(struct kz_rule_lookup_cursor *cursor);
+
+KZ_PROTECTED int64_t
+kz_ndim_eval_rule(struct kz_rule_lookup_cursor * cursor,
+		  int64_t best_all,
+		  const struct kz_traffic_props * const traffic_props,
+		  const unsigned long *src_zone_mask,
+		  const unsigned long *dst_zone_mask);
+
+KZ_PROTECTED size_t
+kz_generate_lookup_data_rule_size(const struct kz_dispatcher_n_dimension_rule * const rule);
+
+KZ_PROTECTED struct kz_rule_lookup_data *
+kz_generate_lookup_data_rule(const struct kz_dispatcher_n_dimension_rule * const rule, void *buf);
+
+KZ_PROTECTED inline unsigned int
+mask_to_size_v4(const struct in_addr * const mask);
+
+KZ_PROTECTED inline unsigned int
+mask_to_size_v6(const struct in6_addr * const mask);
+/**
+ * struct kz_percpu_env - per-CPU work area for the n-dimensional lookup algorithms
+ * @max_result_size: the maximal size of the result set to return
+ * @src_mask: bitmask to use as a temporary helper for source zone evaluation
+ * @dst_mask: bitmask to use as a temporary helper for destination zone evaluation
+ * @results: the buffer to return results in, an array of pointers to
+ *       struct kz_dispatcher_n_dimension_rule structures, should point to an
+ *       array with at lease @max_result_size elements
+ * @result_size: the number of matching rules stored in @results
+ */
+struct kz_percpu_env {
+  /* in */
+  size_t max_result_size;
+  unsigned long *src_mask;
+  unsigned long *dst_mask;
+  /* out */
+  struct kz_dispatcher_n_dimension_rule const **result_rules;
+  size_t result_size;
+};
+
+KZ_PROTECTED u_int32_t
+kz_ndim_eval(
+  const struct kz_traffic_props * const traffic_props,
+  const struct kz_head_d * const dispatchers,
+  struct kz_percpu_env *lenv
+);
+
+KZ_PROTECTED inline void
+mark_zone_path(unsigned long *mask, const struct kz_zone *zone);
+
+KZ_PROTECTED void
+kz_generate_lookup_data(struct kz_head_d *dispatchers);
+
+KZ_PROTECTED inline unsigned int
+mask_to_size_v4(const struct in_addr * const mask);
+
+KZ_PROTECTED inline unsigned int
+mask_to_size_v6(const struct in6_addr * const mask);
+
+KZ_PROTECTED inline struct kz_lookup_ipv6_node *
+ipv6_node_new(void);
+
+KZ_PROTECTED inline void
+ipv6_node_free(struct kz_lookup_ipv6_node *n);
+
+struct kz_lookup_ipv6_node *
+ipv6_add(struct kz_lookup_ipv6_node *root, struct in6_addr *addr, int prefix_len);
+
+KZ_PROTECTED struct kz_lookup_ipv6_node *
+ipv6_lookup(struct kz_lookup_ipv6_node *root, const struct in6_addr *addr);
+
+KZ_PROTECTED void
+ipv6_destroy(struct kz_lookup_ipv6_node *node);
+
+#endif /* _KZORP_LOOKUP_INTERNAL_H */
Index: linux-3.3.8/net/netfilter/kzorp_core.c
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ linux-3.3.8/net/netfilter/kzorp_core.c	2013-11-18 17:12:30.155285737 +0100
@@ -0,0 +1,1930 @@
+/*
+ * KZorp core
+ *
+ * Copyright (C) 2006-2010, BalaBit IT Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+/* TODO:
+ *   - service NAT list should be stored in an array instead of a linked list
+ *   - do we need the _add/_remove functions?
+ */
+
+#include <linux/module.h>
+#include <linux/proc_fs.h>
+#include <linux/netfilter.h>
+#include <linux/skbuff.h>
+#include <linux/proc_fs.h>
+#include <linux/seq_file.h>
+#include <linux/workqueue.h>
+#include <linux/vmalloc.h>
+#ifdef CONFIG_SYSCTL
+#include <linux/sysctl.h>
+#endif
+
+#include <net/ip.h>
+#include <net/ipv6.h>
+#include <net/netfilter/nf_conntrack.h>
+#include <net/netfilter/nf_conntrack_core.h>
+#include <net/netfilter/nf_conntrack_l3proto.h>
+#include <net/netfilter/nf_conntrack_l4proto.h>
+#include <net/netfilter/nf_conntrack_expect.h>
+#include <net/netfilter/nf_conntrack_helper.h>
+#include <net/netfilter/nf_conntrack_acct.h>
+
+#include <linux/icmp.h>
+#include <linux/icmpv6.h>
+#include <linux/netfilter/kzorp.h>
+#include <linux/netfilter/kzorp_netlink.h>
+
+static const char *const kz_log_null = "(NULL)";
+
+#define LOG_RATELIMIT_MSG_COST 50
+
+extern int sysctl_kzorp_log_ratelimit_msg_cost;
+extern int sysctl_kzorp_log_ratelimit_burst;
+
+/***********************************************************
+ * Instances
+ ***********************************************************/
+
+DEFINE_MUTEX(kz_instance_mutex);
+struct list_head kz_instances;
+
+
+/* instance 0 is the "global" instance, so it must be the first instance created */
+static unsigned int instance_id_cnt = 0;
+
+static void __init
+instance_init(void)
+{
+	INIT_LIST_HEAD(&kz_instances);
+}
+
+static void __exit
+instance_cleanup(void)
+{
+	struct kz_instance *i, *s;
+	list_for_each_entry_safe(i, s, &kz_instances, list) {
+		list_del(&i->list);
+		kfree(i);
+	}
+}
+
+/* !!! must be called with the instance mutex held !!! */
+struct kz_instance *
+kz_instance_lookup_nocheck(const char *name)
+{
+	struct kz_instance *i;
+
+	kz_debug("name='%s'\n", name);
+
+	list_for_each_entry(i, &kz_instances, list) {
+		if (strcmp(i->name, name) == 0)
+			return i;
+	}
+
+	return NULL;
+}
+
+/* !!! must be called with the instance mutex held !!! */
+struct kz_instance *
+kz_instance_lookup(const char *name)
+{
+	struct kz_instance *i;
+
+	kz_debug("name='%s'", name);
+
+	list_for_each_entry(i, &kz_instances, list) {
+		if (!(i->flags & KZF_INSTANCE_DELETED) &&
+		    (strcmp(i->name, name) == 0))
+			return i;
+	}
+
+	return NULL;
+}
+
+/* !!! must be called with the instance mutex held !!! */
+struct kz_instance *
+kz_instance_lookup_id(const unsigned int id)
+{
+	struct kz_instance *i;
+
+	kz_debug("id='%u'\n", id);
+
+	list_for_each_entry(i, &kz_instances, list) {
+		if (!(i->flags & KZF_INSTANCE_DELETED) &&
+		    (i->id == id))
+			return i;
+	}
+
+	return NULL;
+}
+
+/***********************************************************
+ * Per-instance bind address lists
+ ***********************************************************/
+
+struct kz_bind *
+kz_bind_new(void)
+{
+	struct kz_bind *bind;
+
+	bind = kzalloc(sizeof(struct kz_bind), GFP_KERNEL);
+	if (bind == NULL)
+		return NULL;
+
+	INIT_LIST_HEAD(&bind->list);
+
+	return bind;
+}
+
+struct kz_bind *
+kz_bind_clone(const struct kz_bind const *_bind)
+{
+	struct kz_bind *bind;
+
+	bind = kz_bind_new();
+	if (bind == NULL)
+		return NULL;
+
+	bind->peer_pid = _bind->peer_pid;
+	bind->family = _bind->family;
+	bind->proto = _bind->proto;
+	bind->addr = _bind->addr;
+	bind->port = _bind->port;
+
+	return bind;
+}
+
+void
+kz_bind_destroy(struct kz_bind *bind)
+{
+	kfree(bind);
+}
+
+/* !!! must be called with the instance mutex held !!! */
+struct kz_instance *
+kz_instance_create(const char *name, const unsigned int len, const netlink_port_t peer_pid)
+{
+	struct kz_instance *i;
+
+	kz_debug("name='%s', pid='%d'\n", name, peer_pid);
+
+	/* check if we already have a deleted instance with this name */
+	i = kz_instance_lookup_nocheck(name);
+	if (i != NULL) {
+		/* caller should check for existing instances */
+		BUG_ON(!(i->flags & KZF_INSTANCE_DELETED));
+		i->flags &= ~KZF_INSTANCE_DELETED;
+		return i;
+	}
+
+	/* limit check */
+	if (instance_id_cnt >= INSTANCE_MAX_NUM)
+		return NULL;
+
+	/* allocate memory for the structure + name + terminating 0 */
+	i = kzalloc(sizeof(*i) + len + 1, GFP_KERNEL);
+	if (i == NULL)
+		return NULL;
+
+	i->id = instance_id_cnt++;
+	i->peer_pid = peer_pid;
+	/* terminating zero comes from kzalloc() */
+	memcpy(i->name, name, len);
+	i->bind_lookup = kzalloc(sizeof(struct kz_bind_lookup), GFP_KERNEL);
+	INIT_LIST_HEAD(&i->bind_lookup->list_bind);
+	list_add(&i->list, &kz_instances);
+
+	kz_debug("instance created; name='%s', id='%d'\n", name, i->id);
+
+	return i;
+}
+
+/* !!! must be called with the instance mutex held !!! */
+void
+kz_instance_delete(struct kz_instance * const i)
+{
+	kz_debug("name='%s'\n", i->name);
+
+	i->flags |= KZF_INSTANCE_DELETED;
+}
+
+/***********************************************************
+ * Utility functions
+ ***********************************************************/
+
+char *
+kz_name_dup(const char * const name)
+{
+	char *n;
+	unsigned int len;
+
+	if (name == NULL)
+		return NULL;
+
+	len = strlen(name);
+	n = kmalloc(len + 1, GFP_KERNEL);
+	if (n == NULL)
+		return NULL;
+
+	memcpy(n, name, len);
+	n[len] = '\0';
+
+	return n;
+}
+
+/***********************************************************
+ * Config
+ ***********************************************************/
+
+/* content shall stay semantically 'empty', properly inited for work,
+   only generation may change after module init!  */
+static struct kz_config static_config =
+{
+	.zones = {.head = LIST_HEAD_INIT(static_config.zones.head)},
+	.services = {.head = LIST_HEAD_INIT(static_config.services.head)},
+	.dispatchers = {.head = LIST_HEAD_INIT(static_config.dispatchers.head)},
+	.generation = 1,
+	.cookie = 0UL
+};
+
+static void
+kz_config_init(struct kz_config *cfg)
+{
+	cfg->cookie = 0;
+	cfg->generation = 0;
+	INIT_LIST_HEAD(&cfg->zones.head);
+	INIT_LIST_HEAD(&cfg->services.head);
+	INIT_LIST_HEAD(&cfg->dispatchers.head);
+	kz_head_zone_init(&cfg->zones);
+	kz_head_dispatcher_init(&cfg->dispatchers);
+}
+
+static int __init
+static_cfg_init(void)
+{
+	int res = 0;
+	kz_config_init(&static_config);
+	static_config.generation = 1;
+
+	res = kz_head_zone_build(&static_config.zones);
+	if (res == 0)
+		res = kz_head_dispatcher_build(&static_config.dispatchers);
+	return res;
+}
+
+static void __exit
+static_cfg_cleanup(void)
+{
+	kz_head_dispatcher_destroy(&static_config.dispatchers);
+	kz_head_zone_destroy(&static_config.zones);
+}
+
+struct kz_config *kz_config_rcu = &static_config;
+
+struct kz_config *kz_config_new(void)
+{
+	struct kz_config *cfg = kzalloc(sizeof(struct kz_config), GFP_KERNEL);
+	if (cfg)
+		kz_config_init(cfg);
+	return cfg;
+}
+
+void kz_config_destroy(struct kz_config * cfg)
+{
+	if (cfg != NULL) {
+		kz_head_destroy_zone(&cfg->zones);
+		kz_head_destroy_service(&cfg->services);
+		kz_head_destroy_dispatcher(&cfg->dispatchers);
+		kfree(cfg);
+	}
+}
+
+static void
+kz_config_list_free_rcu(struct rcu_head *rcu_head)
+{
+	struct kz_config *cfg = container_of(rcu_head, struct kz_config, rcu);
+	if (cfg != &static_config)
+		kz_config_destroy(cfg);
+}
+
+void
+kz_config_swap(struct kz_config * new_cfg)
+{
+	struct kz_config * old_cfg;
+	rcu_read_lock();
+	old_cfg = rcu_dereference(kz_config_rcu);
+	if (new_cfg != old_cfg) {
+		new_cfg->generation = old_cfg->generation + 1;
+		rcu_assign_pointer(kz_config_rcu, new_cfg);
+		if (old_cfg != &static_config)
+			call_rcu(&old_cfg->rcu, kz_config_list_free_rcu);
+	}
+	rcu_read_unlock();
+}
+
+/***********************************************************
+ * Lookup
+ ***********************************************************/
+
+void nfct_kzorp_lookup_rcu(struct nf_conntrack_kzorp * kzorp,
+	enum ip_conntrack_info ctinfo,
+	const struct sk_buff *skb,
+	const struct net_device * const in,
+	const u8 l3proto,
+	const struct kz_config **p_cfg)
+{
+	struct kz_traffic_props traffic_props;
+	struct kz_zone *czone = NULL;
+	struct kz_zone *szone = NULL;
+	struct kz_dispatcher *dpt = NULL;
+	struct kz_service *svc = NULL;
+	struct {
+		u16 src;
+		u16 dst;
+	} __attribute__((packed)) *ports, _ports = { .src = 0, .dst = 0 };
+	const struct kz_config * loc_cfg;
+	u8 l4proto;
+	u_int32_t proto_type = 0, proto_subtype = 0;
+	union nf_inet_addr *saddr, *daddr;
+        struct kz_reqids reqids;
+	int sp_idx;
+
+	ports = &_ports;
+
+	if (p_cfg == NULL)
+		p_cfg = &loc_cfg;
+
+	*p_cfg = rcu_dereference(kz_config_rcu);
+
+	BUG_ON(*p_cfg == NULL);
+	kzorp->generation = (*p_cfg)->generation;
+
+	switch (l3proto) {
+	case NFPROTO_IPV4:
+	{
+		const struct iphdr * const iph = ip_hdr(skb);
+
+		l4proto = iph->protocol;
+		saddr = (union nf_inet_addr *) &iph->saddr;
+		daddr = (union nf_inet_addr *) &iph->daddr;
+
+		if ((l4proto == IPPROTO_TCP) || (l4proto == IPPROTO_UDP)) {
+			ports = skb_header_pointer(skb, ip_hdrlen(skb), sizeof(_ports), &_ports);
+			if (unlikely(ports == NULL))
+				goto done;
+			kz_debug("kzorp lookup for packet: protocol='%u', src='%pI4:%u', dst='%pI4:%u'\n",
+				 iph->protocol, &iph->saddr, ntohs(ports->src), &iph->daddr, ntohs(ports->dst));
+		}
+		else if (l4proto == IPPROTO_ICMP) {
+			const struct icmphdr *icmp;
+			struct icmphdr _icmp = { .type = 0, .code = 0 };
+			icmp = skb_header_pointer(skb, ip_hdrlen(skb), sizeof(_icmp), &_icmp);
+			if (unlikely(icmp == NULL))
+				goto done;
+
+			proto_type = icmp->type;
+			proto_subtype = icmp->code;
+			kz_debug("kzorp lookup for packet: protocol='%u', src='%pI4', dst='%pI4', type='%d', code='%d'\n", l4proto,
+				 &iph->saddr, &iph->daddr, icmp->type, icmp->code);
+		}
+	}
+		break;
+	case NFPROTO_IPV6:
+	{
+		const struct ipv6hdr * const iph = ipv6_hdr(skb);
+		int thoff;
+		u8 tproto = iph->nexthdr;
+		__be16 frag_offp;
+
+		/* find transport header */
+		thoff = ipv6_skip_exthdr(skb, sizeof(*iph), &tproto, &frag_offp);
+		if (unlikely(thoff < 0))
+			goto done;
+
+		l4proto = tproto;
+		saddr = (union nf_inet_addr *) &iph->saddr;
+		daddr = (union nf_inet_addr *) &iph->daddr;
+
+		if ((l4proto == IPPROTO_TCP) || (l4proto == IPPROTO_UDP)) {
+			/* get info from transport header */
+			ports = skb_header_pointer(skb, thoff, sizeof(_ports), &_ports);
+			if (unlikely(ports == NULL))
+				goto done;
+			kz_debug("kzorp lookup for packet: protocol='%u', src='%pI6:%u', dst='%pI6:%u'\n", l4proto,
+				 &iph->saddr, ntohs(ports->src), &iph->daddr, ntohs(ports->dst));
+		}
+		else if (l4proto == IPPROTO_ICMPV6) {
+			const struct icmp6hdr *icmp;
+			struct icmp6hdr _icmp = { .icmp6_type = 0, .icmp6_code = 0 };
+			icmp = skb_header_pointer(skb, thoff, sizeof(_icmp), &_icmp);
+			if (unlikely(icmp == NULL))
+				goto done;
+
+			proto_type = icmp->icmp6_type;
+			proto_subtype = icmp->icmp6_code;
+			kz_debug("kzorp lookup for packet: protocol='%u', src='%pI6', dst='%pI6', type='%d', code='%d'\n", l4proto,
+				 &iph->saddr, &iph->daddr, icmp->icmp6_type, icmp->icmp6_code);
+		}
+
+	}
+		break;
+	default:
+		BUG();
+		break;
+	}
+
+	/* copy IPSEC reqids from secpath to our own structure */
+	if (skb->sp != NULL) {
+		reqids.len = skb->sp->len;
+		for (sp_idx = 0; sp_idx  < reqids.len; sp_idx++)
+			reqids.vec[sp_idx] = skb->sp->xvec[sp_idx]->props.reqid;
+	} else {
+		reqids.len = 0;
+	}
+
+	kz_traffic_props_init(&traffic_props);
+	traffic_props.l3proto = l3proto;
+	traffic_props.proto = l4proto;
+	traffic_props.reqids = &reqids;
+	traffic_props.iface = in;
+	traffic_props.src_addr = saddr;
+	traffic_props.dst_addr = daddr;
+	switch (l4proto) {
+	case IPPROTO_TCP:
+	case IPPROTO_UDP:
+		traffic_props.src_port = ntohs(ports->src);
+		traffic_props.dst_port = ntohs(ports->dst);
+		break;
+
+	case IPPROTO_ICMP:
+	case IPPROTO_ICMPV6:
+		traffic_props.proto_type = proto_type;
+		traffic_props.proto_subtype = proto_subtype;
+		break;
+
+	default:
+		break;
+	}
+	kz_lookup_session(*p_cfg,
+			  &traffic_props,
+			  &dpt, &czone, &szone, &svc,
+			  (ctinfo >= IP_CT_IS_REPLY));
+
+done:
+#define REPLACE_PTR(name, type) \
+	if (kzorp->name != name) { \
+		if (kzorp->name) \
+			kz_##type##_put(kzorp->name); \
+		kzorp->name = name ? kz_##type##_get(name) : NULL; \
+	}
+
+	REPLACE_PTR(czone, zone);
+	REPLACE_PTR(szone, zone);
+	REPLACE_PTR(dpt, dispatcher);
+	REPLACE_PTR(svc, service);
+
+#undef REPLACE_PTR
+
+	kz_debug("kzorp lookup result; dpt='%s', client_zone='%s', server_zone='%s', svc='%s'\n",
+		 kzorp->dpt ? kzorp->dpt->name : kz_log_null,
+		 kzorp->czone ? kzorp->czone->name : kz_log_null,
+		 kzorp->szone ? kzorp->szone->name : kz_log_null,
+		 kzorp->svc ? kzorp->svc->name : kz_log_null);
+
+	return;
+}
+EXPORT_SYMBOL_GPL(nfct_kzorp_lookup_rcu);
+
+
+const struct nf_conntrack_kzorp * nfct_kzorp_cached_lookup_rcu(
+	struct nf_conn *ct,
+	enum ip_conntrack_info ctinfo,
+	const struct sk_buff *skb,
+	const struct net_device * const in,
+	const u8 l3proto,
+	const struct kz_config **p_cfg)
+{
+	struct nf_conntrack_kzorp *kzorp;
+	const struct kz_config * loc_cfg;
+
+	if (p_cfg == NULL)
+		p_cfg = &loc_cfg;
+
+	*p_cfg = rcu_dereference(kz_config_rcu);
+
+	kzorp = nf_ct_ext_find(ct, NF_CT_EXT_KZ);
+
+	if (!kzorp) { /* no kzorp yet, add a fresh one */
+		/* no kzorp extension, we need to try and add it only
+		 * if the conntrack is not yet confirmed */
+		if (unlikely(nf_ct_is_confirmed(ct))) {
+			switch (l3proto) {
+			case NFPROTO_IPV4:
+			{
+				const struct iphdr * const iph = ip_hdr(skb);
+				kz_debug("can't add kzorp to ct for packet: src='%pI4', dst='%pI4'\n",
+					 &iph->saddr, &iph->daddr);
+			}
+				break;
+			case NFPROTO_IPV6:
+			{
+				const struct ipv6hdr * const iph = ipv6_hdr(skb);
+				kz_debug("can't add kzorp to ct for packet: src='%pI6', dst='%pI6'\n",
+					 &iph->saddr, &iph->daddr);
+			}
+				break;
+			default:
+				BUG();
+			}
+			return NULL;
+		}
+
+		kzorp = nf_ct_ext_add(ct, NF_CT_EXT_KZ, GFP_ATOMIC);
+		if (unlikely(!kzorp)) {
+			kz_debug("allocation failed creating kzorp\n");
+			return NULL;
+		}
+		/* implicit:  kzorp->sid = 0; */
+		nfct_kzorp_lookup_rcu(kzorp, ctinfo, skb, in, l3proto, p_cfg);
+		return kzorp;
+	}
+
+	/* use existing kzorp, make sure it is okay */
+
+	if (unlikely(!kz_generation_valid(*p_cfg, kzorp->generation))) {
+		nfct_kzorp_lookup_rcu(kzorp, ctinfo, skb, in, l3proto, p_cfg);
+	}
+
+	return kzorp;
+}
+EXPORT_SYMBOL_GPL(nfct_kzorp_cached_lookup_rcu);
+
+/***********************************************************
+ * Zones
+ ***********************************************************/
+
+#define ZONE_SERVICE_ALLOC_THRESHOLD 8
+struct kz_zone *
+kz_zone_new(void)
+{
+	struct kz_zone *zone;
+
+	zone = kzalloc(sizeof(struct kz_zone), GFP_KERNEL);
+	if (zone == NULL)
+		return NULL;
+
+	atomic_set(&zone->refcnt, 1);
+	zone->depth = 1;
+
+	return zone;
+}
+
+void
+kz_zone_destroy(struct kz_zone *zone)
+{
+       if (zone->admin_parent)
+	       kz_zone_put(zone->admin_parent);
+       /* unique_name may be the same pointer as name! */
+       if (zone->unique_name != zone->name)
+	       kfree(zone->unique_name);
+       if (zone->name)
+	       kfree(zone->name);
+       kfree(zone);
+}
+EXPORT_SYMBOL_GPL(kz_zone_destroy);
+
+struct kz_zone *
+__kz_zone_lookup_name(const struct list_head * const head, const char *name)
+{
+	struct kz_zone *i;
+
+	BUG_ON(!name);
+
+	list_for_each_entry(i, head, list) {
+		if (strcmp(i->unique_name, name) == 0)
+			return i;
+	}
+
+	return NULL;
+}
+
+struct kz_zone *
+kz_zone_lookup_name(const struct kz_config *cfg, const char *name)
+{
+	return __kz_zone_lookup_name(&cfg->zones.head, name);
+}
+
+struct kz_zone *
+kz_zone_clone(const struct kz_zone * const o)
+{
+	struct kz_zone *zone;
+
+
+	zone = kz_zone_new();
+	if (zone == NULL)
+		return NULL;
+
+	zone->flags = o->flags;
+	zone->family = o->family;
+	zone->addr = o->addr;
+	zone->mask = o->mask;
+	zone->depth = o->depth;
+
+	zone->name = kz_name_dup(o->name);
+	if (zone->name == NULL)
+		goto error_put;
+
+	if (o->name == o->unique_name) {
+		zone->unique_name = zone->name;
+	} else {
+		/* unique name is different */
+		zone->unique_name = kz_name_dup(o->unique_name);
+		if (zone->unique_name == NULL)
+			goto error_put;
+	}
+
+	if (o->admin_parent != NULL)
+		zone->admin_parent = kz_zone_get(o->admin_parent);
+
+	return zone;
+
+error_put:
+	kz_zone_put(zone);
+
+	return NULL;
+}
+
+void
+kz_head_destroy_zone(struct kz_head_z *head)
+{
+	struct kz_zone *i, *p;
+
+	/* destroy lookup data structures */
+	kz_head_zone_destroy(head);
+
+	list_for_each_entry_safe(i, p, &head->head, list) {
+		list_del(&i->list);
+		kz_zone_put(i);
+	}
+}
+
+/***********************************************************
+ * Services
+ ***********************************************************/
+
+static atomic_t service_id_cnt;
+
+struct kz_service *
+kz_service_new(void)
+{
+	struct kz_service *service;
+
+	service = kzalloc(sizeof(struct kz_service), GFP_KERNEL);
+	if (service == NULL)
+		return NULL;
+
+	atomic_set(&service->refcnt, 1);
+	atomic_set(&service->session_cnt, 0);
+
+	service->id = atomic_inc_return(&service_id_cnt);
+
+	INIT_LIST_HEAD(&service->a.fwd.snat);
+	INIT_LIST_HEAD(&service->a.fwd.dnat);
+
+	return service;
+}
+
+void
+kz_service_destroy(struct kz_service *service)
+{
+	struct kz_service_nat_entry *i, *s;
+
+	if (service->name)
+		kfree(service->name);
+
+	if (service->type == KZ_SERVICE_FORWARD) {
+		/* free NAT entries */
+		list_for_each_entry_safe(i, s, &service->a.fwd.snat, list) {
+			list_del(&i->list);
+			kfree(i);
+		}
+		list_for_each_entry_safe(i, s, &service->a.fwd.dnat, list) {
+			list_del(&i->list);
+			kfree(i);
+		}
+	}
+
+	kfree(service);
+}
+
+struct kz_service *
+__kz_service_lookup_name(const struct list_head * const head, const char *name)
+{
+	struct kz_service *i;
+
+	BUG_ON(!name);
+
+	list_for_each_entry(i, head, list) {
+		if (strcmp(i->name, name) == 0)
+			return i;
+	}
+
+	return NULL;
+}
+
+struct kz_service *
+kz_service_lookup_name(const struct kz_config *cfg, const char *name)
+{
+	return __kz_service_lookup_name(&cfg->services.head, name);
+}
+EXPORT_SYMBOL_GPL(kz_service_lookup_name);
+
+int
+kz_service_add_nat_entry(struct list_head *head, struct nf_nat_ipv4_range *src,
+			 struct nf_nat_ipv4_range *dst, struct nf_nat_ipv4_range *map)
+{
+	struct kz_service_nat_entry *entry;
+
+	BUG_ON(!src);
+	BUG_ON(!map);
+
+	entry = kzalloc(sizeof(*entry), GFP_KERNEL);
+	if (entry == NULL)
+		return -ENOMEM;
+
+	entry->src = *src;
+	if (dst != NULL)
+		entry->dst = *dst;
+	entry->map = *map;
+
+	list_add_tail(&entry->list, head);
+
+	return 0;
+}
+
+static int
+service_clone_nat_list(const struct list_head * const src, struct list_head *dst)
+{
+	struct kz_service_nat_entry *i;
+	int res = 0;
+
+	list_for_each_entry(i, src, list) {
+		res = kz_service_add_nat_entry(dst, &i->src,
+					    i->dst.min_ip ? &i->dst : NULL,
+					    &i->map);
+		if (res < 0)
+			break;
+	}
+
+	return res;
+}
+
+struct kz_service *
+kz_service_clone(const struct kz_service * const o)
+{
+	struct kz_service *svc;
+
+	svc = kz_service_new();
+	if (svc == NULL)
+		return NULL;
+
+	svc->instance_id = o->instance_id;
+	svc->flags = o->flags;
+	svc->type = o->type;
+	svc->a = o->a;
+	svc->name = kz_name_dup(o->name);
+	if (svc->name == NULL)
+		goto error_put;
+	if (svc->type == KZ_SERVICE_FORWARD) {
+		INIT_LIST_HEAD(&svc->a.fwd.snat);
+		if (service_clone_nat_list(&o->a.fwd.snat, &svc->a.fwd.snat) < 0)
+			goto error_put;
+		INIT_LIST_HEAD(&svc->a.fwd.dnat);
+		if (service_clone_nat_list(&o->a.fwd.dnat, &svc->a.fwd.dnat) < 0)
+			goto error_put;
+	}
+
+	return svc;
+
+error_put:
+	kz_service_put(svc);
+
+	return NULL;
+}
+
+int
+kz_service_lock(struct kz_service * const service)
+{
+	/* lock service session counter */
+	set_bit(KZ_SERVICE_CNT_LOCKED_BIT, (unsigned long *)&service->flags);
+	return atomic_read(&service->session_cnt);
+}
+
+void
+kz_service_unlock(struct kz_service * const service)
+{
+	clear_bit(KZ_SERVICE_CNT_LOCKED_BIT, (unsigned long *)&service->flags);
+}
+
+void
+kz_head_destroy_service(struct kz_head_s *head)
+{
+	struct kz_service *i, *p;
+
+	list_for_each_entry_safe(i, p, &head->head, list) {
+		list_del(&i->list);
+		kz_service_put(i);
+	}
+}
+
+/***********************************************************
+ * Dispatchers
+ ***********************************************************/
+
+static struct workqueue_struct *vfree_queue;
+
+#define DISPATCHER_CSS_ALLOC_THRESHOLD 8
+
+static int __init
+dpt_init(void)
+{
+	vfree_queue = create_workqueue("kzorp_vfree_queue");
+	if (vfree_queue == NULL) {
+		return -ENOMEM;
+	}
+	return 0;
+}
+
+static void
+dpt_cleanup(void)
+{
+	flush_workqueue(vfree_queue);
+	destroy_workqueue(vfree_queue);
+}
+
+void*
+kz_big_alloc(size_t size, enum KZ_ALLOC_TYPE *alloc_type)
+{
+	void * ret = kzalloc(size, GFP_KERNEL | __GFP_NOWARN);
+	*alloc_type = KZALLOC;
+
+	if (!ret) {
+		ret = __vmalloc(size, GFP_KERNEL | __GFP_ZERO, PAGE_KERNEL);
+		*alloc_type = VMALLOC;
+	}
+
+	return ret;
+}
+
+static void
+vfree_wq_function(struct work_struct *work)
+{
+	const kz_vfree_work_t *w = (kz_vfree_work_t *) work;
+
+	vfree(w->p);
+	kfree(w);
+}
+
+void
+kz_big_free(void *ptr, enum KZ_ALLOC_TYPE alloc_type)
+{
+	switch (alloc_type) {
+	case KZALLOC: {
+			kzfree(ptr);
+			break;
+		}
+	case VMALLOC: {
+			int res;
+			kz_vfree_work_t *w = kzalloc(sizeof(kz_vfree_work_t), GFP_KERNEL);
+			INIT_WORK((struct work_struct *) w, vfree_wq_function);
+			w->p = ptr;
+			res = queue_work(vfree_queue, (struct work_struct *)w);
+			BUG_ON(!res);
+			break;
+		}
+	}
+}
+
+/**
+ * kz_dispatcher_alloc_rule_array - allocate rule array for N-dim rules
+ * @dispatcher: the dispatcher to allocate the array for
+ * @alloc_rules: the number of rules to allocate memory for
+ *
+ * This function tries to allocate the rule array using kzalloc(). If
+ * that fails (because we're over the maximum memory allocatable by
+ * the slab allocator) we retry the allocation using vmalloc().
+ *
+ * kz_dispatcher_alloc_rule_array() is always called in user
+ * context. For freeing the vmalloc()-ed memory block we have to
+ * allocate a work_queue structure, too, so that we don't have to
+ * allocate memory when we're trying to free the array.
+ *
+ * Returns: 0 on success,
+ *          -ENOMEM if memory allocation fails
+ */
+int
+kz_dispatcher_alloc_rule_array(struct kz_dispatcher *dispatcher, size_t alloc_rules)
+{
+	const size_t rule_size = sizeof(struct kz_dispatcher_n_dimension_rule) * alloc_rules;
+
+	dispatcher->rule = kz_big_alloc(rule_size, &dispatcher->rule_allocator);
+
+	dispatcher->num_rule = 0;
+	dispatcher->alloc_rule = alloc_rules;
+
+	return 0;
+}
+
+/**
+ * kz_dispatcher_free_rule_array - free rule array in dispatcher structure
+ * @dispatcher: dispatcher to clean up
+ *
+ * Frees the rule array in the dispatcher structure. This is tricky
+ * because the array may have been allocated using vmalloc() and in
+ * that case we have to defer vfree()-ing the memory to a work queue
+ * thread (so that it happens in user context).
+ */
+static void
+kz_dispatcher_free_rule_array(struct kz_dispatcher *dispatcher)
+{
+	if (dispatcher->rule != NULL) {
+		kz_big_free(dispatcher->rule, dispatcher->rule_allocator);
+	}
+
+	dispatcher->num_rule = dispatcher->alloc_rule = 0;
+	dispatcher->rule = NULL;
+}
+
+struct kz_dispatcher *
+kz_dispatcher_new(void)
+{
+	struct kz_dispatcher *dispatcher;
+
+	dispatcher = kzalloc(sizeof(struct kz_dispatcher), GFP_KERNEL);
+	if (dispatcher == NULL)
+		return NULL;
+
+	atomic_set(&dispatcher->refcnt, 1);
+
+	return dispatcher;
+}
+
+static void
+kz_rule_destroy(struct kz_dispatcher_n_dimension_rule *rule)
+{
+	int j;
+
+	if (rule == NULL)
+		return;
+
+	for (j = 0; j < rule->num_src_zone; j++)
+		kz_zone_put(rule->src_zone[j]);
+	for (j = 0; j < rule->num_dst_zone; j++)
+		kz_zone_put(rule->dst_zone[j]);
+
+	kz_service_put(rule->service);
+
+	kfree(rule->src_in_subnet);
+	kfree(rule->dst_in_subnet);
+	kfree(rule->src_in6_subnet);
+	kfree(rule->dst_in6_subnet);
+	kfree(rule->ifname);
+	kfree(rule->ifgroup);
+	kfree(rule->src_port);
+	kfree(rule->dst_port);
+	kfree(rule->src_zone);
+	kfree(rule->dst_zone);
+	kfree(rule->proto);
+	kfree(rule->dst_ifname);
+	kfree(rule->dst_ifgroup);
+	kfree(rule->reqid);
+
+	memset(rule, 0, sizeof(*rule));
+}
+
+void
+kz_dispatcher_destroy(struct kz_dispatcher *dispatcher)
+{
+	int i;
+
+	if (dispatcher->name)
+		kfree(dispatcher->name);
+
+	if (dispatcher->rule != NULL) {
+		/* drop rule references */
+		for (i = 0; i < dispatcher->num_rule; i++)
+			kz_rule_destroy(&dispatcher->rule[i]);
+
+		kz_dispatcher_free_rule_array(dispatcher);
+	}
+
+	kfree(dispatcher);
+}
+
+struct kz_dispatcher *
+kz_dispatcher_lookup_name(const struct kz_config *cfg, const char *name)
+{
+	struct kz_dispatcher *i;
+
+	BUG_ON(!name);
+
+	list_for_each_entry(i, &cfg->dispatchers.head, list) {
+		if (strcmp(i->name, name) == 0)
+			return i;
+	}
+
+	return NULL;
+}
+
+#define kz_alloc_rule_dimension(dim_name, dst_name, src_name, error_label) \
+	if (src_name->alloc_##dim_name) { \
+		dst_name->dim_name = kzalloc(sizeof(*dst_name->dim_name) * src_name->alloc_##dim_name, GFP_KERNEL); \
+		if (dst_name->dim_name == NULL) { \
+			res = -ENOMEM; \
+			goto error_label; \
+		} \
+	} else { \
+		dst_name->dim_name = NULL; \
+	} \
+	dst_name->alloc_##dim_name = src_name->alloc_##dim_name;
+
+int
+kz_dispatcher_add_rule(struct kz_dispatcher *d, struct kz_service *service,
+		       const struct kz_dispatcher_n_dimension_rule * const rule_params)
+{
+	int res = 0;
+	struct kz_dispatcher_n_dimension_rule *rule = NULL;
+	int64_t last_id = -1L;
+
+	if (d->num_rule + 1 > d->alloc_rule) {
+		kz_err("each rule has already been added to this dispatcher; num_rule='%d'\n",
+		       d->alloc_rule);
+		res = -EINVAL;
+		goto error;
+	}
+
+	/* check that the ID of the rule to be added is larger than
+	 * the ID of the last rule */
+	if (d->num_rule > 0)
+		last_id = d->rule[d->num_rule - 1].id;
+
+	if (rule_params->id <= last_id) {
+		kz_err("rule id is not larger than the id of the last rule; id='%u', last_id='%lld'\n", rule_params->id, last_id);
+		res = -EINVAL;
+		goto error;
+	}
+
+	rule = &d->rule[d->num_rule];
+	rule->id = rule_params->id;
+	rule->service = kz_service_get(service);
+	rule->dispatcher = d;
+
+#define CALL_kz_alloc_rule_dimension(DIM_NAME, NL_ATTR_NAME, _, NL_TYPE, ...) \
+	kz_alloc_rule_dimension(DIM_NAME, rule, rule_params, error_free_dimensions)
+
+	KZORP_DIM_LIST(CALL_kz_alloc_rule_dimension, ;);
+
+#undef CALL_kz_alloc_rule_dimension
+
+	d->num_rule++;
+
+	return 0;
+
+error_free_dimensions:
+	kz_rule_destroy(rule);
+
+error:
+	return res;
+}
+
+#define kz_dispatcher_append_rule_entry_value(entry_name)		\
+	if (rule_entry_params->has_##entry_name) {			\
+		if (rule->num_##entry_name + 1 > rule->alloc_##entry_name) { \
+			kz_err("each " #entry_name " has already been added to the rule; alloc_" #entry_name "='%d'", \
+			       rule->num_##entry_name);			\
+			res = -ENOMEM;					\
+			goto error;					\
+		}							\
+		rule->entry_name[rule->num_##entry_name] = rule_entry_params->entry_name; \
+	}
+
+#define kz_dispatcher_append_rule_entry_portrange(entry_name)		\
+	if (rule_entry_params->has_##entry_name) {			\
+		if (rule->num_##entry_name + 1 > rule->alloc_##entry_name) { \
+			kz_err("each " #entry_name " has already been added to the rule; alloc_" #entry_name "='%d'", \
+			       rule->num_##entry_name);			\
+			res = -ENOMEM;					\
+			goto error;					\
+		}							\
+		rule->entry_name[rule->num_##entry_name].from = rule_entry_params->entry_name.from; \
+		rule->entry_name[rule->num_##entry_name].to = rule_entry_params->entry_name.to; \
+	}
+
+#define kz_dispatcher_append_rule_entry_subnet(entry_name)		\
+	if (rule_entry_params->has_##entry_name) {			\
+		if (rule->num_##entry_name + 1 > rule->alloc_##entry_name) { \
+			kz_err("each " #entry_name " has already been added to the rule; alloc_" #entry_name "='%d'", \
+			       rule->num_##entry_name);			\
+			res = -ENOMEM;					\
+			goto error;					\
+		}							\
+		rule->entry_name[rule->num_##entry_name].addr = rule_entry_params->entry_name.addr; \
+		rule->entry_name[rule->num_##entry_name].mask = rule_entry_params->entry_name.mask; \
+	}
+
+#define kz_dispatcher_append_rule_entry_in_subnet(entry_name)		\
+	kz_dispatcher_append_rule_entry_subnet(entry_name)
+#define kz_dispatcher_append_rule_entry_in6_subnet(entry_name)		\
+	kz_dispatcher_append_rule_entry_subnet(entry_name)
+
+#define kz_dispatcher_append_rule_entry_ifname(entry_name) \
+	if (rule_entry_params->has_##entry_name) { \
+		if (rule->num_##entry_name + 1 > rule->alloc_##entry_name) { \
+			kz_err("each " #entry_name " has already been added to the rule; alloc_" #entry_name "='%d'", \
+			       rule->num_##entry_name); \
+			res = -ENOMEM; \
+			goto error; \
+		} \
+		memcpy(rule->entry_name[rule->num_##entry_name], rule_entry_params->entry_name, IFNAMSIZ); \
+	}
+
+#define kz_dispatcher_append_rule_entry_string(entry_name)		\
+	kz_dispatcher_append_rule_entry_value(entry_name)
+
+#define kz_dispatcher_inc_rule_entry_num(entry_name) \
+	if (rule_entry_params->has_##entry_name) { \
+		rule->num_##entry_name++; \
+	}
+
+int
+kz_dispatcher_add_rule_entry(struct kz_dispatcher_n_dimension_rule *rule,
+			     const struct kz_dispatcher_n_dimension_rule_entry_params * const rule_entry_params)
+{
+	int res = 0;
+	struct kz_zone *zone;
+
+#define CALL_kz_dispatcher_append_rule_entry(DIM_NAME, NL_ATTR_NAME, _, NL_TYPE, ...) \
+	kz_dispatcher_append_rule_entry_##NL_TYPE(DIM_NAME)
+
+	KZORP_DIM_LIST(CALL_kz_dispatcher_append_rule_entry, ;);
+
+#undef CALL_kz_dispatcher_append_rule_entry
+
+	// no error has occured
+	if (rule_entry_params->has_src_zone) {
+		zone = rule->src_zone[rule->num_src_zone];
+		if (zone != NULL)
+			kz_zone_get(zone);
+	}
+
+	if (rule_entry_params->has_dst_zone) {
+		zone = rule->dst_zone[rule->num_dst_zone];
+		if (zone != NULL)
+			kz_zone_get(zone);
+	}
+
+#define CALL_kz_dispatcher_inc_rule_entry_num(DIM_NAME, NL_ATTR_NAME, _, NL_TYPE, ...) \
+	kz_dispatcher_inc_rule_entry_num(DIM_NAME)
+
+	KZORP_DIM_LIST(CALL_kz_dispatcher_inc_rule_entry_num, ;);
+
+#undef CALL_kz_dispatcher_inc_rule_entry_num
+
+error:
+	return res;
+}
+
+static void
+kz_rule_arr_relink_zones(u_int32_t * size, struct kz_zone **arr, const struct list_head * zonelist)
+{
+	u_int32_t i, put;
+
+	if (*size == 0)
+		return;
+
+	for (i = 0, put = 0; i < *size; ++i)
+	{
+		struct kz_zone * const in = arr[i];
+		struct kz_zone * out = __kz_zone_lookup_name(zonelist, in->unique_name);
+
+		if (out == NULL) { /* just drop */
+			kz_zone_put(in);
+			continue;
+		}
+		if (in != out) {
+			kz_zone_get(out);
+			kz_zone_put(in);
+		}
+		arr[put++] = out;
+	}
+	*size = put;
+}
+
+static void
+kz_rule_relink_zones(struct kz_dispatcher_n_dimension_rule *r, const struct list_head * zonelist)
+{
+	kz_rule_arr_relink_zones(&r->num_src_zone, r->src_zone, zonelist);
+	kz_rule_arr_relink_zones(&r->num_dst_zone, r->dst_zone, zonelist);
+}
+
+#define kz_clone_rule_dimension(dim_name, dst_name, src_name) \
+	dst_name->num_##dim_name = src_name->num_##dim_name; \
+	memcpy(dst_name->dim_name, src_name->dim_name, \
+	       dst_name->alloc_##dim_name * sizeof(*dst_name->dim_name))
+
+
+int
+kz_rule_copy(struct kz_dispatcher_n_dimension_rule *dst,
+	     const struct kz_dispatcher_n_dimension_rule * const src)
+{
+	int res = 0;
+	int i;
+
+	dst->id = src->id;
+	dst->service = kz_service_get(src->service);
+	dst->dispatcher = NULL;
+
+#define CALL_kz_alloc_rule_dimension(DIM_NAME, NL_ATTR_NAME, _, NL_TYPE, ...) \
+	kz_alloc_rule_dimension(DIM_NAME, dst, src, error)
+
+	KZORP_DIM_LIST(CALL_kz_alloc_rule_dimension, ;);
+
+#undef CALL_kz_alloc_rule_dimension
+
+#define CALL_kz_clone_rule_dimension(DIM_NAME, NL_ATTR_NAME, _, NL_TYPE, ...) \
+	kz_clone_rule_dimension(DIM_NAME, dst, src)
+
+	KZORP_DIM_LIST(CALL_kz_clone_rule_dimension, ;);
+
+#undef CALL_kz_clone_rule_dimension
+
+	for (i = 0; i < dst->num_src_zone; i++)
+		dst->src_zone[i] = kz_zone_get(dst->src_zone[i]);
+	for (i = 0; i < dst->num_dst_zone; i++)
+		dst->dst_zone[i] = kz_zone_get(dst->dst_zone[i]);
+
+	return 0;
+
+error:
+	kz_rule_destroy(dst);
+
+	return res;
+}
+
+int
+kz_dispatcher_copy_rules(struct kz_dispatcher *dst,
+			 const struct kz_dispatcher * const src)
+{
+	unsigned int i = 0, j;
+	int res = 0;
+
+	dst->alloc_rule = src->alloc_rule;
+
+	if (dst->alloc_rule == 0) {
+		dst->rule = NULL;
+		dst->num_rule = 0;
+	} else {
+		res = kz_dispatcher_alloc_rule_array(dst, src->alloc_rule);
+		if (res < 0)
+			return -ENOMEM;
+
+
+		for (i = 0; i < src->num_rule; i++) {
+			res = kz_rule_copy(&dst->rule[i], &src->rule[i]);
+			if (res < 0)
+				goto error;
+
+			dst->rule[i].dispatcher = dst;
+			dst->num_rule = i + 1;
+		}
+	}
+
+	kz_debug("cloned rules; dst_num_rules='%u', dst_alloc_rules='%u', src_num_rules='%u', src_alloc_rules='%u'\n",
+		 dst->num_rule, dst->alloc_rule, src->num_rule, src->alloc_rule);
+
+	return 0;
+
+error:
+	if (dst->rule) {
+		for (j = 0; j < dst->num_rule; j++)
+			kz_rule_destroy(&dst->rule[j]);
+
+		kz_dispatcher_free_rule_array(dst);
+	}
+
+	return res;
+}
+
+struct kz_dispatcher *
+kz_dispatcher_clone_pure(const struct kz_dispatcher * const o)
+{
+	struct kz_dispatcher *dpt;
+
+	dpt = kz_dispatcher_new();
+	if (dpt == NULL)
+		return NULL;
+
+	dpt->instance = o->instance;
+	dpt->name = kz_name_dup(o->name);
+	if (dpt->name == NULL)
+		goto error_put;
+
+	return dpt;
+
+error_put:
+	kz_dispatcher_put(dpt);
+
+	return NULL;
+}
+
+struct kz_dispatcher *
+kz_dispatcher_clone(const struct kz_dispatcher * const o)
+{
+	struct kz_dispatcher *dpt;
+
+	dpt = kz_dispatcher_clone_pure(o);
+	if (dpt == NULL)
+		return NULL;
+
+	if (kz_dispatcher_copy_rules(dpt, o) < 0)
+		goto error_put;
+
+	return dpt;
+
+error_put:
+	kz_dispatcher_put(dpt);
+
+	return NULL;
+}
+
+/* all zone links must point into the passed lists, remove those not found */
+static void
+kz_dispatcher_relink_n_dim(struct kz_dispatcher *d, const struct list_head * zonelist, const struct list_head * servicelist)
+{
+	unsigned int i, put;
+	bool drop = 0;
+	for (i = 0; i < d->num_rule; ++i) {
+		struct kz_dispatcher_n_dimension_rule *rule = &d->rule[i];
+		struct kz_service *service = __kz_service_lookup_name(servicelist, rule->service->name);
+		if (service == NULL) {
+			kz_err("Dropping rule with missing service; dispatcher='%s', rule_id='%u', service='%s'\n",
+			       d->name, rule->id, rule->service->name);
+			kz_rule_destroy(rule);
+			drop = 1;
+			continue;
+		}
+		if (service != rule->service) {
+			kz_service_put(rule->service);
+			rule->service = kz_service_get(service);
+		}
+		kz_rule_relink_zones(rule, zonelist);
+	}
+	if (!drop)
+		return;
+	/* sweep dropped rules */
+	for (i = 0, put = 0; i < d->num_rule; ++i) {
+		if (d->rule[i].service != NULL)
+			d->rule[put++] = d->rule[i];
+	}
+	d->num_rule = put;
+}
+
+void
+kz_dispatcher_relink(struct kz_dispatcher *d, const struct list_head * zonelist, const struct list_head * servicelist)
+{
+	kz_dispatcher_relink_n_dim(d, zonelist, servicelist);
+	kz_debug("re-linked n-dim dispatcher; name='%s', num_rules='%u'\n", d->name, d->num_rule);
+}
+
+void
+kz_head_destroy_dispatcher(struct kz_head_d *head)
+{
+	struct kz_dispatcher *i, *p;
+
+	/* destroy lookup data structures */
+	kz_head_dispatcher_destroy(head);
+
+	list_for_each_entry_safe(i, p, &head->head, list) {
+		list_del(&i->list);
+		kz_dispatcher_put(i);
+	}
+}
+
+/***********************************************************
+ * sysctl interface
+ ***********************************************************/
+
+#ifdef CONFIG_SYSCTL
+static ctl_table kzorp_table[] = {
+	{
+		.procname	= "log_ratelimit_msg_cost",
+		.data		= &sysctl_kzorp_log_ratelimit_msg_cost,
+		.maxlen 	= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= &proc_dointvec_ms_jiffies
+	},
+	{
+		.procname	= "log_ratelimit_burst",
+		.data		= &sysctl_kzorp_log_ratelimit_burst,
+		.maxlen 	= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= &proc_dointvec
+	},
+	{ }
+};
+
+static struct ctl_path kzorp_sysctl_path[] = {
+	{ .procname = "net", },
+	{ .procname = "netfilter", },
+	{ .procname = "kzorp", },
+	{ }
+};
+
+static struct ctl_table_header * kzorp_sysctl_header;
+#endif /* CONFIG_SYSCTL */
+
+#ifdef CONFIG_PROC_FS
+static unsigned int
+seq_print_counters(struct seq_file *s,
+		   const struct nf_conn *ct,
+		   enum ip_conntrack_dir dir)
+{
+	struct nf_conn_counter *acct;
+
+	acct = nf_conn_acct_find(ct);
+	if (!acct)
+		return 0;
+
+	return seq_printf(s, "packets=%lu bytes=%lu ",
+			  acct[dir].packets.counter,
+			  acct[dir].bytes.counter);
+}
+
+struct kz_iter_state {
+	struct seq_net_private p;
+	unsigned int bucket;
+};
+
+static struct hlist_nulls_node *kz_get_first(struct seq_file *seq)
+{
+	struct net *net = seq_file_net(seq);
+	struct kz_iter_state *st = seq->private;
+	struct hlist_nulls_node *n;
+
+	for (st->bucket = 0;
+	     st->bucket < net->ct.htable_size;
+	     st->bucket++) {
+		n = rcu_dereference(net->ct.hash[st->bucket].first);
+		if (!is_a_nulls(n))
+			return n;
+	}
+	return NULL;
+}
+
+static struct hlist_nulls_node *kz_get_next(struct seq_file *seq, struct hlist_nulls_node *head)
+{
+	struct net *net = seq_file_net(seq);
+	struct kz_iter_state *st = seq->private;
+
+	head = rcu_dereference(head->next);
+	while (is_a_nulls(head)) {
+		if (likely(get_nulls_value(head) == st->bucket)) {
+			if (++st->bucket >= net->ct.htable_size)
+				return NULL;
+		}
+		head = rcu_dereference(net->ct.hash[st->bucket].first);
+	}
+	return head;
+}
+
+static struct hlist_nulls_node *kz_get_idx(struct seq_file *seq, loff_t pos)
+{
+	struct hlist_nulls_node *head = kz_get_first(seq);
+
+	if (head)
+		while (pos && (head = kz_get_next(seq, head)))
+			pos--;
+	return pos ? NULL : head;
+}
+
+static void *kz_seq_start(struct seq_file *seq, loff_t *pos)
+	__acquires(RCU)
+{
+	rcu_read_lock();
+	return kz_get_idx(seq, *pos);
+}
+
+static void *kz_seq_next(struct seq_file *s, void *v, loff_t *pos)
+{
+	(*pos)++;
+	return kz_get_next(s, v);
+}
+
+static void kz_seq_stop(struct seq_file *s, void *v)
+	__releases(RCU)
+{
+	rcu_read_unlock();
+}
+
+/* return 0 on success, 1 in case of error */
+static int kz_seq_show(struct seq_file *s, void *v)
+{
+	const struct nf_conntrack_tuple_hash *hash = v;
+	struct nf_conn *conntrack = nf_ct_tuplehash_to_ctrack(hash);
+	const struct nf_conntrack_kzorp *kzorp = nfct_kz(conntrack);
+	struct nf_conntrack_l3proto *l3proto;
+	struct nf_conntrack_l4proto *l4proto;
+	struct kz_dispatcher *dpt = NULL;
+	struct kz_zone *czone = NULL, *szone = NULL;
+	struct kz_service *svc = NULL;
+	struct kz_instance *ins = NULL;
+	int ret = 0;
+
+	NF_CT_ASSERT(conntrack);
+
+	if (unlikely(!atomic_inc_not_zero(&conntrack->ct_general.use)))
+		return 0;
+
+	/* we only want to print DIR_ORIGINAL */
+	if (NF_CT_DIRECTION(hash))
+		goto release;
+
+	/* we onyl want to print forwarded sessions */
+	if (!kzorp || !kzorp->czone || !kzorp->szone || !kzorp->dpt || !kzorp->svc)
+		goto release;
+
+	szone = kzorp->szone;
+	czone = kzorp->czone;
+	dpt   = kzorp->dpt;
+	svc   = kzorp->svc;
+
+	if (svc->type != KZ_SERVICE_FORWARD)
+		goto release;
+
+	ins = kz_instance_lookup_id(svc->instance_id);
+
+	if (!ins)
+		goto release;
+
+	l3proto = __nf_ct_l3proto_find(conntrack->tuplehash[IP_CT_DIR_ORIGINAL]
+				       .tuple.src.l3num);
+
+	NF_CT_ASSERT(l3proto);
+	l4proto = __nf_ct_l4proto_find(conntrack->tuplehash[IP_CT_DIR_ORIGINAL]
+				   .tuple.src.l3num,
+				   conntrack->tuplehash[IP_CT_DIR_ORIGINAL]
+				   .tuple.dst.protonum);
+	NF_CT_ASSERT(l4proto);
+
+	ret = -ENOSPC;
+	if (seq_printf(s, "instance=%-8s sid=%lu dpt=%-8s svc=%-8s czone=%-8s "
+		       "szone=%-8s ", ins->name, kzorp->sid,
+		       dpt->name, svc->name, czone->name, szone->name) != 0)
+		goto release;
+
+	if (seq_printf(s, "%-8s %u %-8s %u %ld ",
+		       l3proto->name,
+		       conntrack->tuplehash[IP_CT_DIR_ORIGINAL].tuple.src.l3num,
+		       l4proto->name,
+		       conntrack->tuplehash[IP_CT_DIR_ORIGINAL].tuple.dst.protonum,
+		       timer_pending(&conntrack->timeout)
+		       ? (long)(conntrack->timeout.expires - jiffies)/HZ : 0) != 0)
+		goto release;
+
+	if (l4proto->print_conntrack && l4proto->print_conntrack(s, conntrack))
+		goto release;
+
+	if (print_tuple(s, &conntrack->tuplehash[IP_CT_DIR_ORIGINAL].tuple,
+			l3proto, l4proto))
+		goto release;
+
+	if (seq_print_counters(s, conntrack, IP_CT_DIR_ORIGINAL))
+		goto release;
+
+	if (!(test_bit(IPS_SEEN_REPLY_BIT, &conntrack->status)))
+		if (seq_printf(s, "[UNREPLIED] "))
+			goto release;
+
+	if (print_tuple(s, &conntrack->tuplehash[IP_CT_DIR_REPLY].tuple,
+			l3proto, l4proto))
+		goto release;
+
+	if (seq_print_counters(s, conntrack, IP_CT_DIR_REPLY))
+		goto release;
+
+	if (test_bit(IPS_ASSURED_BIT, &conntrack->status))
+		if (seq_printf(s, "[ASSURED] "))
+			goto release;
+
+#if defined(CONFIG_NF_CONNTRACK_MARK)
+	if (seq_printf(s, "mark=%u ", conntrack->mark))
+		goto release;
+#endif
+
+#ifdef CONFIG_NF_CONNTRACK_SECMARK
+	if (seq_printf(s, "secmark=%u ", conntrack->secmark))
+		goto release;
+#endif
+
+	if (seq_printf(s, "use=%u\n", atomic_read(&conntrack->ct_general.use)))
+		goto release;
+
+	ret = 0;
+release:
+	nf_ct_put(conntrack);
+	return ret;
+}
+
+static struct seq_operations kz_seq_ops = {
+	.start = kz_seq_start,
+	.next  = kz_seq_next,
+	.stop  = kz_seq_stop,
+	.show  = kz_seq_show
+};
+
+static int kz_open(struct inode *inode, struct file *file)
+{
+	return seq_open_net(inode, file, &kz_seq_ops,
+			sizeof(struct kz_iter_state));
+}
+
+static const struct file_operations kz_file_ops = {
+	.owner   = THIS_MODULE,
+	.open    = kz_open,
+	.read    = seq_read,
+	.llseek  = seq_lseek,
+	.release = seq_release_net,
+};
+#endif /* CONFIG_PROC_FS */
+
+
+/***********************************************************
+ * Rate limit
+ ***********************************************************/
+
+#define LOG_RATELIMIT_MSG_COST 50
+#define LOG_RATELIMIT_BURST    50
+
+/*
+ * printk rate limiting, lifted from the networking subsystem.
+ *
+ * This enforces a rate limit: not more than one kernel message
+ * every printk_ratelimit_jiffies to make a denial-of-service
+ * attack impossible.
+ */
+static int __log_ratelimit(int ratelimit_msg_cost, int ratelimit_burst)
+{
+	static DEFINE_SPINLOCK(ratelimit_lock);
+	static unsigned long toks = LOG_RATELIMIT_MSG_COST * HZ * LOG_RATELIMIT_BURST / 1000;
+	static unsigned long last_msg;
+	static int missed;
+	unsigned long flags;
+	unsigned long now = jiffies;
+
+	spin_lock_irqsave(&ratelimit_lock, flags);
+	toks += now - last_msg;
+	last_msg = now;
+
+	if (toks > (ratelimit_burst * ratelimit_msg_cost))
+		toks = ratelimit_burst * ratelimit_msg_cost;
+
+	if (toks >= ratelimit_msg_cost) {
+		int lost = missed;
+
+		missed = 0;
+		toks -= ratelimit_msg_cost;
+		spin_unlock_irqrestore(&ratelimit_lock, flags);
+
+		if (lost)
+			printk(KERN_WARNING "kzorp: %d messages suppressed.\n", lost);
+
+		return 1;
+	}
+
+	missed++;
+	spin_unlock_irqrestore(&ratelimit_lock, flags);
+
+	return 0;
+}
+
+/* minimum time in jiffies between messages */
+int sysctl_kzorp_log_ratelimit_msg_cost;
+
+/* number of messages we send before ratelimiting */
+int sysctl_kzorp_log_ratelimit_burst = LOG_RATELIMIT_BURST;
+
+int kz_log_ratelimit(void)
+{
+	return __log_ratelimit(sysctl_kzorp_log_ratelimit_msg_cost,
+			       sysctl_kzorp_log_ratelimit_burst);
+}
+EXPORT_SYMBOL_GPL(kz_log_ratelimit);
+
+/***********************************************************
+ * Conntrack extension
+ ***********************************************************/
+
+void
+kz_destroy_kzorp(struct nf_conntrack_kzorp *kzorp)
+{
+	if (kzorp->czone != NULL)
+		kz_zone_put(kzorp->czone);
+	if (kzorp->szone != NULL)
+		kz_zone_put(kzorp->szone);
+	if (kzorp->dpt != NULL)
+		kz_dispatcher_put(kzorp->dpt);
+	if (kzorp->svc != NULL)
+		kz_service_put(kzorp->svc);
+}
+EXPORT_SYMBOL_GPL(kz_destroy_kzorp);
+
+static void
+kz_destroy_conntrack(struct nf_conn *ct)
+{
+	struct nf_conntrack_kzorp *kzorp = nfct_kz(ct);
+
+	if (kzorp == NULL)
+		return;
+
+	if ((kzorp->svc != NULL) && (kzorp->sid != 0) &&
+	    (kzorp->svc->type == KZ_SERVICE_FORWARD)) {
+		if (kz_log_ratelimit()) {
+			struct nf_conn_counter *acct;
+
+			acct = nf_conn_acct_find(ct);
+			if (acct)
+				printk(KERN_INFO "kzorp (svc/%s:%lu): Ending forwarded session; "
+				       "orig_bytes='%lu', orig_packets='%lu', "
+				       "reply_bytes='%lu', reply_packets='%lu'\n",
+				       kzorp->svc->name, kzorp->sid,
+				       acct[IP_CT_DIR_ORIGINAL].bytes.counter,
+				       acct[IP_CT_DIR_ORIGINAL].packets.counter,
+				       acct[IP_CT_DIR_REPLY].bytes.counter,
+				       acct[IP_CT_DIR_REPLY].packets.counter);
+			else
+				printk(KERN_INFO "kzorp (svc/%s:%lu) Ending forwarded session;\n",
+				       kzorp->svc->name, kzorp->sid);
+		}
+	}
+
+	kz_destroy_kzorp(kzorp);
+}
+
+static struct nf_ct_ext_type kz_extend __read_mostly = {
+	.len		= sizeof(struct nf_conntrack_kzorp),
+	.align		= __alignof__(struct nf_conntrack_kzorp),
+	.destroy	= kz_destroy_conntrack,
+	.id		= NF_CT_EXT_KZ,
+	.flags		= NF_CT_EXT_F_PREALLOC,
+};
+
+
+/***********************************************************
+ * Initialization
+ ***********************************************************/
+
+int __init kzorp_core_init(void)
+{
+	int res = -ENOMEM;
+	struct kz_instance *global;
+#ifdef CONFIG_PROC_FS
+	struct proc_dir_entry *proc;
+#endif
+
+	sysctl_kzorp_log_ratelimit_msg_cost = msecs_to_jiffies(LOG_RATELIMIT_MSG_COST);
+
+	atomic_set(&service_id_cnt, 1);
+	instance_init();
+
+	res = static_cfg_init();
+	if (res < 0)
+		goto cleanup;
+
+	res = dpt_init();
+	if (res < 0)
+		goto cleanup;
+
+	res = kz_lookup_init();
+	if (res < 0)
+		goto cleanup_dpt;
+
+	/* create global instance */
+	LOCK_INSTANCES();
+	global = kz_instance_create(KZ_INSTANCE_GLOBAL, KZ_INSTANCE_GLOBAL_STRLEN, 0);
+	if (global == NULL) {
+		UNLOCK_INSTANCES();
+		printk(KERN_ERR "kzorp: failed to create global instance\n");
+		res = -ENOMEM;
+		goto cleanup_lookup;
+	}
+	UNLOCK_INSTANCES();
+
+	res = nf_ct_extend_register(&kz_extend);
+	if (res < 0) {
+		kz_err("unable to register conntrack extension\n");
+		goto cleanup_global_instance;
+	}
+
+#ifdef CONFIG_SYSCTL
+	kzorp_sysctl_header = register_sysctl_paths(kzorp_sysctl_path, kzorp_table);
+	if (!kzorp_sysctl_header) {
+		printk(KERN_ERR "nf_kzorp: can't register to sysctl.\n");
+		res = -EINVAL;
+		goto cleanup_ctx;
+	}
+#endif
+
+#ifdef CONFIG_PROC_FS
+	proc = proc_net_fops_create(&init_net, "nf_kzorp", 0440, &kz_file_ops);
+	if (!proc) {
+		res = -EINVAL;
+		goto cleanup_sysctl;
+	}
+#endif
+
+	res = kz_sockopt_init();
+	if (res < 0)
+		goto cleanup_proc;
+
+	res = kz_netlink_init();
+	if (res < 0)
+		goto cleanup_sockopt;
+
+	return res;
+
+cleanup_sockopt:
+	kz_sockopt_cleanup();
+
+cleanup_proc:
+#ifdef CONFIG_PROC_FS
+	proc_net_remove(&init_net, "nf_kzorp");
+#endif
+
+cleanup_sysctl:
+#if CONFIG_SYSCTL
+	unregister_sysctl_table(kzorp_sysctl_header);
+#endif
+
+cleanup_ctx:
+	nf_ct_extend_unregister(&kz_extend);
+
+cleanup_global_instance:
+	kz_instance_delete(global);
+
+cleanup_lookup:
+	kz_lookup_cleanup();
+
+cleanup_dpt:
+	dpt_cleanup();
+
+cleanup:
+	static_cfg_cleanup();
+	return res;
+}
+
+static void __exit kzorp_core_fini(void)
+{
+	struct kz_instance *global;
+
+	kz_sockopt_cleanup();
+
+#ifdef CONFIG_PROC_FS
+	proc_net_remove(&init_net, "nf_kzorp");
+#endif
+#ifdef CONFIG_SYSCTL
+	unregister_sysctl_table(kzorp_sysctl_header);
+#endif
+	nf_ct_extend_unregister(&kz_extend);
+
+	kz_config_swap(&static_config);
+
+	LOCK_INSTANCES();
+	global = kz_instance_lookup(KZ_INSTANCE_GLOBAL);
+	if (global) {
+		kz_instance_delete(global);
+	}
+	instance_cleanup();
+	UNLOCK_INSTANCES();
+
+	kz_lookup_cleanup();
+
+	dpt_cleanup();
+
+	/* last things last! */
+	rcu_barrier() ;
+	static_cfg_cleanup();
+}
+
+MODULE_DESCRIPTION("kzorp core");
+MODULE_AUTHOR("Krisztian Kovacs <hidden@balabit.com>");
+MODULE_LICENSE("GPL");
+
+module_init(kzorp_core_init);
+module_exit(kzorp_core_fini);
Index: linux-3.3.8/net/netfilter/kzorp_lookup.c
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ linux-3.3.8/net/netfilter/kzorp_lookup.c	2013-11-18 17:12:30.155285737 +0100
@@ -0,0 +1,2238 @@
+/*
+ * KZorp data structure lookup implementation
+ *
+ * Copyright (C) 2006-2011, BalaBit IT Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+/* TODO:
+ *   - FIX transparent vs. non-transparent dispatcher lookups bug #21578 (specification needed before fix)
+ */
+
+#include <linux/version.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/net.h>
+#include <linux/if.h>
+#include <linux/list.h>
+#include <linux/jhash.h>
+#include <linux/percpu.h>
+#include <linux/cpumask.h>
+#include <linux/netdevice.h>
+#include <linux/inetdevice.h>
+#include <linux/sort.h>
+#include <net/ipv6.h>
+#include <net/tcp.h>
+#include <net/udp.h>
+#include <net/addrconf.h>
+#include <net/xfrm.h>
+
+#include <asm/bitops.h>
+
+#include <linux/netfilter/kzorp.h>
+
+#include <net/netfilter/kzorp_lookup_internal.h>
+
+static const char *const kz_log_null = "(NULL)";
+
+/***********************************************************
+ * Global lookup structures
+ ***********************************************************/
+
+struct zone_lookup_t
+{
+	u_int16_t index;
+	u_int16_t depth;
+};
+
+void kz_generate_lookup_data(struct kz_head_d *dispatchers);
+
+static DEFINE_PER_CPU(struct kz_percpu_env *, kz_percpu);
+
+void
+kz_lookup_cleanup(void)
+{
+	int cpu;
+
+	for_each_possible_cpu(cpu) {
+		struct kz_percpu_env *l = per_cpu(kz_percpu, cpu);
+
+		if (l != NULL) {
+			KZ_KFREE(l->src_mask);
+			KZ_KFREE(l->dst_mask);
+			KZ_KFREE(l->result_rules);
+			kfree(l);
+		}
+	}
+}
+
+int __init
+kz_lookup_init(void)
+{
+	int cpu;
+
+	for_each_possible_cpu(cpu) {
+		struct kz_percpu_env *l;
+
+		l = (struct kz_percpu_env *) kzalloc(sizeof(*l), GFP_KERNEL);
+		if (l == NULL)
+			goto cleanup;
+
+		per_cpu(kz_percpu, cpu) = l; /* store early, so cleanup works! */
+
+		l->src_mask = (unsigned long *) kzalloc(KZ_ZONE_BF_SIZE, GFP_KERNEL);
+		if (l->src_mask == NULL)
+			goto cleanup;
+
+		l->dst_mask = (unsigned long *) kzalloc(KZ_ZONE_BF_SIZE, GFP_KERNEL);
+		if (l->dst_mask == NULL)
+			goto cleanup;
+
+		l->result_rules = kzalloc(sizeof(*l->result_rules), GFP_KERNEL);
+		if (l->result_rules == NULL)
+			goto cleanup;
+
+		l->max_result_size = 1;
+	}
+
+	return 0;
+
+cleanup:
+	kz_lookup_cleanup();
+
+	return -ENOMEM;
+}
+
+/***********************************************************
+ * Utility functions
+ ***********************************************************/
+
+/**
+ * mask_to_size_v4 - given a 32 bit IPv4 subnet mask return how many leading 1 bits are set
+ * @mask: IPv4 subnet mask
+ *
+ * Returns: the number of leading '1' bits in @mask
+ */
+KZ_PROTECTED inline unsigned int
+mask_to_size_v4(const struct in_addr * const mask)
+{
+	if (mask == 0U)
+		return 0;
+	else
+		return 32 - fls(ntohl(~mask->s_addr));
+}
+
+/**
+ * mask_to_size_v6 - given a 128 bit IPv6 subnet mask return how many leading 1 bits are set
+ * @mask: IPv6 subnet mask
+ *
+ * Returns: the number of leading '1' bits in @mask
+ */
+KZ_PROTECTED inline unsigned int
+mask_to_size_v6(const struct in6_addr * const mask)
+{
+	unsigned int i;
+
+	if (mask->s6_addr32[0] == 0U &&
+	    mask->s6_addr32[1] == 0U &&
+	    mask->s6_addr32[2] == 0U &&
+	    mask->s6_addr32[3] == 0U)
+		return 0;
+
+	for (i = 0; i < 4; i++) {
+		u_int32_t m = mask->s6_addr32[i];
+		if (m == 0xffffffff)
+			continue;
+		if (m == 0)
+			return i * 32;
+
+		return i * 32 + 32 - fls(ntohl(~m));
+	}
+
+	return 128;
+}
+
+/* Return 1 if the destination address is local on the interface. */
+static inline int
+match_iface_local(const struct net_device * in, u_int8_t proto, const union nf_inet_addr *addr)
+{
+	int res = 0;
+
+
+	if (in == NULL)
+		return 0;
+
+	switch (proto) {
+	case NFPROTO_IPV4:
+		{
+			struct in_device *indev;
+			indev = in_dev_get(in);
+			if (indev == NULL)
+				return 0;
+
+			for_ifa(indev) {
+				if (ifa->ifa_local == addr->ip) {
+					res = 1;
+					break;
+				}
+			}
+			endfor_ifa(indev);
+
+			in_dev_put(indev);
+		}
+		break;
+	case NFPROTO_IPV6:
+		{
+			struct inet6_dev *in6dev;
+			struct inet6_ifaddr *ifp;
+			in6dev = in6_dev_get(in);
+			if (in6dev == NULL)
+				return 0;
+
+			list_for_each_entry(ifp, &in6dev->addr_list, if_list) {
+				if (ipv6_addr_cmp(&ifp->addr, &addr->in6) == 0) {
+					res = 1;
+					break;
+				}
+			}
+
+			in6_dev_put(in6dev);
+		}
+		break;
+	}
+
+	return res;
+}
+
+/***********************************************************
+ * Dispatchers
+ ***********************************************************/
+
+static int
+port_range_cmp(const void *_a, const void *_b)
+{
+	const struct kz_port_range *a = (struct kz_port_range *)_a;
+	const struct kz_port_range *b = (struct kz_port_range *)_b;
+	int res;
+
+	res = a->from - b->from;
+	if (res == 0)
+		res = a->to - b->to;
+
+	return res;
+}
+
+static void
+port_range_swap(void *_a, void *_b, int size)
+{
+	struct kz_port_range *a = (struct kz_port_range *)_a;
+	struct kz_port_range *b = (struct kz_port_range *)_b;
+
+	swap(a->from, b->from);
+	swap(a->to, b->to);
+}
+
+static int
+dpt_ndim_rule_sort_ports(unsigned int n, struct kz_port_range *r)
+{
+	sort(r, n, sizeof(*r), port_range_cmp, port_range_swap);
+
+	/* FIXME: add check to make sure there are no overlaps in ranges */
+	return 0;
+}
+
+static int
+in_subnet_size_cmp(const void *_a, const void *_b)
+{
+	const struct kz_in_subnet *a = (struct kz_in_subnet *)_a;
+	const struct kz_in_subnet *b = (struct kz_in_subnet *)_b;
+
+	int res;
+
+	/* NOTE: inverted result because we need to sort by the mask
+	 * size decreasingly */
+	res = mask_to_size_v4(&b->mask) - mask_to_size_v4(&a->mask);
+
+	if (res == 0)
+		res = (a->addr.s_addr < b->addr.s_addr) ? -1 :
+			((a->addr.s_addr == b->addr.s_addr) ? 0 : 1);
+
+	return res;
+}
+
+static void
+in_subnet_swap(void *_a, void *_b, int size)
+{
+	struct kz_in_subnet *a = (struct kz_in_subnet *)_a;
+	struct kz_in_subnet *b = (struct kz_in_subnet *)_b;
+
+	swap(a->addr, b->addr);
+	swap(a->mask, b->mask);
+}
+
+/**
+ * ipv6_addr_less - return true if an IPv6 address is less than another address
+ * @a1: first address
+ * @a2: second address
+ *
+ * Returns: true if @a1 < @a2 (numerically)
+ */
+static inline bool
+ipv6_addr_less(const struct in6_addr *a1, const struct in6_addr *a2)
+{
+	int i;
+
+	for (i = 0; i < 4; i++) {
+		u32 _a1 = ntohl(a1->s6_addr32[i]);
+		u32 _a2 = ntohl(a2->s6_addr32[i]);
+
+		if (_a1 < _a2)
+			return true;
+		else if (_a1 == _a2)
+			continue;
+		else
+			return false;
+	}
+
+	/* equal */
+	return false;
+}
+
+static int
+in6_subnet_size_cmp(const void *_a, const void *_b)
+{
+	const struct kz_in6_subnet *a = (struct kz_in6_subnet *)_a;
+	const struct kz_in6_subnet *b = (struct kz_in6_subnet *)_b;
+
+	int res;
+
+	/* NOTE: inverted result because we need to sort by the mask
+	 * size decreasingly */
+	res = mask_to_size_v6(&b->mask) - mask_to_size_v6(&a->mask);
+
+	if (res == 0)
+		res = ipv6_addr_less(&a->addr, &b->addr) ? -1 :
+		       (ipv6_addr_equal(&a->addr, &b->addr) ? 0 : 1);
+
+	return res;
+}
+
+static void
+in6_subnet_swap(void *_a, void *_b, int size)
+{
+	struct kz_in6_subnet *a = (struct kz_in6_subnet *)_a;
+	struct kz_in6_subnet *b = (struct kz_in6_subnet *)_b;
+
+	swap(a->addr, b->addr);
+	swap(a->mask, b->mask);
+}
+
+static int
+dpt_ndim_rule_sort_in_subnets(unsigned int n, struct kz_in_subnet *r)
+{
+	sort(r, n, sizeof(*r), in_subnet_size_cmp, in_subnet_swap);
+
+	return 0;
+}
+
+static int
+dpt_ndim_rule_sort_in6_subnets(unsigned int n, struct kz_in6_subnet *r)
+{
+	sort(r, n, sizeof(*r), in6_subnet_size_cmp, in6_subnet_swap);
+
+	return 0;
+}
+
+static int
+zone_depth_cmp(const void *_a, const void *_b)
+{
+	const struct kz_zone *a = *(const struct kz_zone **)_a;
+	const struct kz_zone *b = *(const struct kz_zone **)_b;
+	int res;
+
+	/* NOTE: inverted result because we need to sort by the depth
+	 * in reverse order */
+	res = b->depth - a->depth;
+	if (res == 0)
+		res = strcmp(a->unique_name, b->unique_name);
+
+	kz_debug("a='%s', b='%s', res='%d'\n", a->unique_name, b->unique_name, res);
+
+	return res;
+}
+
+static void
+zone_swap(void *_a, void *_b, int size)
+{
+	struct kz_zone **a = (struct kz_zone **)_a;
+	struct kz_zone **b = (struct kz_zone **)_b;
+
+	swap(*a, *b);
+}
+
+static int
+dpt_ndim_rule_sort_zones(unsigned int n, struct kz_zone **r)
+{
+	sort(r, n, sizeof(*r), zone_depth_cmp, zone_swap);
+
+	return 0;
+}
+
+static int
+dpt_ndim_rule_sort(struct kz_dispatcher_n_dimension_rule *rule)
+{
+	int res;
+
+	kz_debug("sorting rule; id='%u'\n", rule->id);
+
+	res = dpt_ndim_rule_sort_ports(rule->num_src_port, rule->src_port);
+	if (res < 0)
+		return res;
+
+	res = dpt_ndim_rule_sort_ports(rule->num_dst_port, rule->dst_port);
+	if (res < 0)
+		return res;
+
+	res = dpt_ndim_rule_sort_in_subnets(rule->num_src_in_subnet, rule->src_in_subnet);
+	if (res < 0)
+		return res;
+
+	res = dpt_ndim_rule_sort_in6_subnets(rule->num_src_in6_subnet, rule->src_in6_subnet);
+	if (res < 0)
+		return res;
+
+	res = dpt_ndim_rule_sort_in_subnets(rule->num_dst_in_subnet, rule->dst_in_subnet);
+	if (res < 0)
+		return res;
+
+	res = dpt_ndim_rule_sort_in6_subnets(rule->num_dst_in6_subnet, rule->dst_in6_subnet);
+	if (res < 0)
+		return res;
+
+	res = dpt_ndim_rule_sort_zones(rule->num_src_zone, rule->src_zone);
+	if (res < 0)
+		return res;
+
+	res = dpt_ndim_rule_sort_zones(rule->num_dst_zone, rule->dst_zone);
+
+	return res;
+}
+
+static int
+dpt_ndim_sort(struct kz_dispatcher *dispatcher)
+{
+	unsigned int i;
+	int res;
+
+	kz_debug("sorting dispatcher; name='%s'\n", dispatcher->name);
+
+	for (i = 0; i < dispatcher->num_rule; i++) {
+		res = dpt_ndim_rule_sort(&dispatcher->rule[i]);
+		if (res < 0)
+			return res;
+	}
+
+	return 0;
+}
+
+/***********************************************************
+ * Dispatcher lookup
+ ***********************************************************/
+
+void
+kz_head_dispatcher_init(struct kz_head_d *h)
+{
+	h->lookup_data = NULL;
+}
+EXPORT_SYMBOL_GPL(kz_head_dispatcher_init);
+
+int
+kz_head_dispatcher_build(struct kz_head_d *h)
+{
+	struct kz_dispatcher *i;
+	int res = 0;
+
+	list_for_each_entry(i, &h->head, list) {
+		/* n-dim dispatchers do not have a complex
+		 * lookup data structure yet, but we still
+		 * have to do some preparation for the lookup
+		 * here:
+		 *
+		 *  - port range lists should be sorted by on the 'from' entry
+		 *  - subnet lists should be sorted by the subnet size
+		 *  - zone lists should be sorted by the zone depth
+		 */
+		res = dpt_ndim_sort(i);
+		if (res < 0)
+			goto cleanup;
+	}
+
+	kz_generate_lookup_data(h);
+
+	return res;
+
+cleanup:
+	kz_debug("problem, cleaning up\n");
+
+	return res;
+}
+EXPORT_SYMBOL_GPL(kz_head_dispatcher_build);
+
+void
+kz_head_dispatcher_destroy(struct kz_head_d *h)
+{
+	if (h->lookup_data != NULL)
+		kz_big_free(h->lookup_data, h->lookup_data_allocator);
+}
+EXPORT_SYMBOL_GPL(kz_head_dispatcher_destroy);
+
+/***********************************************************
+ * Helper functions for weighted zone checks
+ ***********************************************************/
+
+/**
+ * mark_zone_path - mark all reachable zone IDs starting from a given zone
+ * @mask: the bitfield to mark zones in
+ * @zone: the zone to start with
+ *
+ * Starting with @zone and iterating up on the admin_parent chain this
+ * function sets bits in @mask to 1 for all accessible zones.
+ */
+KZ_PROTECTED inline void
+mark_zone_path(unsigned long *mask, const struct kz_zone *zone)
+{
+	while (zone != NULL) {
+		set_bit(zone->index, mask);
+		zone = zone->admin_parent;
+	}
+}
+
+/**
+ * unmark_zone_path - clear reachable marking for all reachable zone IDs
+ * @mask: the bitfield to clear bits in
+ * @zone: the zone to start with
+ *
+ * Undoes what mark_zone_path() did.
+ */
+static inline void
+unmark_zone_path(unsigned long *mask, const struct kz_zone *zone)
+{
+	while (zone != NULL) {
+		clear_bit(zone->index, mask);
+		zone = zone->admin_parent;
+	}
+}
+
+/**
+ * zone_score - return the "score" of a given zone
+ * @zone: the zone we need to score
+ * @mask: bitfield initialized with mark_zone_path()
+ *
+ * Returns a scrore for the given zone, based on whether or not it is
+ * accessible according to the mask and how deep it is in the zone
+ * hierarchy.
+ *
+ * The idea is that the more specific the match is the larger the
+ * score is.
+ *
+ * Returns: -1 if @zone is not accessible
+ *	    0 for root zones
+ *	    n if @zone is reachable through n links from a root zone
+ */
+static inline int
+zone_score(const struct zone_lookup_t *zone, const unsigned long * const mask)
+{
+	/* NULL zone == wildcard */
+	if (zone == NULL)
+		return 0;
+
+	/* check if the zone is reachable */
+	if (test_bit(zone->index, mask)) {
+		return zone->depth;
+	}
+	else {
+		return -1;
+	}
+}
+
+/* ipv4_masked_addr_cmp - return wether two addresses are in the same subnet
+ * @a1: first address
+ * @m: netmask of the subnet
+ * @a2: second address
+ *
+ * Returns: 0 if the addresses are in the same subnet
+ *          1 else
+ */
+static inline int
+ipv4_masked_addr_cmp(const struct in_addr *a1, const struct in_addr *m,
+		     const struct in_addr *a2)
+{
+	return !!((a1->s_addr ^ a2->s_addr) & m->s_addr);
+}
+
+static inline int
+iface_name_cmp(const char *ifname1, const char *ifname2)
+{
+	return !strncmp(ifname1, ifname2, IFNAMSIZ);
+}
+
+/***********************************************************
+ * N-dimensional rule lookup
+ *
+ * This is special: we have to do the rule lookup on an aggregated
+ * list of rules in all N-dimension dispatchers.
+ ***********************************************************/
+
+#define SCORE_ZONE_BITS 5 /* max. zone->depth + 1 */
+#define SCORE_SUBNET_BITS 8 /* /128 IPv6 subnet depth + 1 */
+#define SCORE_DST_IFACE_BITS 2 /* Tri-state: 2 iface match, 1 ifgroup match, 0 empty */
+#define SCORE_SRC_ADDRESS_BITS (SCORE_ZONE_BITS + SCORE_SUBNET_BITS)
+#define SCORE_DST_ADDRESS_BITS (SCORE_ZONE_BITS + SCORE_DST_IFACE_BITS + SCORE_SUBNET_BITS)
+
+/**
+ * union kz_ndim_score - structure to store rule evaluation scores
+ *
+ * NOTE: zero usually means wildcard match (ie. no restriction was
+ * specified in the rule). More specific match means higher score.
+ *
+ * FIXME: This layout depends on the particular bitfield layout GCC
+ * uses on x86 and is totally non-portable.
+ */
+typedef union kz_ndim_score {
+	struct {
+		unsigned long dst_address : SCORE_DST_ADDRESS_BITS;
+		unsigned long src_address : SCORE_SRC_ADDRESS_BITS;
+		unsigned long dst_port : 2;		/* 1: matching range, 2: specific match (range of 1 element) */
+		unsigned long src_port : 2;		/* 1: matching range, 2: specific match (range of 1 element) */
+		unsigned long proto : 1;		/* 1: protocol match */
+		unsigned long proto_type : 1;		/* 1: protocol type match */
+		unsigned long proto_subtype : 1;	/* 1: protocol type subtype match */
+		unsigned long iface : 3;		/* 1: interface group match, 2: interface match, 4: reqid match */
+	} d;
+	int64_t all;
+} kz_ndim_score;
+
+static int
+kz_ndim_eval_reqid_match(const struct kz_reqids * const reqids,
+			 const u_int32_t n_reqids, const u_int32_t * const r_reqids)
+{
+	int reqid_idx, idx;
+	if (!reqids || n_reqids == 0)
+		return 0;
+
+	for (idx = 0; idx < reqids->len; idx++) {
+		const u_int32_t reqid = reqids->vec[idx];
+		for (reqid_idx = 0; reqid_idx < n_reqids; reqid_idx++) {
+			kz_debug("comparing reqids; id='%d', r_reqid='%d'\n", reqid, r_reqids[reqid_idx]);
+			if (reqid == r_reqids[reqid_idx])
+				return 1;
+		}
+	}
+
+	return 0;
+}
+
+/**
+ * kz_ndim_eval_rule_iface - evaluate if a network interface matches a list of interface names or interface groups
+ * @n_ifaces: number of elements in the interface name array
+ * @r_ifaces: array of interface names to check
+ * @n_ifgroups: number of elements in the interface group array
+ * @r_ifgroups: array of interface group IDs to check
+ * @iface: pointer to a net_device structure -- we have to check this
+ *
+ * Returns: -1, if no matching interface name or group ID was found, or there's no interface
+ *		and @r_ifaces or @r_ifgroups is not empty
+ *	     0, if both @r_ifaces and @r_ifgroups is empty
+ *	     1, if a matching interface group ID was found
+ *	     2, if a matching interface name was found
+ */
+static int
+kz_ndim_eval_rule_iface(const u_int32_t n_reqids, const u_int32_t * const r_reqids,
+			const u_int32_t n_ifaces, ifname_t * r_ifaces,
+			const u_int32_t n_ifgroups, const u_int32_t * const r_ifgroups,
+			const struct kz_reqids * const reqids,
+			const struct net_device * const iface)
+{
+	unsigned int i;
+	int score = 0;
+
+	kz_debug("n_ifaces='%u', n_ifgroups='%u', iface='%s'\n",
+		 n_ifaces, n_ifgroups, iface ? iface->name : kz_log_null);
+
+	if (n_reqids == 0 && n_ifaces == 0 && n_ifgroups == 0)
+		return score;
+
+	if (iface == NULL)
+		return -1;
+
+	for (i = 0; i < n_ifgroups; i++) {
+		kz_debug("comparing groups; id='%u', r_id='%u'\n", iface->group, r_ifgroups[i]);
+		if (iface->group == r_ifgroups[i]) {
+			score = 1;
+			break;
+		}
+	}
+
+	for (i = 0; i < n_ifaces; i++) {
+		kz_debug("comparing names; name='%s', r_name='%s'\n", iface->name, (char *) (r_ifaces + i));
+		if (iface_name_cmp(iface->name, (char *) (r_ifaces + i))) {
+			score |= 2;
+			break;
+		}
+	}
+
+	if (kz_ndim_eval_reqid_match(reqids, n_reqids, r_reqids))
+		score |= 4;
+
+	return score ? score : -1;
+}
+
+static int
+kz_ndim_eval_rule_dst_if(const u_int32_t n_ifaces, ifname_t * r_ifaces,
+		    const u_int32_t n_ifgroups, const u_int32_t * const r_ifgroups,
+		    const struct net_device * const iface,
+		    const u_int8_t proto, const union nf_inet_addr *daddr)
+{
+	if (n_ifaces == 0 && n_ifgroups == 0)
+		return 0;
+
+	if (iface == NULL)
+		return -1;
+
+	if (match_iface_local(iface, proto, daddr))
+		return kz_ndim_eval_rule_iface(0, NULL, /* We don't have reqid for dst addresses */
+					       n_ifaces, r_ifaces,
+					       n_ifgroups, r_ifgroups,
+					       NULL, iface);
+	else
+		return -1;
+}
+
+#define KZ_NDIM_EVAL_RULE_NUMERIC_DIMENSION(dim_name, format_specifier) \
+	unsigned int i; \
+	\
+	kz_debug("n_##dim_name##s='%u', dim_name='%u'\n", n_##dim_name##s, dim_name); \
+	\
+	if (n_##dim_name##s == 0) \
+		return 0; \
+	\
+	for (i = 0; i < n_##dim_name##s; i++) { \
+		kz_debug("comparing dim_name; dim_name='%u', r_##dim_name='%u'\n", dim_name, r_##dim_name##s[i]); \
+		if (dim_name == r_##dim_name##s[i]) \
+			return 1; \
+	} \
+	\
+	return -1;
+
+/**
+ * kz_ndim_eval_rule_proto - evaluate if the protocol ID matches a list of protocols
+ * @n_protos: number of elements in the protocol ID array
+ * @r_protos: array of protocol IDs to check
+ * @proto: protocol ID to look for in the array
+ *
+ * Returns: -1, if no matching protocol ID was found
+ *	     0, if @r_protos is empty
+ *	     1, if a match was found
+ */
+static int
+kz_ndim_eval_rule_proto(const u_int32_t n_protos, const u_int8_t * const r_protos,
+			const u_int8_t proto)
+{
+	unsigned int i;
+
+	kz_debug("n_protos='%u', proto='%u'\n", n_protos, proto);
+
+	if (n_protos == 0)
+		return 0;
+
+	for (i = 0; i < n_protos; i++) {
+		kz_debug("comparing protocol; proto='%u', r_proto='%u'\n", proto, r_protos[i]);
+		if (proto == r_protos[i])
+			return 1;
+	}
+
+	return -1;
+}
+
+
+/**
+ * kz_ndim_eval_rule_proto_type - evaluate if the protocol type number matches a list of protocols
+ * @n_proto_types: number of elements in the protocol type array
+ * @r_proto_types: array of protocol types to check
+ * @proto: protocol ID to look for in the array
+ *
+ * Returns: -1, if no matching protocol ID was found
+ *	     0, if @r_proto_types is empty
+ *	     1, if a match was found
+ */
+static int
+kz_ndim_eval_rule_proto_type(const u_int32_t n_proto_types, const u_int32_t * const r_proto_types,
+			     const u_int32_t proto_type)
+{
+	KZ_NDIM_EVAL_RULE_NUMERIC_DIMENSION(proto_type, u);
+}
+
+/**
+ * kz_ndim_eval_rule_proto_subtype - evaluate if the protocol subtype number matches a list of protocols
+ * @n_proto_subtypes: number of elements in the protocol subtype array
+ * @r_proto_subtypes: array of protocol subtypes to check
+ * @proto: protocol ID to look for in the array
+ *
+ * Returns: -1, if no matching protocol ID was found
+ *	     0, if @r_proto_subtypes is empty
+ *	     1, if a match was found
+ */
+static int
+kz_ndim_eval_rule_proto_subtype(const u_int32_t n_proto_subtypes, const u_int32_t * const r_proto_subtypes,
+				const u_int32_t proto_subtype)
+{
+	KZ_NDIM_EVAL_RULE_NUMERIC_DIMENSION(proto_subtype, u);
+}
+
+
+/**
+ * kz_ndim_eval_rule_port - evaluate if a discrete port number matches a list of port ranges
+ * @n_ports: number of port ranges on the list
+ * @r_ports: array of kz_port_range structures (sorted by the 'from' field)
+ * @port: port number to match for
+ *
+ * Assumptions:
+ * @r_ports should be sorted increasingly by the 'from' field of kz_port_range
+ *
+ * Returns: -1, if no matching port range was found in @r_ports and @r_ports is not empty
+ *	     0, if @r_ports is empty
+ *	     1, if a matching range of size larger than one was found
+ *	     2, if a matching range of size one (iow. one port) was found in the list
+ */
+static int
+kz_ndim_eval_rule_port(const u_int32_t n_ports, const struct kz_port_range * const r_ports,
+		       const u_int16_t port)
+{
+	unsigned int i;
+
+	kz_debug("n_ports='%u', port='%u'\n", n_ports, port);
+
+	if (n_ports == 0)
+		return 0;
+
+	for (i = 0; i < n_ports; i++) {
+		kz_debug("comparing port range; port='%u', r_from='%u', r_to='%u'\n", port,
+			 r_ports[i].from, r_ports[i].to);
+
+		/* if port is less than 'from' we can be sure that
+		 * there's no match */
+		if (port < r_ports[i].from)
+			return -1;
+
+		if (port <= r_ports[i].to) {
+			/* match single port: 2; match in real range: 1 */
+			return (r_ports[i].from == r_ports[i].to) ? 2 : 1;
+		}
+	}
+
+	return -1;
+}
+
+#define kz_ndim_eval_rule_src_port kz_ndim_eval_rule_port
+#define kz_ndim_eval_rule_dst_port kz_ndim_eval_rule_port
+
+/**
+ * kz_ndim_eval_rule_subnet - evaluate how an IP address matches an array of subnets
+ * @n_subnets: number of IPv4 subnets in the array
+ * @r_subnets: array of kz_in_subnet structures
+ * @n_subnets6: number of IPv6 subnets in the array
+ * @r_subnets6: array of kz_in6_subnet structures
+ * @proto: protocol of the address to check
+ * @addr: the address to check
+ *
+ * Assumptions:
+ * @r_subnets and @r_subnets6 should be sorted decreasingly by the size
+ * of the subnet mask and the ip component of subnet structures should
+ * be properly masked with the mask.
+ *
+ * Returns: -1, if no matching subnet was found in @r_subnets, and @r_subnets is not empty
+ *	     0, if @r_subnets is empty
+ *           n, (n > 0) for matches, where n is the size of the subnet mask of
+ *              the matching subnet + 1
+ */
+static int
+kz_ndim_eval_rule_subnet(const u_int32_t n_subnets, const struct kz_in_subnet *const r_subnets,
+                         const u_int32_t n_subnets6, const struct kz_in6_subnet * const r_subnets6,
+                         u_int8_t proto, const union nf_inet_addr * addr)
+{
+	unsigned int i;
+
+	kz_debug("n_subnets='%u', n_subnets6='%u'\n", n_subnets, n_subnets6);
+
+	if (n_subnets == 0 && n_subnets6 == 0)
+		return 0;
+
+	switch (proto)
+	{
+	case NFPROTO_IPV4:
+		for (i = 0; i < n_subnets; i++) {
+			kz_debug("comparing subnet; ip='%pI4', network='%pI4', mask='%pI4'\n",
+				 &addr->in, &r_subnets[i].addr, &r_subnets[i].mask);
+
+			if (!ipv4_masked_addr_cmp(&addr->in, &r_subnets[i].mask, &r_subnets[i].addr))
+				return mask_to_size_v4(&r_subnets[i].mask) + 1;
+		}
+		break;
+	case NFPROTO_IPV6:
+		for (i = 0; i < n_subnets6; i++) {
+			kz_debug("comparing subnet; ip='%pI6', network='%pI6', mask='%pI6'\n",
+				 &addr->in6, &r_subnets6[i].addr, &r_subnets6[i].mask);
+
+			if (!ipv6_masked_addr_cmp(&addr->in6, &r_subnets6[i].mask, &r_subnets6[i].addr))
+				return mask_to_size_v6(&r_subnets6[i].mask) + 1;
+		}
+		break;
+	default:
+		BUG();
+	}
+	return -1;
+}
+
+/**
+ * kz_ndim_eval_rule_zone - evaluate how good a list of zones matches our zone
+ * @n_zones: number of zones in the list
+ * @r_zones: array of zone pointers containint @n_zones elements
+ * @zone: zone to check match for
+ * @mask: bitmask with the ids of accessible zones marked
+ *
+ * Assumptions:
+ * @r_zones should be sorted decreasingly by the zone depth
+ *
+ * Returns a score indicating how good a match, if any, was found for @zone in
+ * the @r_zones list. Higher scores indicate better match.
+ *
+ * Returns: -1, if no matching zone was found in @r_zones, or there's no zone specified
+ *              and @r_zones is not empty,
+ *           0, if @r_zones is empty,
+ *           n, (n > 0) for matches, where n is the depth of the matching zone in @r_zones,
+ *              the zone depth starts with 1, @see kz_zone_new in kzorp_core.c.
+ */
+static int
+kz_ndim_eval_rule_zone(const u_int32_t n_zones, struct zone_lookup_t * const r_zones,
+		        const struct kz_zone * const zone, const unsigned long *mask)
+{
+	unsigned int i;
+	int zscore = -1;
+
+	kz_debug("n_zones='%u', zone='%s'\n", n_zones, zone ? zone->unique_name : kz_log_null);
+
+	if (n_zones == 0)
+		return 0;
+
+	if (zone == NULL)
+		return -1;
+
+	for (i = 0; i < n_zones; i++) {
+		//kz_debug("comparing zone; zone='%s', r_zone='%s'\n", zone->unique_name, r_zones[i]->unique_name);
+
+		zscore = zone_score(&r_zones[i], mask);
+
+		if (zscore < 0)
+			continue;
+
+		/* Matching zone, the first match should be the most
+		 * specific since @r_zones is ordered on the zone
+		 * depth. Stop iterating the list.
+		 */
+		break;
+	}
+
+	return zscore;
+}
+
+/**
+ * kz_ndim_eval_rule_address - evaluate all address related dimensions (subnets and zones)
+ * @n_subnets: number of IPv4 subnets in the array
+ * @r_subnets: array of kz_in_subnet structures
+ * @n_subnets6: number of IPv6 subnets in the array
+ * @r_subnets6: array of kz_in6_subnet structures
+ * @n_zones: number of zones in the list
+ * @r_zones: array of zone pointers containint @n_zones elements
+ * @proto: protocol of the address to check
+ * @addr: the address to check
+ * @zone: zone to check match for
+ * @mask: bitmask with the ids of accessible zones marked
+ *
+ * Assumptions:
+ * @r_subnets and @r_subnets6 should be sorted decreasingly by the size
+ * of the subnet mask and the ip component of subnet structures should
+ * be properly masked with the mask.
+ * @r_zones should be sorted decreasingly by the zone depth
+ *
+ * Returns a score indicating how good a match, if any, was found for
+ * the address related dimensions.
+ *
+ * Evaluates the dimensions in the following order: subnet, zone.  If
+ * no subnet match is found the zone dimension is evaluated.
+ *
+ * Returns: -1, if no match was found
+ *           0, if both the subnets and zone dimensions are empty
+ *           n, (n > 0) for matches, where n is the aggregated score from the subnet and
+ *              zone evaluation
+ */
+
+static int
+kz_ndim_eval_rule_address(const u_int32_t n_subnets, const struct kz_in_subnet * const r_subnets,
+			   const u_int32_t n_subnets6, const struct kz_in6_subnet * const r_subnets6,
+			   const u_int32_t n_zones, struct zone_lookup_t * const r_zones,
+			   u_int8_t proto, const union nf_inet_addr *addr,
+			   const struct kz_zone * const zone, const unsigned long *mask)
+{
+	int score = 0;
+	int subnet_score = kz_ndim_eval_rule_subnet(n_subnets, r_subnets, n_subnets6, r_subnets6, proto, addr);
+	int zone_score = kz_ndim_eval_rule_zone(n_zones, r_zones, zone, mask);
+
+	if (subnet_score > 0)
+		score = subnet_score << SCORE_ZONE_BITS;
+
+	if (zone_score > 0)
+		score |= zone_score;
+
+	return (score == 0 && (subnet_score < 0 || zone_score < 0)) ? -1 : score;
+}
+
+static int
+kz_ndim_eval_rule_dst(const u_int32_t n_subnets, const struct kz_in_subnet * const r_subnets,
+		      const u_int32_t n_subnets6, const struct kz_in6_subnet * const r_subnets6,
+		      const u_int32_t n_zones, struct zone_lookup_t * const r_zones,
+		      const u_int32_t n_ifaces, ifname_t * r_ifaces,
+		      const u_int32_t n_ifgroups, const u_int32_t * const r_ifgroups,
+		      const struct net_device * const iface,
+		      u_int8_t proto, const union nf_inet_addr *addr,
+		      const struct kz_zone * const zone, const unsigned long *mask)
+{
+	int score = 0;
+	int subnet_score = kz_ndim_eval_rule_subnet(n_subnets, r_subnets, n_subnets6, r_subnets6, proto, addr);
+	int iface_score = kz_ndim_eval_rule_dst_if(n_ifaces, r_ifaces, n_ifgroups, r_ifgroups, iface, proto, addr);
+	int zone_score = kz_ndim_eval_rule_zone(n_zones, r_zones, zone, mask);
+
+	if (subnet_score > 0)
+		score = subnet_score << (SCORE_ZONE_BITS + SCORE_DST_IFACE_BITS);
+
+	if (iface_score > 0)
+		score |= iface_score << SCORE_ZONE_BITS;
+
+	if (zone_score > 0)
+		score |= zone_score;
+
+	return (score == 0 && (subnet_score < 0 || iface_score < 0 || zone_score < 0)) ? -1 : score;
+}
+
+
+#define EVAL_DIM_RES(name)					\
+	if (dim_res < 0)					\
+		return -1;					\
+	res.d.name = (unsigned) dim_res;			\
+	if (equal) {						\
+		if ((unsigned) dim_res < best.d.name)		\
+			return -1;				\
+		else if ((unsigned) dim_res > best.d.name)	\
+			equal = false;				\
+	}
+
+#define EVAL_DIM(name)							\
+	dim_res = rule->num_##name ? kz_ndim_eval_rule_##name(rule->num_##name, rule->name, name) : 0; \
+	EVAL_DIM_RES(name);
+
+/* structs used for lookup data to encode dimensions */
+
+KZ_PROTECTED struct kz_rule_lookup_data*
+kz_rule_lookup_cursor_next_rule(struct kz_rule_lookup_cursor *cursor)
+{
+	if (cursor->rule->bytes_to_next == 0)
+		return NULL;
+
+	cursor->rule = (void*)(cursor->rule) + cursor->rule->bytes_to_next;
+	cursor->pos = sizeof(struct kz_rule_lookup_data);
+	return cursor->rule;
+}
+
+#define DEFINE_LOOKUP_DATA_TYPE(DIM_NAME, _, __, ___, LOOKUP_TYPE, ...) \
+	typedef struct { \
+		u_int32_t num; \
+		LOOKUP_TYPE data[]; \
+	} DIM_NAME##_dim_lookup_data
+
+KZORP_DIM_LIST(DEFINE_LOOKUP_DATA_TYPE, ;);
+
+#undef DEF_LOOKUP_DATA_TYPE
+
+#define SIZEOF_STRUCT_MEMBER(STRUCT, MEMBER) (sizeof((STRUCT *)0)->MEMBER)
+#define PAD(value, n) (((value - 1) | (n-1)) + 1)
+
+/* returns the size of a NAME_lookup_data struct filled with COUNT elements,
+ * padded to 4 bytes */
+#define LOOKUP_DATA_SIZE(NAME, COUNT) PAD(SIZEOF_STRUCT_MEMBER(NAME##_dim_lookup_data, num) + COUNT * SIZEOF_STRUCT_MEMBER(NAME##_dim_lookup_data, data[0]), 4)
+#define LOOKUP_DATA_SIZE_OPTIONAL(NAME, COUNT) (COUNT ? LOOKUP_DATA_SIZE(NAME, COUNT) : 0)
+
+/* Each value represents a bit in the bitmap used in lookup data structure.
+ * Order must be the same as the order in which dimensions are fetched from
+ * lookup data. */
+enum KZORP_DIMENSIONS {
+#define KZORP_DIM_ENUM(DIM_NAME, ...) KZORP_DIM_##DIM_NAME
+
+	KZORP_DIM_LIST(KZORP_DIM_ENUM, KZORP_COMMA_SEPARATOR)
+
+#undef KZORP_DIM_ENUM
+};
+
+#define GENERATE_DIM_COPY_IFNAME(dst, src) memcpy(dst, src, IFNAMSIZ)
+#define GENERATE_DIM_COPY_ZONE(dst, src) dst.index = src->index; dst.depth = src->depth;
+#define GENERATE_DIM_ASSIGN_VALUE(dst, src) dst = src
+
+#define GENERATE_DIM_WITH_COPY_FUNCTOR(map, name, copy_functor) \
+	do { \
+		if (!!rule->num_##name) { \
+			int i; \
+			name##_dim_lookup_data *d = pos; \
+			pos += LOOKUP_DATA_SIZE(name, rule->num_##name); \
+			map = map | (1 << KZORP_DIM_##name); \
+			d->num = rule->num_##name; \
+			for (i = 0; i < d->num; ++i) { \
+				copy_functor(d->data[i], rule->name[i]); \
+			} \
+		} \
+	} while (0);
+
+#define generate_dim_value(map, name) GENERATE_DIM_WITH_COPY_FUNCTOR(map, name, GENERATE_DIM_ASSIGN_VALUE)
+#define generate_dim_ifname(map, name) GENERATE_DIM_WITH_COPY_FUNCTOR(map, name, GENERATE_DIM_COPY_IFNAME)
+#define generate_dim_string(map, name) GENERATE_DIM_WITH_COPY_FUNCTOR(map, name, GENERATE_DIM_COPY_ZONE)
+#define generate_dim_in_subnet generate_dim_value
+#define generate_dim_in6_subnet generate_dim_value
+#define generate_dim_portrange generate_dim_value
+
+KZ_PROTECTED size_t
+kz_generate_lookup_data_rule_size(const struct kz_dispatcher_n_dimension_rule * const rule)
+{
+	size_t rule_size = sizeof(struct kz_rule_lookup_data);
+
+#define CALL_LOOKUP_DATA_SIZE_OPTIONAL(DIM_NAME, ...) \
+	(LOOKUP_DATA_SIZE_OPTIONAL(DIM_NAME, rule->num_##DIM_NAME))
+
+	rule_size += KZORP_DIM_LIST(CALL_LOOKUP_DATA_SIZE_OPTIONAL, +);
+
+#undef CALL_LOOKUP_DATA_SIZE_OPTIONAL
+
+	return PAD(rule_size, 8);
+}
+
+KZ_PROTECTED struct kz_rule_lookup_data *
+kz_generate_lookup_data_rule(const struct kz_dispatcher_n_dimension_rule * const rule, void *buf)
+{
+	void *pos = buf;
+	int map = 0;
+	struct kz_rule_lookup_data *current_rule = buf;
+
+	pos += sizeof(struct kz_rule_lookup_data);
+	current_rule->orig = rule;
+
+#define CALL_kz_generate_lookup_rule_dim(DIM_NAME, NL_ATTR_NAME, _, NL_TYPE, ...) \
+	generate_dim_##NL_TYPE(map, DIM_NAME)
+
+	KZORP_DIM_LIST(CALL_kz_generate_lookup_rule_dim, ;);
+
+#undef CALL_kz_generate_lookup_rule_dim
+
+	pos = (void*)PAD((int64_t)pos, 8);
+	current_rule->dimension_map = map;
+	current_rule->bytes_to_next = pos - buf;
+	current_rule = pos;
+	return buf;
+}
+
+KZ_PROTECTED void
+kz_generate_lookup_data(struct kz_head_d *dispatchers)
+{
+	struct kz_dispatcher *dispatcher;
+	struct kz_rule_lookup_data *lookup_data, *current_rule, *prev_rule = NULL;
+	void *pos;
+	u_int32_t rules_data_size = 0;
+
+	/* First pass calculates total size */
+        list_for_each_entry(dispatcher, &dispatchers->head, list) {
+		unsigned int rule_idx;
+		for (rule_idx = 0; rule_idx < dispatcher->num_rule; rule_idx++) {
+			rules_data_size += kz_generate_lookup_data_rule_size(&dispatcher->rule[rule_idx]);
+		}
+	}
+
+	if (rules_data_size > 0) {
+		pos = current_rule = lookup_data = kz_big_alloc(rules_data_size, &dispatchers->lookup_data_allocator);
+
+		/* Second pass builds up the lookup data */
+		list_for_each_entry(dispatcher, &dispatchers->head, list) {
+			unsigned int rule_idx;
+			for (rule_idx = 0; rule_idx < dispatcher->num_rule; rule_idx++) {
+				prev_rule = current_rule;
+				current_rule = kz_generate_lookup_data_rule(&dispatcher->rule[rule_idx], pos);
+				pos += current_rule->bytes_to_next;
+			}
+		}
+
+		if (current_rule)
+			current_rule->bytes_to_next = 0;
+
+		dispatchers->lookup_data = lookup_data;
+	}
+}
+
+#define RULE_LOOKUP_GET_TYPE(dimension_name, out_num, out_data) \
+	do { \
+		int dimension_bit = 1 << KZORP_DIM_##dimension_name; \
+		*out_num = 0; \
+		*out_data = NULL; \
+		if ((cursor->rule->dimension_map & dimension_bit)) \
+		{ \
+			dimension_name##_dim_lookup_data *s = (void*)cursor->rule + cursor_pos; \
+			*out_num = s->num; \
+			*out_data = s->data; \
+			cursor_pos += LOOKUP_DATA_SIZE(dimension_name, s->num); \
+		} \
+	} while (0);
+
+/* Assumes a cursor, a num_NAME and a data_NAME variable */
+#define RULE_FETCH_DIM(name) RULE_LOOKUP_GET_TYPE(name, &num_##name, &data_##name)
+
+#define EVAL_DIM_LOOKUP(NAME) \
+	do { \
+		u_int32_t num_##NAME; \
+		void *data_##NAME; \
+                RULE_LOOKUP_GET_TYPE(NAME, &num_##NAME, &data_##NAME); \
+		dim_res = num_##NAME ? kz_ndim_eval_rule_##NAME(num_##NAME, data_##NAME, traffic_props->NAME) : 0; \
+		EVAL_DIM_RES(NAME); \
+	} while (0);
+
+KZ_PROTECTED int64_t
+kz_ndim_eval_rule(struct kz_rule_lookup_cursor * cursor,
+		  int64_t best_all,
+		  const struct kz_traffic_props * const traffic_props,
+		  const unsigned long *src_zone_mask,
+		  const unsigned long *dst_zone_mask)
+{
+	kz_ndim_score best, res;
+	bool equal = true;
+	int dim_res;
+	u_int32_t cursor_pos = cursor->pos;
+
+	/*kz_debug("evaluating rule; id='%u'\n", rule->id);*/
+
+	best.all = best_all;
+	res.all = 0;
+
+	{
+		u_int32_t num_reqid, num_ifname, num_ifgroup;
+		u_int32_t *data_reqid;
+		ifname_t *data_ifname;
+		u_int32_t *data_ifgroup;
+
+		RULE_FETCH_DIM(reqid);
+		RULE_FETCH_DIM(ifname);
+		RULE_FETCH_DIM(ifgroup);
+		dim_res = kz_ndim_eval_rule_iface(num_reqid, data_reqid,
+						  num_ifname, data_ifname,
+						  num_ifgroup, data_ifgroup,
+						  traffic_props->reqids, traffic_props->iface);
+		EVAL_DIM_RES(iface);
+	}
+
+	EVAL_DIM_LOOKUP(proto);
+	EVAL_DIM_LOOKUP(proto_type);
+	EVAL_DIM_LOOKUP(proto_subtype);
+	EVAL_DIM_LOOKUP(src_port);
+	EVAL_DIM_LOOKUP(dst_port);
+
+	{
+	/* source address */
+		u_int32_t num_src_in_subnet, num_src_in6_subnet, num_src_zone;
+		struct kz_in_subnet *data_src_in_subnet;
+		struct kz_in6_subnet *data_src_in6_subnet;
+		struct zone_lookup_t *data_src_zone;
+		RULE_FETCH_DIM(src_in_subnet);
+		RULE_FETCH_DIM(src_in6_subnet);
+		RULE_FETCH_DIM(src_zone);
+
+		dim_res = kz_ndim_eval_rule_address(num_src_in_subnet, data_src_in_subnet,
+						     num_src_in6_subnet, data_src_in6_subnet,
+						     num_src_zone, data_src_zone,
+						     traffic_props->l3proto,
+						     traffic_props->src_addr,
+						     traffic_props->src_zone, src_zone_mask);
+		EVAL_DIM_RES(src_address);
+	}
+
+	{
+		/* destination interface/address */
+		u_int32_t num_dst_in_subnet, num_dst_in6_subnet, num_dst_zone, num_dst_ifname, num_dst_ifgroup;
+		struct kz_in_subnet *data_dst_in_subnet;
+		struct kz_in6_subnet *data_dst_in6_subnet;
+		struct zone_lookup_t *data_dst_zone;
+		ifname_t *data_dst_ifname;
+		u_int32_t *data_dst_ifgroup;
+		RULE_FETCH_DIM(dst_in_subnet);
+		RULE_FETCH_DIM(dst_in6_subnet);
+		RULE_FETCH_DIM(dst_ifname);
+		RULE_FETCH_DIM(dst_ifgroup);
+		RULE_FETCH_DIM(dst_zone);
+
+		dim_res = kz_ndim_eval_rule_dst(num_dst_in_subnet, data_dst_in_subnet,
+						 num_dst_in6_subnet, data_dst_in6_subnet,
+						 num_dst_zone, data_dst_zone,
+						 num_dst_ifname, data_dst_ifname,
+						 num_dst_ifgroup, data_dst_ifgroup,
+						 traffic_props->iface,
+						 traffic_props->l3proto,
+						 traffic_props->dst_addr,
+						 traffic_props->dst_zone, dst_zone_mask);
+		EVAL_DIM_RES(dst_address);
+	}
+
+	cursor->pos = cursor_pos;
+	return res.all;
+}
+
+/**
+ * kz_adjust_zone - return configured zone for any zone
+ * @zone: zone to check
+ *
+ * Returns the parent zone if the zone was generated by Zorp because
+ * of multiple subnets configured by the user; or @zone if it's not a
+ * pseudo-zone.
+ */
+static inline const struct kz_zone *
+kz_adjust_zone(const struct kz_zone *zone)
+{
+	if (zone && zone->name != zone->unique_name)
+		zone = zone->admin_parent;
+
+	return zone;
+}
+
+KZ_PROTECTED u_int32_t
+kz_ndim_eval(const struct kz_traffic_props * const traffic_props,
+	     const struct kz_head_d * const dispatchers,
+	     struct kz_percpu_env *lenv)
+{
+	kz_ndim_score best;
+	const size_t max_out_idx = lenv->max_result_size;
+	size_t out_idx = 0;
+	struct kz_rule_lookup_cursor cursor;
+	struct kz_rule_lookup_data *rule;
+	const struct kz_zone * src_zone = traffic_props->src_zone;
+	const struct kz_zone * dst_zone = traffic_props->dst_zone;
+
+	BUG_ON(!lenv);
+	BUG_ON(!lenv->max_result_size);
+	BUG_ON(!lenv->result_rules);
+
+	if (!dispatchers || list_empty(&dispatchers->head)) {
+		kz_debug("no dispatchers to evaluate\n");
+		lenv->result_size = 0;
+		return 0;
+	}
+
+	src_zone = kz_adjust_zone(src_zone);
+	dst_zone = kz_adjust_zone(dst_zone);
+
+	/* set up helper bitmaps */
+	mark_zone_path(lenv->src_mask, src_zone);
+	mark_zone_path(lenv->dst_mask, dst_zone);
+
+	best.all = 0;
+
+	cursor.rule = dispatchers->lookup_data;
+	cursor.pos = sizeof(struct kz_rule_lookup_data);
+	rule = dispatchers->lookup_data;
+
+	while (rule) {
+		int64_t score;
+		prefetch(rule->bytes_to_next + (void*)rule);
+		score = kz_ndim_eval_rule(&cursor, best.all,
+					  traffic_props,
+					  lenv->src_mask, lenv->dst_mask);
+
+		if (score == -1 || best.all > score) {
+			/* no match or worse than the current best */
+			rule = kz_rule_lookup_cursor_next_rule(&cursor);
+			continue;
+		} else if (best.all < score) {
+			/* better match, so reset result list */
+			kz_debug("reset result list\n");
+			out_idx = 0;
+			best.all = score;
+		}
+		if (out_idx < max_out_idx) {
+			kz_debug("appending rule to result list; id='%u', score='%llu'\n", rule->orig->id, score);
+			lenv->result_rules[out_idx] = rule->orig;
+		}
+		rule = kz_rule_lookup_cursor_next_rule(&cursor);
+
+		out_idx++;
+	}
+
+	/* clean up helpers */
+	unmark_zone_path(lenv->src_mask, src_zone);
+	unmark_zone_path(lenv->dst_mask, dst_zone);
+
+	kz_debug("out_idx='%zu'\n", out_idx);
+
+	return lenv->result_size = out_idx;
+}
+
+/**
+ * kz_ndim_lookup -- look up service for a session by evaluating n-dimensional rules
+ * @iface: input interface
+ * @l3proto: L3 protocol number (IPv4/IPv6)
+ * @src_addr: source address
+ * @dst_addr: destination address
+ * @l4proto: L4 protocol number (TCP/UDP/etc.)
+ * @src_port: source TCP/UDP port (if meaningful for @proto)
+ * @dst_port: destination TCP/UDP port (if meaningful for @proto)
+ * @src_zone: the zone @src_addr belongs to
+ * @dst_zone: the zone @dst_addr belongs to
+ * @dispatcher: pointer to a kz_dispatcher pointer to return the dispatcher in (OUTPUT)
+ *
+ * Evaluate our n-dimensional rules in all dispatchers and return the
+ * resulting service as a result. If no matching rule was found or
+ * there were more than one matching rule, we return NULL.
+ */
+static struct kz_service *
+kz_ndim_lookup(const struct kz_config *cfg,
+	       const struct kz_traffic_props * const traffic_props,
+	       struct kz_dispatcher **dispatcher)
+{
+	struct kz_percpu_env *lenv;
+	const struct kz_head_d * const d = &cfg->dispatchers;
+	struct kz_service *service = NULL;
+	u_int32_t num_results;
+
+	kz_debug("src_zone='%s', dst_zone='%s'\n",
+		 traffic_props->src_zone ? traffic_props->src_zone->unique_name : kz_log_null,
+		 traffic_props->dst_zone ? traffic_props->dst_zone->unique_name : kz_log_null);
+
+	preempt_disable();
+	lenv = __get_cpu_var(kz_percpu);
+
+	num_results = kz_ndim_eval(traffic_props, d, lenv);
+
+	kz_debug("num_results='%u'\n", num_results);
+
+	if (num_results == 1) {
+		service = lenv->result_rules[0]->service;
+		*dispatcher = lenv->result_rules[0]->dispatcher;
+
+		kz_debug("found service; dispatcher='%s', rule_id='%u', name='%s'\n",
+			 lenv->result_rules[0]->dispatcher->name,
+			 lenv->result_rules[0]->id,
+			 service ? service->name : kz_log_null);
+	}
+
+	preempt_enable();
+
+	kz_debug("service='%s'\n", service ? service->name : "null");
+
+	return service;
+}
+
+/***********************************************************
+ * IPv4 zone lookup
+ ***********************************************************/
+
+static inline unsigned int
+zone_ipv4_hash_fn(const u_int32_t prefix)
+{
+	return jhash_1word(prefix, 0) % KZ_ZONE_HASH_SIZE;
+}
+
+static inline bool
+zone_ipv4_cmp(const struct kz_zone * const z, const u_int32_t _mask)
+{
+	struct in_addr mask = { htonl(_mask) };
+	return !ipv4_masked_addr_cmp(&z->addr.in, &z->mask.in, &mask);
+}
+
+static inline unsigned int
+zone_ipv4_hash_fn_z(const struct kz_zone * const z)
+{
+	return zone_ipv4_hash_fn(ntohl(z->addr.in.s_addr) & ntohl(z->mask.in.s_addr));
+}
+
+static inline unsigned int
+zone_ipv4_mask_bits(const struct kz_zone * const z)
+{
+	return mask_to_size_v4(&z->mask.in);
+}
+
+static inline void
+zone_ipv4_hash(struct kz_head_z *h, struct kz_zone *z)
+{
+	const unsigned int b = zone_ipv4_mask_bits(z);
+	const unsigned int v = zone_ipv4_hash_fn_z(z);
+
+	kz_debug("mask='%pI4', order='%d', bucket='%d'\n", &z->mask.in, b, v);
+
+	hlist_add_head(&z->hlist, &h->luzone.hash[b][v]);
+}
+
+static inline void
+zone_ipv4_unhash(struct kz_zone *z)
+{
+	if (!hlist_unhashed(&z->hlist))
+		hlist_del(&z->hlist);
+}
+
+struct kz_zone *
+kz_head_zone_ipv4_lookup(const struct kz_head_z *h, const struct in_addr * const addr)
+{
+	int o;
+	u_int32_t m, ip;
+
+	kz_debug("addr='%pI4'\n", addr);
+
+        ip = ntohl(addr->s_addr);
+	for (o = 32, m = 0xffffffff; o >= 0; o--, m <<= 1) {
+		struct kz_zone *i;
+		struct hlist_node *n;
+		const u_int32_t p = ip & m;
+		const unsigned int v = zone_ipv4_hash_fn(p);
+
+		if (!hlist_empty(&h->luzone.hash[o][v])) {
+			hlist_for_each_entry(i, n, &h->luzone.hash[o][v], hlist) {
+				if (zone_ipv4_cmp(i, p)) {
+					kz_debug("found zone; name='%s'\n", i->name);
+					return i;
+				}
+			}
+		}
+	}
+
+	return NULL;
+}
+EXPORT_SYMBOL_GPL(kz_head_zone_ipv4_lookup);
+
+/***********************************************************
+ * IPv6 zone lookup
+ ***********************************************************/
+
+#ifndef KZ_USERSPACE
+KZ_PROTECTED inline struct kz_lookup_ipv6_node *
+ipv6_node_new(void)
+{
+	return kzalloc(sizeof(struct kz_lookup_ipv6_node), GFP_KERNEL);
+}
+
+KZ_PROTECTED inline void
+ipv6_node_free(struct kz_lookup_ipv6_node *n)
+{
+	kfree(n);
+}
+#endif
+
+static inline __be32
+ipv6_addr_bit_set(const void *token, int bit)
+{
+	const __be32 *addr = token;
+
+	return htonl(1 << ((~bit) & 0x1F)) & addr[bit >> 5];
+}
+
+struct kz_lookup_ipv6_node *
+ipv6_add(struct kz_lookup_ipv6_node *root, struct in6_addr *addr, int prefix_len)
+{
+	struct kz_lookup_ipv6_node *n, *parent, *leaf, *intermediate;
+	__be32 dir = 0;
+	int prefix_match_len;
+
+	n = root;
+
+	do {
+		/* prefix is different */
+		if (prefix_len < n->prefix_len ||
+		    !ipv6_prefix_equal(&n->addr, addr, n->prefix_len))
+			goto insert_above;
+
+		/* prefix is the same */
+		if (prefix_len == n->prefix_len)
+			return n;
+
+		/* more bits to go */
+		dir = ipv6_addr_bit_set(addr, n->prefix_len);
+		parent = n;
+		n = dir ? n->right : n->left;
+	} while (n);
+
+	/* add a new leaf node */
+	leaf = ipv6_node_new();
+	if (leaf == NULL)
+		return NULL;
+
+	leaf->prefix_len = prefix_len;
+	leaf->parent = parent;
+	ipv6_addr_copy(&leaf->addr, addr);
+
+	if (dir)
+		parent->right = leaf;
+	else
+		parent->left = leaf;
+
+	return leaf;
+
+insert_above:
+	/* split node, since we have a new key with shorter or different prefix */
+	parent = n->parent;
+
+	prefix_match_len = __ipv6_addr_diff(addr, &n->addr, sizeof(*addr));
+
+	if (prefix_len > prefix_match_len) {
+		/*
+		 *	   +----------------+
+		 *	   |  intermediate  |
+		 *	   +----------------+
+		 *	      /	       	  \
+		 * +--------------+  +--------------+
+		 * |   new leaf	  |  |   old node   |
+		 * +--------------+  +--------------+
+		 */
+		intermediate = ipv6_node_new();
+		leaf = ipv6_node_new();
+		if (leaf == NULL || intermediate == NULL) {
+			if (leaf)
+				ipv6_node_free(leaf);
+			if (intermediate)
+				ipv6_node_free(intermediate);
+			return NULL;
+		}
+
+		intermediate->prefix_len = prefix_match_len;
+		ipv6_addr_copy(&intermediate->addr, addr);
+
+		if (dir)
+			parent->right = intermediate;
+		else
+			parent->left = intermediate;
+
+		leaf->prefix_len = prefix_len;
+		ipv6_addr_copy(&leaf->addr, addr);
+
+		intermediate->parent = parent;
+		leaf->parent = intermediate;
+		n->parent = intermediate;
+
+		if (ipv6_addr_bit_set(&n->addr, prefix_match_len)) {
+			intermediate->right = n;
+			intermediate->left = leaf;
+		} else {
+			intermediate->right = leaf;
+			intermediate->left = n;
+		}
+	} else {
+		/* prefix_len <= prefix_match_len
+		 *
+		 *	 +-------------------+
+		 *	 |     new leaf      |
+		 *	 +-------------------+
+		 *	    /  	       	  \
+		 * +--------------+  +--------------+
+		 * |   old node   |  |     NULL     |
+		 * +--------------+  +--------------+
+		 */
+		leaf = ipv6_node_new();
+		if (leaf == NULL)
+			return NULL;
+
+		leaf->prefix_len = prefix_len;
+		leaf->parent = parent;
+		ipv6_addr_copy(&leaf->addr, addr);
+
+		if (dir)
+			parent->right = leaf;
+		else
+			parent->left = leaf;
+
+		if (ipv6_addr_bit_set(&n->addr, prefix_len))
+			leaf->right = n;
+		else
+			leaf->left = n;
+
+		n->parent = leaf;
+	}
+
+	return leaf;
+}
+
+KZ_PROTECTED struct kz_lookup_ipv6_node *
+ipv6_lookup(struct kz_lookup_ipv6_node *root, const struct in6_addr *addr)
+{
+	struct kz_lookup_ipv6_node *n = root;
+	__be32 dir;
+
+	/* first, descend to a possibly matching node */
+
+	for (;;) {
+		struct kz_lookup_ipv6_node *next;
+
+		dir = ipv6_addr_bit_set(addr, n->prefix_len);
+
+		next = dir ? n->right : n->left;
+
+		if (next) {
+			n = next;
+			continue;
+		}
+
+		break;
+	}
+
+	/* we're at a node that has a possibility to match: go up the
+	 * tree until we find something that is matching exactly */
+
+	while (n) {
+		if (n->zone) {
+			/* this is not an intermediate node, but a
+			 * real one with data associated with it */
+			if (ipv6_prefix_equal(&n->addr, addr, n->prefix_len))
+				return n;
+		}
+
+		n = n->parent;
+	}
+
+	return NULL;
+}
+
+KZ_PROTECTED void
+ipv6_destroy(struct kz_lookup_ipv6_node *node)
+{
+	if (node->left)
+		ipv6_destroy(node->left);
+
+	if (node->right)
+		ipv6_destroy(node->right);
+
+	ipv6_node_free(node);
+}
+
+static int
+zone_ipv6_tree_add(struct kz_head_z *h, struct kz_zone *z)
+{
+	struct kz_lookup_ipv6_node *node;
+	const unsigned int prefix_len = mask_to_size_v6(&z->mask.in6);
+
+	kz_debug("adding zone to radix tree; name='%s', address='%pI6', mask='%pI6', prefix_len='%u'\n", z->name, &z->addr.in6, &z->mask.in6, prefix_len);
+
+        node = ipv6_add(h->luzone.root, &z->addr.in6, prefix_len);
+	if (node == NULL) {
+		kz_err("error allocating node structure\n");
+		return -ENOMEM;
+	}
+
+	if (node->zone != NULL) {
+		kz_err("duplicate subnet detected; zone1='%s', zone2='%s'\n", z->name, node->zone->name);
+		return -EEXIST;
+	}
+
+	node->zone = z;
+
+	return 0;
+}
+
+struct kz_zone *
+kz_head_zone_ipv6_lookup(const struct kz_head_z *h, const struct in6_addr * const addr)
+{
+	struct kz_lookup_ipv6_node *node;
+
+	kz_debug("addr='%pI6'\n", addr);
+
+	node = ipv6_lookup(h->luzone.root, addr);
+	if (node == NULL)
+		return NULL;
+
+	/* if ipv6_lookup() returns with an intermediate node we're in
+	 * big trouble, because that means that the lookup algorithm
+	 * is broken */
+	WARN_ON(node->zone == NULL);
+
+	return node->zone;
+}
+
+/***********************************************************
+ * Generic zones
+ ***********************************************************/
+
+/**
+ * kz_head_zone_init - initialize zone lookup data structures to an empty state
+ * @h: head to set up
+ */
+void
+kz_head_zone_init(struct kz_head_z *h)
+{
+	unsigned int i, j;
+
+	for (i = 0; i < 33; i++)
+		for (j = 0; j < KZ_ZONE_HASH_SIZE; j++)
+			INIT_HLIST_HEAD(&h->luzone.hash[i][j]);
+	h->luzone.root = ipv6_node_new();
+}
+EXPORT_SYMBOL_GPL(kz_head_zone_init);
+
+/**
+ * kz_head_zone_build - build zone lookup data structures
+ */
+int
+kz_head_zone_build(struct kz_head_z *h)
+{
+	struct kz_zone *i;
+	int res;
+	unsigned int index = 0;
+
+	/* we do not get an extra ref for the lookup structure: the
+	 * zone is on the linked list of the head anyway and there's
+	 * no way of releasing that without the lookup structures
+	 * being destroyed first */
+
+	list_for_each_entry(i, &h->head, list) {
+		/* put in hash if the zone has a range */
+		if (i->flags & KZF_ZONE_HAS_RANGE) {
+
+			switch (i->family) {
+			case AF_INET:
+				zone_ipv4_hash(h, i);
+				break;
+
+			case AF_INET6:
+				if ((res = zone_ipv6_tree_add(h, i)) < 0)
+					return res;
+				break;
+
+			default:
+				BUG();
+				break;
+			}
+		}
+		/* assign bitmask index */
+		i->index = index++;
+	}
+
+	if (index > KZ_ZONE_MAX) {
+		kz_err("maximum number of zones exceeded; supported='%d', present='%d'\n",
+		       KZ_ZONE_MAX, index);
+		return -EINVAL;
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(kz_head_zone_build);
+
+void
+kz_head_zone_destroy(struct kz_head_z *h)
+{
+	struct kz_zone *i;
+
+	if (h->luzone.root != NULL) {
+		ipv6_destroy(h->luzone.root);
+		h->luzone.root = NULL;
+	}
+
+	list_for_each_entry(i, &h->head, list) {
+		if (i->flags & KZF_ZONE_HAS_RANGE) {
+
+			switch (i->family) {
+			case AF_INET:
+				zone_ipv4_unhash(i);
+				break;
+			case AF_INET6:
+				/* IPv6 lookup structure has already
+				 * been destroyed */
+				break;
+			default:
+				BUG();
+			}
+		}
+	}
+}
+EXPORT_SYMBOL_GPL(kz_head_zone_destroy);
+
+/***********************************************************
+ * Per-instance bind addresses
+ ***********************************************************/
+
+/**
+ * bind_lookup_new() - allocate and initialize a new bind lookup structure
+ */
+static struct kz_bind_lookup *
+bind_lookup_new(void)
+{
+	struct kz_bind_lookup *bind_lookup;
+
+	bind_lookup = kzalloc(sizeof(struct kz_bind_lookup), GFP_KERNEL);
+	if (bind_lookup == NULL)
+		return NULL;
+
+	INIT_LIST_HEAD(&bind_lookup->list_bind);
+
+	return bind_lookup;
+}
+
+static void
+bind_lookup_destroy(struct kz_bind_lookup *bind_lookup)
+{
+	struct kz_bind *pos_bind, *n_bind;
+
+	list_for_each_entry_safe(pos_bind, n_bind, &bind_lookup->list_bind, list) {
+		list_del(&pos_bind->list);
+		kz_bind_destroy(pos_bind);
+	}
+
+	if (bind_lookup->binds)
+		kfree(bind_lookup->binds);
+
+	kfree(bind_lookup);
+}
+
+/**
+ * bind_lookup_get_l3proto() - convert L3 protocol to lookup index
+ * @l3proto: layer 3 protocol (IPv4 or IPv6)
+ * Returns: enum value matching @l3proto
+ */
+static enum kz_bind_l3proto
+bind_lookup_get_l3proto(const u8 l3proto)
+{
+	switch (l3proto) {
+	case AF_INET:
+		return KZ_BIND_L3PROTO_IPV4;
+		break;
+	case AF_INET6:
+		return KZ_BIND_L3PROTO_IPV6;
+		break;
+	default:
+		break;
+	}
+
+	BUG();
+}
+
+/**
+ * bind_lookup_get_l4proto() - convert L4 protocol to lookup index
+ * @l4proto: layer 4 protocol (TCP or UDP)
+ * Returns: enum value matching @l4proto
+ */
+static enum kz_bind_l4proto
+bind_lookup_get_l4proto(const u8 l4proto)
+{
+	switch (l4proto) {
+	case IPPROTO_TCP:
+		return KZ_BIND_L4PROTO_TCP;
+		break;
+	case IPPROTO_UDP:
+		return KZ_BIND_L4PROTO_UDP;
+		break;
+	default:
+		break;
+	}
+
+	BUG();
+}
+
+static void
+bind_lookup_build(struct kz_bind_lookup *bind_lookup)
+{
+	const struct kz_bind const *bind;
+	unsigned int num_binds;
+	enum kz_bind_l3proto l3proto;
+	enum kz_bind_l4proto l4proto;
+        unsigned int filled_bind_nums[KZ_BIND_L3PROTO_COUNT][KZ_BIND_L4PROTO_COUNT] = { { 0, 0 }, { 0, 0 } };
+
+	num_binds = 0;
+	list_for_each_entry(bind, &bind_lookup->list_bind, list) {
+		l3proto = bind_lookup_get_l3proto(bind->family);
+		l4proto = bind_lookup_get_l4proto(bind->proto);
+
+		bind_lookup->bind_nums[l3proto][l4proto]++;
+		num_binds++;
+	}
+
+	if (num_binds == 0)
+		return;
+
+	bind_lookup->binds = (const struct kz_bind const **) kzalloc(sizeof(struct kz_bind *) * num_binds, GFP_KERNEL);
+	num_binds = 0;
+	for (l3proto = KZ_BIND_L3PROTO_IPV4; l3proto < KZ_BIND_L3PROTO_COUNT; l3proto++) {
+		for (l4proto = KZ_BIND_L4PROTO_TCP; l4proto < KZ_BIND_L4PROTO_COUNT; l4proto++) {
+			bind_lookup->binds_by_type[l3proto][l4proto] = &bind_lookup->binds[num_binds];
+			num_binds += bind_lookup->bind_nums[l3proto][l4proto];
+		}
+	}
+
+	list_for_each_entry(bind, &bind_lookup->list_bind, list) {
+		l3proto = bind_lookup_get_l3proto(bind->family);
+		l4proto = bind_lookup_get_l4proto(bind->proto);
+
+		bind_lookup->binds_by_type[l3proto][l4proto][filled_bind_nums[l3proto][l4proto]++] = bind;
+	}
+}
+
+static void
+bind_lookup_free_rcu(struct rcu_head *rcu_head)
+{
+	struct kz_bind_lookup *bind_lookup = container_of(rcu_head, struct kz_bind_lookup, rcu);
+
+	bind_lookup_destroy(bind_lookup);
+}
+
+static inline void
+instance_bind_lookup_swap(struct kz_instance *instance, struct kz_bind_lookup *new_bind_lookup)
+{
+	struct kz_bind_lookup *old_bind_lookup;
+
+	rcu_read_lock();
+	old_bind_lookup = rcu_dereference(instance->bind_lookup);
+	if (new_bind_lookup != old_bind_lookup) {
+		rcu_assign_pointer(instance->bind_lookup, new_bind_lookup);
+		call_rcu(&old_bind_lookup->rcu, bind_lookup_free_rcu);
+	}
+	rcu_read_unlock();
+}
+
+/* !!! must be called with the instance mutex held !!! */
+void
+kz_instance_remove_bind(struct kz_instance *instance, const netlink_port_t pid_to_remove, const struct kz_transaction const *tr)
+{
+	struct kz_bind_lookup *bind_lookup;
+	const struct kz_bind const *orig_bind;
+	struct kz_bind *new_bind;
+	struct kz_operation *io, *po;
+
+	bind_lookup = bind_lookup_new();
+
+	list_for_each_entry(orig_bind, &instance->bind_lookup->list_bind, list) {
+		bool skip = (!tr || (tr->flags & KZF_TRANSACTION_FLUSH_BIND)) &&
+			    orig_bind->peer_pid == pid_to_remove;
+		if (!skip) {
+			new_bind = kz_bind_clone(orig_bind);
+			list_add(&new_bind->list, &bind_lookup->list_bind);
+			kz_bind_debug(new_bind, "bind from old bind list added");
+		}
+	}
+
+	if (tr)
+		list_for_each_entry_safe(io, po, &tr->op, list) {
+			if (io->type == KZNL_OP_BIND) {
+				new_bind = (struct kz_bind *) (io->data);
+				list_del(&io->list);
+				list_add(&new_bind->list, &bind_lookup->list_bind);
+				kz_bind_debug(new_bind, "bind from transaction added");
+			}
+		}
+
+	bind_lookup_build(bind_lookup);
+	instance_bind_lookup_swap(instance, bind_lookup);
+}
+EXPORT_SYMBOL_GPL(kz_instance_remove_bind);
+
+/* Bind lookup */
+
+static inline unsigned int
+bind_lookup_hash_v4(__be32 saddr, __be16 sport, __be32 daddr, __be16 dport)
+{
+	/* FIXME: seed */
+	return jhash_3words(saddr, daddr, (sport << 16) + dport, 0);
+}
+
+const struct kz_bind * const
+kz_instance_bind_lookup_v4(const struct kz_instance const *instance, u8 l4proto,
+			__be32 saddr, __be16 sport,
+			__be32 daddr, __be16 dport)
+{
+	unsigned int bind_num;
+	unsigned int lookup_bind_num;
+	enum kz_bind_l4proto bind_l4proto = bind_lookup_get_l4proto(l4proto);
+	const struct kz_bind const *bind;
+
+	kz_debug("lookup bind; l4proto='%d', saddr='%pI4', sport='%d', daddr='%pI4', dport='%d'\n", l4proto, &saddr, htons(sport), &daddr, htons(dport));
+
+	bind_num = instance->bind_lookup->bind_nums[KZ_BIND_L3PROTO_IPV4][bind_l4proto];
+	if (bind_num == 0) {
+		kz_debug("no potential bind found;\n");
+		return NULL;
+	}
+
+	lookup_bind_num = bind_lookup_hash_v4(saddr, sport, daddr, dport) % bind_num;
+	kz_debug("potential bind found; bind_num='%d', selected_bind_num='%d'\n", bind_num, lookup_bind_num);
+
+	bind = instance->bind_lookup->binds_by_type[KZ_BIND_L3PROTO_IPV4][bind_l4proto][lookup_bind_num];
+
+	kz_bind_debug(bind, "bind found");
+
+	return bind;
+
+}
+EXPORT_SYMBOL(kz_instance_bind_lookup_v4);
+
+static inline unsigned int
+bind_lookup_hash_v6(const struct in6_addr const *saddr, __be16 sport, const struct in6_addr const *daddr, __be16 dport)
+{
+	/* FIXME: seed */
+	return jhash_3words(jhash2(saddr->s6_addr32, ARRAY_SIZE(saddr->s6_addr32), 0),
+			    jhash2(daddr->s6_addr32, ARRAY_SIZE(daddr->s6_addr32), 0),
+			    (sport << 16) + dport, 0);
+}
+
+const struct kz_bind * const
+kz_instance_bind_lookup_v6(const struct kz_instance const *instance, u8 l4proto,
+			   const struct in6_addr const *saddr, __be16 sport,
+			   const struct in6_addr const *daddr, __be16 dport)
+{
+	unsigned int bind_num;
+	unsigned int lookup_bind_num;
+	enum kz_bind_l4proto bind_l4proto = bind_lookup_get_l4proto(l4proto);
+	const struct kz_bind const *bind;
+
+	kz_debug("lookup bind; l4proto='%d', saddr='%pI6', sport='%d', daddr='%pI6', dport='%d'\n", l4proto, saddr, htons(sport), daddr, htons(dport));
+
+	bind_num = instance->bind_lookup->bind_nums[KZ_BIND_L3PROTO_IPV6][bind_l4proto];
+	if (bind_num == 0) {
+		kz_debug("no potential bind found;\n");
+		return NULL;
+	}
+
+	lookup_bind_num = bind_lookup_hash_v6(saddr, sport, daddr, dport) % bind_num;
+	kz_debug("potential bind found; bind_num='%d', selected_bind_num='%d'\n", bind_num, lookup_bind_num);
+
+	bind = instance->bind_lookup->binds_by_type[KZ_BIND_L3PROTO_IPV6][bind_l4proto][lookup_bind_num];
+
+	kz_bind_debug(bind, "bind found");
+
+	return bind;
+}
+EXPORT_SYMBOL_GPL(kz_instance_bind_lookup_v6);
+
+/***********************************************************
+ * NAT rule lookup
+ ***********************************************************/
+
+/* FIXME: this is _heavily_ dependent on TCP and UDP port numbers
+ * being mapped to the same offset in the ip_nat_range structure */
+static inline int
+nat_in_range(const struct nf_nat_ipv4_range *r,
+	 const __be32 addr, const __be16 port,
+	 const u_int8_t proto)
+{
+	/* log messages: the IP addresses are in host-endian format due to usage of "<" and ">" relations */
+	kz_debug("comparing range; flags='%x', start_ip='%pI4', end_ip='%pI4', start_port='%u', end_port='%u'\n",
+		 r->flags, &r->min_ip, &r->max_ip, ntohs(r->min.udp.port), ntohs(r->max.udp.port));
+	kz_debug("with packet; proto='%d', ip='%pI4', port='%u'\n",
+		 proto, &addr, ntohs(port));
+
+	if ((proto != IPPROTO_TCP) && (proto != IPPROTO_UDP))
+		return 0;
+
+	if (r->flags & NF_NAT_RANGE_MAP_IPS) {
+		if ((r->min_ip && ntohl(addr) < ntohl(r->min_ip)) ||
+		    (r->max_ip && ntohl(addr) > ntohl(r->max_ip)))
+			return 0;
+	}
+
+	if (r->flags & NF_NAT_RANGE_PROTO_SPECIFIED) {
+		if ((r->min.udp.port && ntohs(port) < ntohs(r->min.udp.port)) ||
+		    (r->max.udp.port && ntohs(port) > ntohs(r->max.udp.port)))
+			return 0;
+	}
+
+	kz_debug("match\n");
+
+	return 1;
+}
+
+const struct nf_nat_ipv4_range *
+kz_service_nat_lookup(const struct list_head * const head,
+		      const __be32 saddr, const __be32 daddr,
+		      const __be16 sport, const __be16 dport,
+		  const u_int8_t proto)
+{
+	struct kz_service_nat_entry *i;
+
+	kz_debug("proto='%u', src='%pI4:%u', dst='%pI4:%u'\n",
+		 proto, &saddr, ntohs(sport), &daddr, ntohs(dport));
+
+	list_for_each_entry(i, head, list) {
+		/* source range _must_ match, destination either matches or
+		 * the destination range is empty in the rule */
+		if (nat_in_range(&i->src, saddr, sport, proto) &&
+		    (((i->dst.min_ip == 0) && (i->dst.max_ip == 0)) || nat_in_range(&i->dst, daddr, dport, proto))) {
+			return &i->map;
+		}
+	}
+
+	return NULL;
+}
+EXPORT_SYMBOL_GPL(kz_service_nat_lookup);
+
+/***********************************************************
+ * Session lookup
+ ***********************************************************/
+
+/* NOTE: ports are passed, but legal only if protocol have them! */
+void
+kz_lookup_session(const struct kz_config *cfg,
+		  struct kz_traffic_props * const traffic_props,
+		  struct kz_dispatcher **dispatcher,
+		  struct kz_zone **clientzone, struct kz_zone **serverzone,
+		  struct kz_service **service, int reply)
+{
+	struct kz_dispatcher *dpt = NULL;
+	struct kz_service *svc = NULL;
+	const struct kz_head_z * const zones = &cfg->zones;
+
+	switch (traffic_props->l3proto) {
+	case NFPROTO_IPV4:
+		kz_debug("in='%s', l3proto='%u', l4proto='%u', src='%pI4:%u', dst='%pI4:%u'\n",
+			 traffic_props->iface ? traffic_props->iface->name : "(NULL)", traffic_props->l3proto, traffic_props->proto, &traffic_props->src_addr->in, traffic_props->src_port, &traffic_props->dst_addr->in, traffic_props->dst_port);
+		break;
+	case NFPROTO_IPV6:
+		kz_debug("in='%s', l3proto='%u', l4proto='%u', src='%pI6:%u', dst='%pI6:%u'\n",
+			 traffic_props->iface ? traffic_props->iface->name : "(NULL)", traffic_props->l3proto, traffic_props->proto, &traffic_props->src_addr->in6, traffic_props->src_port, &traffic_props->dst_addr->in6, traffic_props->dst_port);
+		break;
+	default:
+		BUG();
+		break;
+	}
+
+	/* look up src/dst zone */
+	switch (traffic_props->l3proto) {
+	case NFPROTO_IPV4:
+		traffic_props->src_zone = kz_head_zone_ipv4_lookup(zones, reply ? &traffic_props->dst_addr->in : &traffic_props->src_addr->in);
+		traffic_props->dst_zone = kz_head_zone_ipv4_lookup(zones, reply ? &traffic_props->src_addr->in : &traffic_props->dst_addr->in);
+		break;
+	case NFPROTO_IPV6:
+		traffic_props->src_zone = kz_head_zone_ipv6_lookup(zones, reply ? &traffic_props->dst_addr->in6 : &traffic_props->src_addr->in6);
+		traffic_props->dst_zone = kz_head_zone_ipv6_lookup(zones, reply ? &traffic_props->src_addr->in6 : &traffic_props->dst_addr->in6);
+		break;
+	default:
+		BUG();
+		break;
+	}
+
+	if (traffic_props->src_zone != NULL) {
+		kz_debug("found client zone; name='%s'\n", traffic_props->src_zone->name);
+	}
+	if (traffic_props->dst_zone != NULL) {
+		kz_debug("found server zone; name='%s'\n", traffic_props->dst_zone->name);
+	}
+
+	/* evaluate n-dimensional rules */
+	svc = kz_ndim_lookup(cfg, traffic_props, &dpt);
+
+	*dispatcher = dpt;
+	*clientzone = traffic_props->src_zone;
+	*serverzone = traffic_props->dst_zone;
+	*service = svc;
+}
+EXPORT_SYMBOL_GPL(kz_lookup_session);
Index: linux-3.3.8/net/netfilter/kzorp_netlink.c
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ linux-3.3.8/net/netfilter/kzorp_netlink.c	2013-11-18 17:12:30.159285808 +0100
@@ -0,0 +1,3803 @@
+/*
+ * KZorp netlink interface
+ *
+ * Copyright (C) 2006-2010, BalaBit IT Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/skbuff.h>
+#include <linux/in.h>
+#include <linux/init.h>
+#include <linux/spinlock.h>
+#include <linux/mutex.h>
+#include <linux/rcupdate.h>
+#include <linux/notifier.h>
+#include <linux/netdevice.h>
+#include <linux/netfilter.h>
+#include <linux/proc_fs.h>
+#include <linux/netfilter/kzorp_netlink.h>
+#include <linux/netfilter/kzorp.h>
+
+#include <net/ipv6.h>
+#include <net/sock.h>
+#include <net/genetlink.h>
+
+
+/***********************************************************
+ * Transactions
+ ***********************************************************/
+
+/* we have at most 1 transaction running at the same time */
+/* the config only changes through transaction; when we start one,
+   we can store pointer to the config and assume it stable till closed
+
+   if that changes, refcount or rcu lock must be applied to kz_transaction->cfg !
+
+*/
+static struct kz_transaction transaction;
+static bool transaction_open = 0;
+
+static void __init
+transaction_init(void)
+{
+	memset(&transaction, 0, sizeof(transaction));
+	INIT_LIST_HEAD(&transaction.op);
+	transaction_open = 0;
+}
+
+/* !!! must be called with the transaction mutex held !!! */
+inline static struct kz_transaction *
+transaction_lookup(int peer_pid)
+{
+	if (transaction_open && transaction.peer_pid == peer_pid)
+		return &transaction;
+	else
+		return NULL;
+}
+
+/* !!! must be called with the transaction mutex held !!! */
+static struct kz_transaction *
+transaction_create(const netlink_port_t peer_pid, const unsigned int instance_id, u_int64_t config_cookie)
+{
+	kz_debug("pid='%d', instance_id='%d', config_cookie='%llu'\n",
+		 peer_pid, instance_id, config_cookie);
+
+	if (transaction_open) {
+		kz_err("transaction already exists;\n");
+		return NULL;
+	}
+
+	transaction_open = 1;
+	transaction.instance_id = instance_id;
+	transaction.peer_pid = peer_pid;
+	transaction.flags = 0;
+	transaction.cookie = config_cookie;
+	transaction.cfg = kz_config_rcu; /* lock and protocol ensures no rcu_lock needed */
+
+	return &transaction;
+}
+
+static void transaction_cleanup_op(struct kz_transaction *);
+
+/* !!! must be called with the transaction mutex held !!! */
+static void
+transaction_destroy(struct kz_transaction *t)
+{
+	kz_debug("transaction='%p'\n", t);
+
+	BUG_ON(t != &transaction);
+
+	transaction_cleanup_op(t);
+
+	BUG_ON(!list_empty(&t->op));
+
+	transaction_open = 0;
+}
+
+/***********************************************************
+ * Transaction operations
+ ***********************************************************/
+
+/* caller must mutex the passed transaction! */
+static int
+transaction_add_op(struct kz_transaction *tr,
+		   enum kznl_op_data_type type,
+		   void * const data,
+		   void (*cleanup_func)(void *))
+{
+	struct kz_operation *o;
+
+	o = kzalloc(sizeof(struct kz_operation), GFP_KERNEL);
+	if (o == NULL) {
+		if (cleanup_func && data)
+			cleanup_func(data);
+		return -ENOMEM;
+	}
+
+	o->type = type;
+	o->data = data;
+	o->data_destroy = cleanup_func;
+	list_add(&o->list, &tr->op);
+	kz_debug("add op; type='%d'\n", type);
+
+	return 0;
+}
+
+/* cleanup functions passed */
+static void
+transaction_destroy_zone(void *data)
+{
+	kz_zone_put((struct kz_zone *)data);
+}
+
+static void
+transaction_destroy_service(void *data)
+{
+	kz_service_put((struct kz_service *)data);
+}
+
+static void
+transaction_destroy_dispatcher(void *data)
+{
+	kz_dispatcher_put((struct kz_dispatcher *)data);
+}
+
+static void
+transaction_destroy_bind(void *data)
+{
+	kz_bind_destroy((struct kz_bind *)data);
+}
+
+/* caller must mutex the passed transaction! */
+static void
+transaction_cleanup_op(struct kz_transaction *tr)
+{
+	struct kz_operation *o, *p;
+
+	list_for_each_entry_safe(o, p, &tr->op, list) {
+		list_del(&o->list);
+
+		if (o->data && o->data_destroy)
+			o->data_destroy(o->data);
+
+		kfree(o);
+	}
+}
+
+/* caller must mutex the passed transaction! */
+static struct kz_zone *
+transaction_zone_lookup(const struct kz_transaction * const tr,
+			const char *name)
+{
+	const struct kz_operation *i;
+
+	list_for_each_entry(i, &tr->op, list) {
+		if (i->type == KZNL_OP_ZONE) {
+			struct kz_zone *z = (struct kz_zone *)i->data;
+
+			if (strcmp(z->unique_name, name) == 0)
+				return z;
+		}
+	}
+
+	return NULL;
+}
+
+/* caller must mutex the passed transaction! */
+static struct kz_service *
+transaction_service_lookup(const struct kz_transaction * const tr,
+			   const char *name)
+{
+	const struct kz_operation *i;
+
+	list_for_each_entry(i, &tr->op, list) {
+		if (i->type == KZNL_OP_SERVICE) {
+			struct kz_service *s = (struct kz_service *)i->data;
+
+			if (strcmp(s->name, name) == 0)
+				return s;
+		}
+	}
+
+	return NULL;
+}
+
+/* caller must mutex the passed transaction! */
+static struct kz_dispatcher *
+transaction_dispatcher_lookup(const struct kz_transaction * const tr,
+			   const char *name)
+{
+	const struct kz_operation *i;
+
+	list_for_each_entry(i, &tr->op, list) {
+		if (i->type == KZNL_OP_DISPATCHER) {
+			struct kz_dispatcher *d = (struct kz_dispatcher *)i->data;
+
+			if (strcmp(d->name, name) == 0)
+				return d;
+		}
+	}
+
+	return NULL;
+}
+
+static inline bool
+kz_bind_eq(const struct kz_bind * const a, const struct kz_bind * const b)
+{
+	return (a->port == b->port &&
+		a->proto == b->proto &&
+		a->family == b->family &&
+		nf_inet_addr_cmp(&a->addr, &b->addr));
+}
+
+/* !!! must be called with the instance mutex held !!! */
+static struct kz_bind *
+transaction_bind_lookup(const struct kz_transaction * const tr,
+			const struct kz_bind *bind)
+{
+	const struct kz_operation *i;
+
+	kz_bind_debug(bind, "lookup item");
+
+	list_for_each_entry(i, &tr->op, list) {
+		if (i->type == KZNL_OP_BIND) {
+			struct kz_bind *b = (struct kz_bind *) i->data;
+
+			kz_bind_debug(b, "check item");
+
+			if (kz_bind_eq(b, bind))
+				return b;
+		}
+	}
+
+	return NULL;
+}
+
+/**
+ * transaction_rule_lookup - look up dispatcher and the rule in the transaction
+ * @tr: transaction
+ * @dispatcher_name: name of the dispatcher to look for
+ * @id: rule id to look for
+ *
+ * NOTE: caller must mutex the passed transaction!
+ *
+ * This function checks if we have a dispatcher named @dispatcher_name
+ * in the transaction operation list and if it has a rule with ID
+ * @id. Rules must be uploaded so that their IDs are in increasing
+ * order, failing to do so is an error. Because of this, this function
+ * simply checks if the rule ID of the rule last added matches @id.
+ */
+static struct kz_dispatcher_n_dimension_rule *
+transaction_rule_lookup(const struct kz_transaction * const tr,
+			const char *dispatcher_name, u_int32_t id)
+{
+	const struct kz_operation *i;
+
+	kz_debug("dispatcher_name='%s', id='%u'\n", dispatcher_name, id);
+
+	list_for_each_entry(i, &tr->op, list) {
+		if (i->type == KZNL_OP_DISPATCHER) {
+			struct kz_dispatcher *d;
+			struct kz_dispatcher_n_dimension_rule *rule = NULL;
+
+			d = (struct kz_dispatcher *) i->data;
+
+			if (strcmp(d->name, dispatcher_name))
+				continue;
+
+			/* we have found the dispatcher, check if the ID of
+			 * the last rule matches @id */
+			if (d->num_rule > 0)
+				rule = &d->rule[d->num_rule - 1];
+			if (rule && (id == rule->id))
+				return rule;
+
+			return NULL;
+		}
+	}
+
+	return NULL;
+}
+
+/***********************************************************
+ * Object lookup utility functions
+ ***********************************************************/
+
+/**
+ * lookup_zone_merged - look up a zone by name in the transaction + current config
+ * @tr: transaction
+ * @name: name of the zone
+ *
+* This function looks up a zone by name in a merged view of the
+ * current transaction and the current configuration. It looks up the
+ * config only if the transaction does not have the flush zones bit
+ * set, that is, there is no chance that the looked-up service will be
+ * removed by a subsequent commit.
+ */
+static inline struct kz_zone *
+lookup_zone_merged(const struct kz_transaction * const tr, const char *name)
+{
+	struct kz_zone *zone = transaction_zone_lookup(tr, name);
+
+	if (zone == NULL && !(tr->flags & KZF_TRANSACTION_FLUSH_ZONES))
+		zone = kz_zone_lookup_name(tr->cfg, name);
+
+	return zone;
+}
+
+/**
+ * lookup_service_merged - look up a service by name in the transaction + current config
+ * @tr: transaction
+ * @name: name to look for
+ *
+ * This function looks up a service by name in a merged view of the
+ * current transaction and the current configuration. It looks up the
+ * config only if the transaction does not have the flush services bit
+ * set, that is, there is no chance that the looked-up service will be
+ * removed by a subsequent commit.
+ **/
+static inline struct kz_service *
+lookup_service_merged(const struct kz_transaction * const tr, const char *name)
+{
+	struct kz_service *service = transaction_service_lookup(tr, name);
+
+	if (service == NULL && !(tr->flags & KZF_TRANSACTION_FLUSH_SERVICES))
+		service = kz_service_lookup_name(tr->cfg, name);
+
+	return service;
+}
+
+/***********************************************************
+ * Netlink attribute parsing
+ ***********************************************************/
+
+static inline int
+kznl_parse_name(const struct nlattr *attr, char *name, unsigned long nsize)
+{
+	struct kza_name *a = nla_data(attr);
+	unsigned long length;
+
+	length = (unsigned long) ntohs(a->length);
+	if (nsize < length + 1) {
+		kz_err("invalid target length; dst_size='%lu', len='%lu'\n", nsize, length);
+		return -EINVAL;
+	}
+
+	memcpy(name, a->name, length);
+	name[length] = 0;
+
+	return 0;
+}
+
+static int
+kznl_parse_name_alloc(const struct nlattr *attr, char **name)
+{
+	struct kza_name *a = nla_data(attr);
+	char *n;
+	int res;
+	unsigned long length = ntohs(a->length);
+
+	if (length == 0 || length > KZ_ATTR_NAME_MAX_LENGTH)
+		return -EINVAL;
+
+	n = kzalloc(length + 1, GFP_KERNEL);
+	if (n == NULL)
+		return -ENOMEM;
+
+	res = kznl_parse_name(attr, n, length + 1);
+	if (res >= 0)
+		*name = n;
+
+	return res;
+}
+
+static inline int
+kznl_parse_in_addr(const struct nlattr *attr, struct in_addr *addr)
+{
+	struct kz_in_subnet *a = nla_data(attr);
+
+	addr->s_addr = a->addr.s_addr;
+
+	kz_debug("parsed IPv4 address='%pI4'\n", addr);
+
+	return 0;
+}
+
+static inline int
+kznl_parse_in6_addr(const struct nlattr *attr, struct in6_addr *addr)
+{
+	struct kz_in6_subnet *a = nla_data(attr);
+
+	ipv6_addr_copy(addr, &a->addr);
+
+	kz_debug("parsed IPv6 address='%pI6'\n", addr);
+
+	return 0;
+}
+
+static const struct nla_policy inet_addr_nla_policy[KZNL_ATTR_TYPE_COUNT + 1] = {
+	[KZNL_ATTR_INET_ADDR]	= { .type = NLA_NESTED },
+	[KZNL_ATTR_INET6_ADDR]	= { .type = NLA_NESTED },
+};
+
+static inline int
+kznl_parse_inet_addr(const struct nlattr *attr, union nf_inet_addr *addr, sa_family_t *family)
+{
+	int res = 0;
+	struct nlattr *tb[KZNL_ATTR_TYPE_COUNT + 1];
+
+	res = nla_parse_nested(tb, KZNL_ATTR_TYPE_COUNT, attr, inet_addr_nla_policy);
+	if (res < 0) {
+		kz_err("failed to parse nested attribute\n");
+		return res;
+	}
+
+	kz_debug ("nested attributes: %p %p", tb[KZNL_ATTR_INET_ADDR], tb[KZNL_ATTR_INET6_ADDR]);
+	if (tb[KZNL_ATTR_INET_ADDR]) {
+		res = kznl_parse_in_addr(tb[KZNL_ATTR_INET_ADDR], &addr->in);
+		if (res < 0) {
+			kz_err("failed to parse IPv4 address\n");
+			return res;
+		} else {
+			*family = AF_INET;
+		}
+	}
+	else if (tb[KZNL_ATTR_INET6_ADDR]) {
+		res = kznl_parse_in6_addr(tb[KZNL_ATTR_INET6_ADDR], &addr->in6);
+		if (res < 0) {
+			kz_err("failed to parse IPv6 address\n");
+			return res;
+		} else {
+			*family = AF_INET6;
+		}
+	} else {
+		kz_err("required attributes missing: address\n");
+		res = -EINVAL;
+	}
+
+	return res;
+}
+
+
+
+static inline int
+kznl_parse_in_subnet(const struct nlattr *attr, struct in_addr *subnet_addr, struct in_addr *subnet_mask)
+{
+	struct kz_in_subnet *a = nla_data(attr);
+	u_int32_t mask, i;
+
+	subnet_addr->s_addr = a->addr.s_addr;
+	subnet_mask->s_addr = a->mask.s_addr;
+
+	kz_debug("address='%pI4', mask='%pI4'\n", subnet_addr, subnet_mask);
+
+	mask = ntohl(subnet_mask->s_addr);
+	for (i = 1 << 31; i && (mask & i); i >>= 1)
+		;
+	if (i && (i - 1) & mask)
+		return -EINVAL;
+
+	return 0;
+}
+
+static inline int
+kznl_parse_in6_subnet(const struct nlattr *attr, struct in6_addr *addr, struct in6_addr *mask)
+{
+	struct kz_in6_subnet *a = nla_data(attr);
+	struct in6_addr pfx;
+	int prefixlen;
+
+	ipv6_addr_copy(addr, &a->addr);
+	ipv6_addr_copy(mask, &a->mask);
+
+	kz_debug("address='%pI6', mask='%pI6'\n", addr, mask);
+
+	ipv6_addr_set(&pfx, 0xffffffff, 0xffffffff, 0xffffffff, 0xffffffff);
+	prefixlen = ipv6_addr_diff(mask, &pfx);
+	ipv6_addr_prefix(&pfx, mask, prefixlen);
+	if (!ipv6_addr_equal(&pfx, mask))
+		return -EINVAL;
+
+	return 0;
+}
+
+static const struct nla_policy inet_subnet_nla_policy[KZNL_ATTR_TYPE_COUNT + 1] = {
+	[KZNL_ATTR_INET_SUBNET]		= { .type = NLA_NESTED },
+	[KZNL_ATTR_INET6_SUBNET]	= { .type = NLA_NESTED },
+};
+
+static inline int
+kznl_parse_inet_subnet(const struct nlattr *attr, union nf_inet_addr *addr, union nf_inet_addr *mask, sa_family_t *family)
+{
+	int res = 0;
+	struct nlattr *tb[KZNL_ATTR_TYPE_COUNT + 1];
+
+	res = nla_parse_nested(tb, KZNL_ATTR_TYPE_COUNT, attr, inet_subnet_nla_policy);
+	if (res < 0) {
+		kz_err("failed to parse nested attribute\n");
+		return res;
+	}
+
+	if (tb[KZNL_ATTR_INET_SUBNET]) {
+		res = kznl_parse_in_subnet(tb[KZNL_ATTR_INET_SUBNET], &addr->in, &mask->in);
+		if (res < 0) {
+			kz_err("failed to parse IPv4 subnet\n");
+			return res;
+		} else {
+			*family = AF_INET;
+		}
+	}
+	else if (tb[KZNL_ATTR_INET6_SUBNET]) {
+		res = kznl_parse_in6_subnet(tb[KZNL_ATTR_INET6_SUBNET], &addr->in6, &mask->in6);
+		if (res < 0) {
+			kz_err("failed to parse IPv6 subnet\n");
+			return res;
+		} else {
+			*family = AF_INET6;
+		}
+	} else {
+		kz_err("required attributes missing: subnet\n");
+		res = -EINVAL;
+	}
+
+	return res;
+}
+
+static inline int
+kznl_parse_port(const struct nlattr *attr, __u16 *_port)
+{
+	__u16 port;
+
+	port = ntohs(nla_get_be16(attr));
+	if (port == 0) {
+		kz_err("invalid port number received; port='%hu'", port);
+		return -EINVAL;
+	}
+
+	*_port = port;
+
+	return 0;
+}
+
+static inline int
+kznl_parse_port_range(const struct nlattr *attr, u_int16_t *range_from, u_int16_t *range_to)
+{
+	struct kza_port_range *a = nla_data(attr);
+	const u_int16_t from = ntohs(a->from);
+	const u_int16_t to = ntohs(a->to);
+
+	if (to < from)
+		return -EINVAL;
+
+	*range_from = from;
+	*range_to = to;
+
+	return 0;
+}
+
+static inline int
+kznl_parse_proto(const struct nlattr *attr, __u8 *_proto)
+{
+	*_proto = nla_get_u8(attr);
+
+	return 0;
+}
+
+static inline int
+kznl_parse_reqid(const struct nlattr *attr, __u32 *_reqid)
+{
+	*_reqid = ntohl(nla_get_be32(attr));
+
+	return 0;
+}
+
+static inline int
+kznl_parse_proto_type(const struct nlattr *attr, u_int8_t proto, __u32 *proto_type)
+{
+	const u_int32_t _proto_type = ntohl(nla_get_be32(attr));
+	if ((proto == IPPROTO_ICMP || proto == IPPROTO_ICMPV6) && _proto_type > 255) {
+		kz_err("invalid protocol type received; proto_type='%hu'", _proto_type);
+		return -EINVAL;
+	}
+
+	*proto_type = _proto_type;
+
+	return 0;
+}
+
+static inline int
+kznl_parse_proto_subtype(const struct nlattr *attr, u_int8_t proto, __u32 *proto_subtype)
+{
+	const u_int32_t _proto_subtype = ntohl(nla_get_be32(attr));
+	if ((proto == IPPROTO_ICMP || proto == IPPROTO_ICMPV6) && _proto_subtype > 255) {
+		kz_err("invalid protocol type received; proto_subtype='%hu'", _proto_subtype);
+		return -EINVAL;
+	}
+
+	*proto_subtype = _proto_subtype;
+
+	return 0;
+}
+
+
+
+static inline int
+kznl_parse_service_params(const struct nlattr *attr, struct kz_service *svc)
+{
+	struct kza_service_params *a = nla_data(attr);
+	u_int32_t new_flags = ntohl(a->flags);
+
+	if (a->type <= KZ_SERVICE_INVALID || a->type >= KZ_SERVICE_TYPE_COUNT)
+		return -EINVAL;
+	if ((new_flags | KZF_SERVICE_PUBLIC_FLAGS) != KZF_SERVICE_PUBLIC_FLAGS)
+		return -EINVAL;
+
+	svc->type = (enum kz_service_type) a->type;
+	svc->flags = new_flags;
+
+	return 0;
+}
+
+static inline int
+kznl_parse_service_router_dst(struct nlattr *cda[], struct kz_service *svc)
+{
+	int res;
+
+	res = kznl_parse_inet_addr(cda[KZNL_ATTR_SERVICE_ROUTER_DST_ADDR], &svc->a.fwd.router_dst_addr, &svc->a.fwd.router_dst_addr_family);
+	if (res < 0) {
+		kz_err("failed to parse dst ip nested attribute\n");
+		goto error;
+	}
+	res = kznl_parse_port(cda[KZNL_ATTR_SERVICE_ROUTER_DST_PORT], &svc->a.fwd.router_dst_port);
+	if (res < 0) {
+		kz_err("failed to parse dst port attribute\n");
+		goto error;
+	}
+
+	return 0;
+error:
+	return res;
+}
+
+static inline int
+kznl_parse_service_nat_params(const struct nlattr *attr, struct nf_nat_ipv4_range *range)
+{
+	const struct kza_service_nat_params *a = nla_data(attr);
+	u_int32_t flags = ntohl(a->flags);
+
+	if ((flags | KZF_SERVICE_NAT_MAP_PUBLIC_FLAGS) != KZF_SERVICE_NAT_MAP_PUBLIC_FLAGS)
+		return -EINVAL;
+
+	if (flags & KZF_SERVICE_NAT_MAP_IPS)
+		range->flags |= NF_NAT_RANGE_MAP_IPS;
+	if (flags & KZF_SERVICE_NAT_MAP_PROTO_SPECIFIC)
+		range->flags |= NF_NAT_RANGE_PROTO_SPECIFIED;
+
+	range->min_ip = a->min_ip;
+	range->max_ip = a->max_ip;
+	range->min.udp.port = a->min_port;
+	range->max.udp.port = a->max_port;
+
+	return 0;
+}
+
+static inline int
+kznl_parse_service_session_cnt(const struct nlattr *attr, u_int32_t *count)
+{
+	struct kza_service_session_cnt *a = nla_data(attr);
+
+	*count = ntohl(a->count);
+
+	return 0;
+}
+
+static inline int
+kznl_parse_service_deny_method(const struct nlattr *attr, unsigned int *type)
+{
+	*type = nla_get_u8(attr);
+
+	return 0;
+}
+
+static inline int
+kznl_parse_service_ipv4_deny_method(const struct nlattr *attr, unsigned int *_type)
+{
+	unsigned int type;
+	int res;
+
+	res = kznl_parse_service_deny_method(attr, &type);
+	if (res < 0)
+		return res;
+
+	if (type >= KZ_SERVICE_DENY_METHOD_V4_COUNT)
+		return -EINVAL;
+
+	*_type = type;
+
+	return 0;
+}
+
+static inline int
+kznl_parse_service_ipv6_deny_method(const struct nlattr *attr, unsigned int *_type)
+{
+	unsigned int type;
+	int res;
+
+	res = kznl_parse_service_deny_method(attr, &type);
+	if (res < 0)
+		return res;
+
+	if (type > KZ_SERVICE_DENY_METHOD_V6_COUNT)
+		return -EINVAL;
+
+	*_type = type;
+
+	return 0;
+}
+
+static inline int
+kznl_check_port_ranges(u_int32_t num_ranges, u_int16_t ranges[])
+{
+	unsigned int i;
+
+	for (i = 0; i < num_ranges; i++) {
+		if (ranges[2 * i] > ranges[2 * i + 1])
+			return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int
+kznl_parse_dispatcher_n_dimension(const struct nlattr *attr, struct kz_dispatcher *n_dimension)
+{
+	struct kza_dispatcher_n_dimension_params *a = nla_data(attr);
+
+	return kz_dispatcher_alloc_rule_array(n_dimension, ntohl(a->num_rules));
+}
+
+static int
+kznl_parse_dispatcher_n_dimension_rule(const struct nlattr *attr,
+				       struct kz_dispatcher_n_dimension_rule *rule)
+{
+	struct kza_n_dimension_rule_params *a = nla_data(attr);
+
+	rule->id = ntohl(a->id);
+	return 0;
+}
+
+static int
+kznl_parse_dispatcher_n_dimension_rule_entry(const struct nlattr *attr,
+					     struct kz_dispatcher_n_dimension_rule_entry_params *rule_entry)
+{
+	struct kz_dispatcher_n_dimension_rule_entry_params *a = nla_data(attr);
+	rule_entry->rule_id = ntohl(a->rule_id);
+	return 0;
+}
+
+static inline int
+kznl_parse_query_params(const struct nlattr *attr, u_int8_t *proto, char *ifname)
+{
+	struct kza_query_params *a = nla_data(attr);
+
+	*proto = a->proto;
+	memcpy(ifname, a->ifname, IFNAMSIZ);
+
+	return 0;
+}
+
+/***********************************************************
+ * Netlink attribute dumping
+ ***********************************************************/
+
+static int
+kznl_dump_name(struct sk_buff *skb, unsigned int attr, const char *name)
+{
+	size_t len = strlen(name);
+
+	{
+		struct {
+			struct kza_name hdr;
+			char name[len];
+		} msg;
+
+		msg.hdr.length = htons(len);
+		memcpy(&msg.name, name, len);
+		NLA_PUT(skb, attr, sizeof(struct kza_name) + len, &msg);
+	}
+
+	return 0;
+
+nla_put_failure:
+	return -1;
+}
+
+static inline int
+kznl_dump_port(struct sk_buff *skb, unsigned int attr, __u16 port)
+{
+	if (port == 0)
+		return -1;
+
+	NLA_PUT_BE16(skb, attr, htons(port));
+
+	return 0;
+
+nla_put_failure:
+	return -1;
+}
+
+static int
+kznl_dump_port_range(struct sk_buff *skb, unsigned int attr,
+		     const struct kz_port_range * const range)
+{
+	struct kza_port_range r;
+
+	r.from = htons(range->from);
+	r.to = htons(range->to);
+
+	NLA_PUT(skb, attr, sizeof(struct kza_port_range), &r);
+
+	return 0;
+
+nla_put_failure:
+	return -1;
+}
+
+static int
+kznl_dump_in_subnet(struct sk_buff *skb, unsigned int attr,
+		    const struct in_addr * const addr,
+		    const struct in_addr * const mask)
+{
+	struct kz_in_subnet a;
+
+	a.addr.s_addr = addr->s_addr;
+	a.mask.s_addr = mask->s_addr;
+
+	NLA_PUT(skb, attr, sizeof(struct kz_in_subnet), &a);
+
+	return 0;
+
+nla_put_failure:
+	return -1;
+}
+
+static int
+kznl_dump_in6_subnet(struct sk_buff *skb, unsigned int attr,
+		     const struct in6_addr * const addr,
+		     const struct in6_addr * const mask)
+{
+	struct kz_in6_subnet a;
+
+	ipv6_addr_copy(&a.addr, addr);
+	ipv6_addr_copy(&a.mask, mask);
+
+	NLA_PUT(skb, attr, sizeof(struct kz_in6_subnet), &a);
+
+	return 0;
+
+nla_put_failure:
+	return -1;
+}
+
+static int
+kznl_dump_inet_subnet(struct sk_buff *skb, unsigned int attr,
+		      sa_family_t family, const union nf_inet_addr *addr, const union nf_inet_addr *mask)
+{
+	int res = 0;
+	struct nlattr *nest_helper;
+
+	nest_helper = nla_nest_start(skb, attr | NLA_F_NESTED);
+	if (!nest_helper)
+		return -1;
+
+	if (family == AF_INET) {
+		kz_debug("dump inet subnet; address='%pI4', mask='%pI4'\n", &addr->in, &mask->in);
+		res = kznl_dump_in_subnet(skb, KZNL_ATTR_INET_SUBNET, &addr->in, &mask->in);
+		if (res < 0)
+			goto nla_put_failure;
+	}
+	else if (family == AF_INET6) {
+		kz_debug("dump inet subnet; address='%pI6', mask='%pI6'\n", &addr->in6, &mask->in6);
+		res = kznl_dump_in6_subnet(skb, KZNL_ATTR_INET6_SUBNET, &addr->in6, &mask->in6);
+		if (res < 0)
+			goto nla_put_failure;
+	} else {
+		BUG();
+	}
+
+nla_put_failure:
+
+	nla_nest_end(skb, nest_helper);
+
+	return res;
+}
+
+static int
+kznl_dump_inet_addr(struct sk_buff *skb, unsigned int attr,
+		    sa_family_t family, const union nf_inet_addr *addr)
+{
+	int res = 0;
+	struct nlattr *nest_helper;
+
+	nest_helper = nla_nest_start(skb, attr | NLA_F_NESTED);
+	if (!nest_helper)
+		return -1;
+
+	if (family == AF_INET) {
+		kz_debug("dump inet addr; address='%pI4'\n", &addr->in);
+		res = nla_put(skb, KZNL_ATTR_INET_ADDR, sizeof(struct in_addr), &addr->in);
+		if (res < 0)
+			goto nla_put_failure;
+	}
+	else if (family == AF_INET6) {
+		kz_debug("dump inet addr; address='%pI6'\n", &addr->in6);
+		res = nla_put(skb, KZNL_ATTR_INET6_ADDR, sizeof(struct in6_addr), &addr->in6);
+		if (res < 0)
+			goto nla_put_failure;
+	} else {
+		BUG();
+	}
+
+nla_put_failure:
+
+	nla_nest_end(skb, nest_helper);
+
+	return res;
+}
+
+static inline int
+kznl_dump_service_deny_method(struct sk_buff *skb, unsigned int attr,
+			      unsigned int method)
+{
+	NLA_PUT_U8(skb, attr, (method & 0xff));
+	return 0;
+
+nla_put_failure:
+	return -1;
+}
+
+static inline int
+kznl_dump_service_nat_entry(struct kza_service_nat_params *a, struct nf_nat_ipv4_range *range)
+{
+	if (range->flags & NF_NAT_RANGE_MAP_IPS)
+		a->flags |= KZF_SERVICE_NAT_MAP_IPS;
+	if (range->flags & NF_NAT_RANGE_PROTO_SPECIFIED)
+		a->flags |= KZF_SERVICE_NAT_MAP_PROTO_SPECIFIC;
+
+	a->flags = htons(a->flags);
+	a->min_ip = range->min_ip;
+	a->max_ip = range->max_ip;
+	a->min_port = range->min.udp.port;
+	a->max_port = range->max.udp.port;
+
+	return 0;
+}
+
+/***********************************************************
+ * Netlink message processing
+ ***********************************************************/
+
+static struct genl_family kznl_family = {
+	.id = GENL_ID_GENERATE,
+	.name = "kzorp",
+	.version = 1,
+	.maxattr = KZNL_ATTR_TYPE_COUNT,
+};
+
+static int
+kznl_recv_start(struct sk_buff *skb, struct genl_info *info)
+{
+	int res = 0;
+	struct kz_instance *ins;
+	struct kz_transaction *tr;
+	char *ins_name;
+	u_int64_t config_cookie = 0UL;
+
+	if (!info->attrs[KZNL_ATTR_INSTANCE_NAME]) {
+		kz_err("required attributes missing\n");
+		res = -EINVAL;
+		goto error;
+	}
+
+	/* parse attributes */
+	if (kznl_parse_name_alloc(info->attrs[KZNL_ATTR_INSTANCE_NAME], &ins_name) < 0) {
+		kz_err("error while parsing name attribute\n");
+		res = -EINVAL;
+		goto error;
+	}
+
+	/* parse config cookie if present */
+	if (info->attrs[KZNL_ATTR_CONFIG_COOKIE]) {
+		config_cookie = be64_to_cpu(nla_get_u64(info->attrs[KZNL_ATTR_CONFIG_COOKIE]));
+	}
+
+	LOCK_TRANSACTIONS();
+
+	/* look up pid in transactions */
+	tr = transaction_lookup(info->snd_pid);
+	if (tr != NULL) {
+		/* problem: we already have a transaction running with this PID as peer */
+		kz_err("transaction pending for this PID\n");
+		res = -EINVAL;
+		goto error_unlock_tr;
+	}
+
+	/* look up/create instance */
+	ins = kz_instance_lookup(ins_name);
+	if (ins == NULL) {
+		ins = kz_instance_create(ins_name, strlen(ins_name), info->snd_pid);
+		if (ins == NULL) {
+			kz_err("failed to create new instance\n");
+			res = -EINVAL;
+			goto error_unlock_tr;
+		}
+	}
+
+	if (ins->flags & KZF_INSTANCE_TRANS) {
+		/* the instance already has an associated transaction */
+		kz_err("the instance already has a pending transaction\n");
+		res = -EEXIST;
+		goto error_unlock_tr;
+	}
+
+	/* create transaction */
+	tr = transaction_create(info->snd_pid, ins->id, config_cookie);
+	if (tr == NULL) {
+		kz_err("failed to create transaction\n");
+		res = -EINVAL;
+		goto error_unlock_tr;
+	}
+
+	/* mark instance */
+	ins->flags |= KZF_INSTANCE_TRANS;
+
+	kz_debug("transaction started; transaction='%p'\n", tr);
+
+error_unlock_tr:
+	UNLOCK_TRANSACTIONS();
+
+	if (ins_name != NULL)
+		kfree(ins_name);
+
+error:
+	return res;
+}
+
+/* this is a SINGLE point that changes the config (should that change, review what thinks so)
+
+   we could just collect operations raw, and do all the checks here. for historic reasons we
+   instead do preliminary checks as they come in. We have some expectations, and limit what can be done.
+
+   Important limitation is the messages that set flush flag -- it must arrive early, if not, some checks may get mislead
+   the semantic of those flags is ALWAYS as if they arrived at start.
+
+   elements that refer to each other must arrive in proper order (what is checked on arrival)
+
+   the transaction_op list have a mix of services, zones, dispatchers;
+
+   reference-setting messages can come only to the "newly added" items. If no flush, we inherit from the previous config,
+   though the referent list of those can change indirectly (i.e we have Zone1 that refers Svc1 and Svc2. We send config
+   that flushes services, not flush zones, sends Svc1 and no Svc2. This results config having (old) Zone1 refering (new) Svc1.
+
+   dependencies are ordered:
+     service: none
+     zone -> service  [inbound, outbound] by id; zone -> zone [admin-parent] by pointer
+     dispatcher -> zone, service  [server-zone, client-zone, service] by pointers
+
+   procedure:
+     - alloc new config struct
+     - copy services from old/transactions, retain id from old if name present; clear session counts;
+     - copy zone DAC from old to transactions if required by flag; old overrides new, no consolidation!
+     - copy zones from old/transactions
+     - consolidate admin-parents in zones to refer inside new config
+     - check service links in zones, drop missing
+     - copy dispatchers from old/transactions
+     - consolidate pointers in css
+     - init lookup helper structures
+     - swap in the new config (old gets nuked on rcu unlock)
+
+   any problems en-route mean just dropping out, freeing anything in new config and transaction,
+   the old config stays. The transaction is always closed.
+
+   this function is called having transaction_mutex
+*/
+static int
+kznl_recv_commit_transaction(struct kz_instance *instance, struct kz_transaction *tr)
+{
+	struct kz_operation *io, *po;
+	int res = 0;
+	const struct kz_config * const old = tr->cfg;
+	struct kz_config *new ;
+
+	/* preliminary sanity checks */
+	{
+		/* append dispatcherss created in the transaction */
+		list_for_each_entry(io, &tr->op, list) {
+			if (io->type == KZNL_OP_DISPATCHER) {
+				const struct kz_dispatcher *dispatcher = (struct kz_dispatcher *) io->data;
+
+				if (dispatcher->num_rule != dispatcher->alloc_rule) {
+					kz_err("rule number mismatch; dispatcher='%s', alloc_rules='%u', num_rules='%u'\n",
+						dispatcher->name, dispatcher->alloc_rule, dispatcher->num_rule);
+					return -EINVAL;
+				}
+			}
+		}
+	}
+
+	/* the new config instance */
+	new = kz_config_new();
+	if (new == NULL)
+		return -ENOMEM;
+
+	/* process services */
+	{
+		struct kz_service *i, *svc, *orig;
+
+		/* clone existing services */
+		list_for_each_entry(i, &old->services.head, list) {
+			/* skip service if the FLUSH flag is set and it belongs
+			 * to the same instance */
+			if ((tr->flags & KZF_TRANSACTION_FLUSH_SERVICES) &&
+			    (i->instance_id == tr->instance_id)) {
+				continue;
+			}
+
+			svc = kz_service_clone(i);
+			if (svc == NULL)
+				goto mem_error;
+			kz_debug("cloned service; name='%s'\n", svc->name);
+			list_add_tail(&svc->list, &new->services.head);
+			atomic_set(&svc->session_cnt, kz_service_lock(i));
+		}
+
+		/* add services in the transaction */
+		list_for_each_entry_safe(io, po, &tr->op, list) {
+			if (io->type == KZNL_OP_SERVICE) {
+				svc = (struct kz_service *)(io->data);
+				list_del(&io->list);
+				list_add_tail(&svc->list, &new->services.head);
+				kfree(io);
+				kz_debug("add service; name='%s'\n", svc->name);
+				orig = kz_service_lookup_name(old, svc->name);
+				if (orig != NULL) {
+					kz_debug("migrate service session count\n");
+					atomic_set(&svc->session_cnt, kz_service_lock(orig));
+					svc->id = orig->id; /* use the original ID! */
+				}
+			}
+		}
+	}
+
+	/* process zones */
+	{
+		struct kz_zone *i, *zone;
+
+		/* clone existing zones */
+		if (!(tr->flags & KZF_TRANSACTION_FLUSH_ZONES)) {
+			list_for_each_entry(i, &old->zones.head, list) {
+				zone = kz_zone_clone(i);
+				if (zone == NULL)
+					goto mem_error;
+				kz_debug("clone zone; name='%s', depth='%u'\n", zone->unique_name, zone->depth);
+				list_add_tail(&zone->list, &new->zones.head);
+			}
+		}
+
+		/* append zones created in the transaction */
+		list_for_each_entry_safe(io, po, &tr->op, list) {
+			if (io->type == KZNL_OP_ZONE) {
+				zone = (struct kz_zone *)(io->data);
+				list_del(&io->list);
+				list_add_tail(&zone->list, &new->zones.head);
+				kfree(io);
+				kz_debug("add zone; name='%s', depth='%u'\n", zone->unique_name, zone->depth);
+			}
+		}
+
+		/* consolidate admin_parent links - must point to zones in new list */
+		list_for_each_entry(i, &new->zones.head, list) {
+			if (i->admin_parent != NULL) {
+				struct kz_zone *parent;
+
+				parent = __kz_zone_lookup_name(&new->zones.head, i->admin_parent->unique_name);
+				if (parent == NULL) {
+					/* oops, its admin parent was deleted, this is an
+					 * internal error */
+					kz_err("transaction problem: internal error, aborting\n");
+					res = -EINVAL;
+					goto error;
+				}
+
+				kz_zone_get(parent);
+				kz_zone_put(i->admin_parent);
+				i->admin_parent = parent;
+				kz_debug("set admin-parent for zone; name='%s' parent='%s', depth='%u', parent_depth='%u'\n", i->unique_name, parent->unique_name, i->depth, parent->depth);
+			}
+		}
+	}
+	/* process dispatchers */
+	{
+		struct kz_dispatcher *i, *dpt;
+
+		/* clone existing dispatchers */
+		list_for_each_entry(i, &old->dispatchers.head, list) {
+			/* skip service if the FLUSH flag is set and it belongs
+			 * to the same instance */
+			if ((tr->flags & KZF_TRANSACTION_FLUSH_DISPATCHERS) &&
+			    (i->instance->id == tr->instance_id))
+				continue;
+
+			kz_debug("cloning dispatcher; name='%s', alloc_rules='%u'\n", i->name, i->alloc_rule);
+
+			dpt = kz_dispatcher_clone(i);
+			if (dpt == NULL)
+				goto mem_error;
+			list_add_tail(&dpt->list, &new->dispatchers.head);
+		}
+
+		/* append dispatcherss created in the transaction */
+		list_for_each_entry_safe(io, po, &tr->op, list) {
+			if (io->type == KZNL_OP_DISPATCHER) {
+				struct kz_dispatcher *dispatcher = (struct kz_dispatcher *) io->data;
+				kz_debug("add dispatcher; name='%s', alloc_rules='%u', num_rules='%u'\n", dispatcher->name, dispatcher->alloc_rule, dispatcher->num_rule);
+				list_del(&io->list);
+				list_add_tail(&dispatcher->list, &new->dispatchers.head);
+				kfree(io);
+			}
+		}
+
+		/* consolidate content */
+		list_for_each_entry(i, &new->dispatchers.head, list) {
+			kz_dispatcher_relink(i, &new->zones.head, &new->services.head);
+		}
+	}
+
+	/* remove binds of transaction owner process */
+	kz_instance_remove_bind(instance, tr->peer_pid, tr);
+
+	/* build lookup structures */
+	res = kz_head_zone_build(&new->zones);
+	if (res < 0) {
+		kz_err("failed to build zone lookup data structures, aborting\n");
+		goto error;
+	}
+
+	res = kz_head_dispatcher_build(&new->dispatchers);
+	if (res < 0) {
+		kz_err("error building dispatcher lookup structures\n");
+		goto error;
+	}
+
+	/* all ok, commit finally */
+	kz_debug("install new config\n");
+	kz_config_swap(new);
+	res = 0;
+	goto free_locals;
+
+mem_error:
+	kz_err("memory exhausted during kzorp config commit");
+	res = -ENOMEM;
+error:
+	/* unlock services in old */
+	{
+		struct kz_service *i;
+		list_for_each_entry(i, &old->services.head, list) {
+			kz_service_unlock(i);
+		}
+	}
+
+	kz_config_destroy(new);
+
+free_locals:
+	return res;
+}
+
+static int
+kznl_recv_commit(struct sk_buff *skb, struct genl_info *info)
+{
+	int res = 0;
+	struct kz_transaction *tr;
+	struct kz_instance *inst;
+
+	LOCK_TRANSACTIONS();
+
+	tr = transaction_lookup(info->snd_pid);
+	if (tr == NULL) {
+		/* we have no transaction associated with this peer */
+		kz_err("no transaction found; pid='%d'\n", info->snd_pid);
+		res = -ENOENT;
+		goto error_unlock_tr;
+	}
+
+	inst = kz_instance_lookup_id(tr->instance_id);
+	res = kznl_recv_commit_transaction(inst, tr);
+
+	if (inst != NULL)
+		inst->flags &= ~KZF_INSTANCE_TRANS;
+	transaction_destroy(tr);
+
+error_unlock_tr:
+	UNLOCK_TRANSACTIONS();
+	return res;
+}
+
+static int
+kznl_recv_setflag(struct sk_buff *skb, struct genl_info *info, unsigned int flag)
+{
+	int res = 0;
+	struct kz_transaction *tr;
+
+	LOCK_TRANSACTIONS();
+
+	tr = transaction_lookup(info->snd_pid);
+	if (tr == NULL) {
+		/* we have no transaction associated with this peer */
+		kz_err("no transaction found; pid='%d'\n", info->snd_pid);
+		res = -ENOENT;
+		goto error_unlock_tr;
+	}
+
+	/* set the flag in the transaction */
+	tr->flags |= flag;
+
+error_unlock_tr:
+	UNLOCK_TRANSACTIONS();
+
+	return res;
+}
+
+static int
+kznl_recv_flush_z(struct sk_buff *skb, struct genl_info *info)
+{
+	return kznl_recv_setflag(skb, info, KZF_TRANSACTION_FLUSH_ZONES);
+}
+
+static int
+kznl_recv_flush_s(struct sk_buff *skb, struct genl_info *info)
+{
+	return kznl_recv_setflag(skb, info, KZF_TRANSACTION_FLUSH_SERVICES);
+}
+
+static int
+kznl_recv_flush_d(struct sk_buff *skb, struct genl_info *info)
+{
+	return kznl_recv_setflag(skb, info, KZF_TRANSACTION_FLUSH_DISPATCHERS);
+}
+
+static int
+kznl_recv_flush_b(struct sk_buff *skb, struct genl_info *info)
+{
+	return kznl_recv_setflag(skb, info, KZF_TRANSACTION_FLUSH_BIND);
+}
+
+static int
+kznl_recv_add_zone(struct sk_buff *skb, struct genl_info *info)
+{
+	int res = 0;
+	struct kz_zone *zone, *p;
+	struct kz_transaction *tr;
+	char *parent_name = NULL;
+
+	if (!info->attrs[KZNL_ATTR_ZONE_NAME]) {
+		kz_err("required attribute missing: name\n");
+		res = -EINVAL;
+		goto error;
+	}
+
+	/* allocate zone structure */
+	zone = kz_zone_new();
+	if (zone == NULL) {
+		kz_err("failed to allocate zone structure\n");
+		res = -ENOMEM;
+		goto error;
+	}
+
+	/* fill fields */
+	res = kznl_parse_name_alloc(info->attrs[KZNL_ATTR_ZONE_NAME], &zone->name);
+	if (res < 0) {
+		kz_err("failed to parse zone name\n");
+		goto error_put_zone;
+	}
+
+	if (info->attrs[KZNL_ATTR_ZONE_RANGE]) {
+		res = kznl_parse_inet_subnet(info->attrs[KZNL_ATTR_ZONE_RANGE], &zone->addr, &zone->mask, &zone->family);
+		if (res < 0) {
+			kz_err("failed to parse zone range attribute\n");
+			goto error_put_zone;
+		} else {
+			zone->flags |= KZF_ZONE_HAS_RANGE;
+		}
+	}
+
+	if (info->attrs[KZNL_ATTR_ZONE_UNAME]) {
+		res = kznl_parse_name_alloc(info->attrs[KZNL_ATTR_ZONE_UNAME], &zone->unique_name);
+		if (res < 0) {
+			kz_err("failed to parse unique name\n");
+			goto error_put_zone;
+		}
+
+		/* compare unique name and name: if they are the same,
+		 * we can just set the unique name to name and save
+		 * some memory */
+		if (strcmp(zone->unique_name, zone->name) == 0) {
+			kfree(zone->unique_name);
+			zone->unique_name = zone->name;
+		}
+
+	} else {
+		/* unique name attribute not present, it's equal to name */
+		zone->unique_name = zone->name;
+	}
+
+	if (info->attrs[KZNL_ATTR_ZONE_PNAME]) {
+		res = kznl_parse_name_alloc(info->attrs[KZNL_ATTR_ZONE_PNAME], &parent_name);
+		if (res < 0) {
+			kz_err("failed to parse parent name\n");
+			goto error_put_zone;
+		}
+	}
+
+	/* look up transaction */
+	LOCK_TRANSACTIONS();
+
+	tr = transaction_lookup(info->snd_pid);
+	if (tr == NULL) {
+		kz_err("no transaction found; pid='%d'\n", info->snd_pid);
+		res = -ENOENT;
+		goto error_unlock_tr;
+	}
+
+	/* check that we don't yet have a zone with the same name */
+	p = lookup_zone_merged(tr, zone->unique_name);
+	if (p != NULL) {
+		kz_err("zone with the same unique name already present; name='%s'\n", zone->unique_name);
+		res = -EEXIST;
+		goto error_unlock_op;
+	}
+
+	/* look up parent zone by name:
+	 * it's either been added in this transaction or is present in the global
+	 * zone list (should check iff the transaction does not have the FLUSH
+	 * flag set) */
+	if (parent_name != NULL) {
+		p = lookup_zone_merged(tr, parent_name);
+		if (p == NULL) {
+			kz_err("parent zone not found; name='%s'\n", parent_name);
+			res = -ENOENT;
+			goto error_unlock_op;
+		}
+
+		zone->admin_parent = kz_zone_get(p);
+		/* there's an implicit dependency here on the zones being ordered
+		 * so that we've already set up the depth of the parent zone */
+		zone->depth = p->depth + 1;
+	}
+
+	res = transaction_add_op(tr, KZNL_OP_ZONE, kz_zone_get(zone), transaction_destroy_zone);
+	if (res < 0) {
+		kz_err("failed to queue transaction operation\n");
+	}
+
+error_unlock_op:
+error_unlock_tr:
+	UNLOCK_TRANSACTIONS();
+
+	if (parent_name != NULL)
+		kfree(parent_name);
+
+error_put_zone:
+	kz_zone_put(zone);
+
+error:
+	return res;
+}
+
+/* zone dumps */
+
+static int
+kznl_build_zone_add(struct sk_buff *skb, netlink_port_t pid, u_int32_t seq, int flags,
+		    enum kznl_msg_types msg, const struct kz_zone *zone)
+{
+	void *hdr;
+
+	hdr = genlmsg_put(skb, pid, seq, &kznl_family, flags, msg);
+	if (!hdr)
+		goto nla_put_failure;
+
+	kz_debug("flags='%x', family='%d'\n", zone->flags, zone->family);
+	if (zone->flags & KZF_ZONE_HAS_RANGE) {
+		if (kznl_dump_inet_subnet(skb, KZNL_ATTR_ZONE_RANGE, zone->family, &zone->addr, &zone->mask) < 0)
+			goto nla_put_failure;
+	}
+
+	if (kznl_dump_name(skb, KZNL_ATTR_ZONE_UNAME, zone->unique_name) < 0)
+		goto nla_put_failure;
+	if (kznl_dump_name(skb, KZNL_ATTR_ZONE_NAME, zone->name) < 0)
+		goto nla_put_failure;
+	if (zone->admin_parent != NULL) {
+		if (kznl_dump_name(skb, KZNL_ATTR_ZONE_PNAME, zone->admin_parent->name) < 0)
+			goto nla_put_failure;
+	}
+
+	return genlmsg_end(skb, hdr);
+
+nla_put_failure:
+	genlmsg_cancel(skb, hdr);
+	return -1;
+}
+
+static int
+kznl_build_zone(struct sk_buff *skb, netlink_port_t pid, u_int32_t seq, int flags,
+		const struct kz_zone *zone, const struct kz_config * cfg)
+{
+	/* *part_idx and *entry_idx is left pointing the failed item */
+	return kznl_build_zone_add(skb, pid, seq, flags, KZNL_MSG_ADD_ZONE, zone);
+}
+
+static int
+kznl_dump_zones(struct sk_buff *skb, struct netlink_callback *cb)
+{
+	const struct kz_zone *i, *last;
+	const struct kz_config * cfg;
+
+	/*
+	 * race condition recovery: restart dump
+	 * (if this turns to be a problem, cfg shall be refcounted!)
+	 *
+	 * on first entry cb->args is all-0
+	 */
+
+	/* check if we've finished the dump */
+	if (cb->args[3] == 2)
+		return skb->len;
+
+	rcu_read_lock();
+	cfg = rcu_dereference(kz_config_rcu);
+	if (cb->args[3] == 0 || !kz_generation_valid(cfg, cb->args[4])) {
+		cb->args[4] = kz_generation_get(cfg);
+		cb->args[3] = 1;
+	}
+
+restart:
+	last = (struct kz_zone *) cb->args[0];
+	list_for_each_entry(i, &cfg->zones.head, list) {
+		/* check if we're continuing the dump from a given entry */
+		if (last != NULL) {
+			if (i == last) {
+				/* ok, this was the last entry we've tried to dump */
+				cb->args[0] = 0;
+				last = NULL;
+			} else
+				continue;
+		}
+
+		if (kznl_build_zone(skb, NETLINK_CB(cb->skb).pid,
+				   cb->nlh->nlmsg_seq, 0, i, cfg) < 0) {
+			/* zone dump failed, try to continue from here next time */
+			cb->args[0] = (long) i;
+			goto out;
+		}
+	}
+
+	if (last != NULL) {
+		/* we've tried to continue an interrupted dump but did not find the
+		 * restart point. cannot do any better but start again. */
+		cb->args[0] = 0;
+		goto restart;
+	}
+
+	/* done */
+	cb->args[3] = 2;
+
+out:
+	rcu_read_unlock();
+
+	return skb->len;
+}
+
+static int
+kznl_recv_get_zone(struct sk_buff *skb, struct genl_info *info)
+{
+	int res = 0;
+	char *zone_name = NULL;
+	struct kz_zone *zone;
+	struct sk_buff *nskb = NULL;
+	const struct kz_config * cfg;
+
+	/* parse attributes */
+	if (!info->attrs[KZNL_ATTR_ZONE_UNAME]) {
+		kz_err("required name attribute missing\n");
+		res = -EINVAL;
+		goto error;
+	}
+
+	res = kznl_parse_name_alloc(info->attrs[KZNL_ATTR_ZONE_UNAME], &zone_name);
+	if (res < 0) {
+		kz_err("failed to parse zone name\n");
+		goto error;
+	}
+
+	rcu_read_lock();
+	cfg = rcu_dereference(kz_config_rcu);
+
+	zone = kz_zone_lookup_name(cfg, zone_name);
+	if (zone == NULL) {
+		kz_debug("no such zone found\n");
+		res = -ENOENT;
+		goto error_unlock_zone;
+	}
+
+	/* create skb and dump */
+	nskb = genlmsg_new(NLMSG_GOODSIZE, GFP_KERNEL);
+	if (!nskb) {
+		kz_err("failed to allocate reply message\n");
+		res = -ENOMEM;
+		goto error_unlock_zone;
+	}
+
+	if (kznl_build_zone(nskb, info->snd_pid,
+			    info->snd_seq, 0, zone, cfg) < 0) {
+		/* data did not fit in a single entry -- for now no support of continuation
+		   we could loop and multicast; we chose not to send the partial info */
+		kz_err("failed to create zone messages\n");
+		res = -ENOMEM;
+		goto error_free_skb;
+	}
+
+	rcu_read_unlock();
+
+	return genlmsg_reply(nskb, info);
+
+error_free_skb:
+	nlmsg_free(nskb);
+
+error_unlock_zone:
+	rcu_read_unlock();;
+
+	if (zone_name != NULL)
+		kfree(zone_name);
+
+error:
+	return res;
+}
+
+static int
+kznl_recv_add_service(struct sk_buff *skb, struct genl_info *info)
+{
+	int res = 0;
+	struct kz_service *svc, *p;
+	struct kz_transaction *tr;
+	u_int32_t count;
+
+	if (!info->attrs[KZNL_ATTR_SERVICE_PARAMS] || !info->attrs[KZNL_ATTR_SERVICE_NAME]) {
+		kz_err("required attributes missing\n");
+		res = -EINVAL;
+		goto error;
+	}
+
+	/* allocate service structure */
+	svc = kz_service_new();
+	if (svc == NULL) {
+		kz_err("failed to allocate service structure\n");
+		res = -ENOMEM;
+		goto error;
+	}
+
+	/* fill fields */
+	res = kznl_parse_service_params(info->attrs[KZNL_ATTR_SERVICE_PARAMS], svc);
+	if (res < 0 ||
+	    (svc->type != KZ_SERVICE_PROXY && svc->type != KZ_SERVICE_FORWARD && svc->type != KZ_SERVICE_DENY)) {
+		kz_err("failed to parse service parameters\n");
+		goto error_put_svc;
+	}
+
+	/* forwarded service, not transparent -> we need router destination */
+	if (svc->type == KZ_SERVICE_FORWARD && !(svc->flags & KZF_SERVICE_TRANSPARENT)) {
+		if (!info->attrs[KZNL_ATTR_SERVICE_ROUTER_DST_PORT]) {
+			kz_err("required router destination port attribute missing\n");
+			res = -EINVAL;
+			goto error_put_svc;
+		}
+		if (!info->attrs[KZNL_ATTR_SERVICE_ROUTER_DST_ADDR]) {
+			kz_err("required router destination address attribute missing\n");
+			res = -EINVAL;
+			goto error_put_svc;
+		}
+	}
+
+	/* for deny service we require the reject type to be specified */
+	if (svc->type == KZ_SERVICE_DENY) {
+		if (!info->attrs[KZNL_ATTR_SERVICE_DENY_IPV4_METHOD]) {
+			kz_err("required IPv4 reject method attribute missing\n");
+			res = -EINVAL;
+			goto error_put_svc;
+		}
+		if (!info->attrs[KZNL_ATTR_SERVICE_DENY_IPV6_METHOD]) {
+			kz_err("required IPv6 reject method attribute missing\n");
+			res = -EINVAL;
+			goto error_put_svc;
+		}
+	}
+
+	res = kznl_parse_name_alloc(info->attrs[KZNL_ATTR_SERVICE_NAME], &svc->name);
+	if (res < 0) {
+		kz_err("failed to parse service name\n");
+		goto error_put_svc;
+	}
+
+	if (info->attrs[KZNL_ATTR_SERVICE_SESSION_CNT]) {
+		res = kznl_parse_service_session_cnt(info->attrs[KZNL_ATTR_SERVICE_SESSION_CNT], &count);
+		if (res < 0) {
+			kz_err("failed to parse session counter\n");
+			goto error_put_svc;
+		}
+		atomic_set(&svc->session_cnt, count);
+	}
+
+	switch (svc->type) {
+	case KZ_SERVICE_PROXY:
+		kz_debug("service structure created, proxy type\n");
+		break;
+
+	case KZ_SERVICE_FORWARD:
+		INIT_LIST_HEAD(&svc->a.fwd.snat);
+		INIT_LIST_HEAD(&svc->a.fwd.dnat);
+
+		/* for non-transparent services we also need the router target address */
+		if (!(svc->flags & KZF_SERVICE_TRANSPARENT)) {
+			res = kznl_parse_service_router_dst(info->attrs, svc);
+			if (res < 0) {
+				kz_err("failed to parse router target address\n");
+				goto error_put_svc;
+			}
+		}
+
+		kz_debug("service structure created, forwarded type\n");
+		break;
+
+	case KZ_SERVICE_DENY:
+		res = kznl_parse_service_ipv4_deny_method(info->attrs[KZNL_ATTR_SERVICE_DENY_IPV4_METHOD],
+							  &svc->a.deny.ipv4_reject_method);
+		if (res < 0) {
+			kz_err("failed to parse deny service IPv4 reject method\n");
+			goto error_put_svc;
+		}
+
+		res = kznl_parse_service_ipv6_deny_method(info->attrs[KZNL_ATTR_SERVICE_DENY_IPV6_METHOD],
+							  &svc->a.deny.ipv6_reject_method);
+		if (res < 0) {
+			kz_err("failed to parse deny service IPv6 reject method\n");
+			goto error_put_svc;
+		}
+
+		kz_debug("service structure created, deny type\n");
+		break;
+
+	default:
+		kz_err("invalid service type specified; type='%d'\n", svc->type);
+		res = -EINVAL;
+		goto error_put_svc;
+	}
+
+	/* look up transaction */
+	LOCK_TRANSACTIONS();
+
+	tr = transaction_lookup(info->snd_pid);
+	if (tr == NULL) {
+		kz_err("no transaction found; pid='%d'\n", info->snd_pid);
+		res = -ENOENT;
+		goto error_unlock_tr;
+	}
+
+	svc->instance_id = tr->instance_id;
+
+	/* check that we don't yet have a service with the same name */
+	p = transaction_service_lookup(tr, svc->name);
+	if (p != NULL) {
+		kz_err("service with the same name already present; name='%s'\n", svc->name);
+		res = -EEXIST;
+		goto error_unlock_op;
+	}
+
+	p = kz_service_lookup_name(tr->cfg, svc->name);
+	if (p != NULL) {
+		if ((p->instance_id != tr->instance_id) ||
+		    !(tr->flags & KZF_TRANSACTION_FLUSH_SERVICES)) {
+			kz_err("service with the same name already present; name='%s'\n", svc->name);
+			res = -EEXIST;
+			goto error_unlock_op;
+		}
+	}
+
+	res = transaction_add_op(tr, KZNL_OP_SERVICE, kz_service_get(svc), transaction_destroy_service);
+	if (res < 0) {
+		kz_err("failed to queue transaction operation\n");
+	}
+
+error_unlock_op:
+error_unlock_tr:
+	UNLOCK_TRANSACTIONS();
+
+error_put_svc:
+	kz_service_put(svc);
+
+error:
+	return res;
+}
+
+static int
+kznl_recv_add_service_nat(struct sk_buff *skb, struct genl_info *info, bool snat)
+{
+	int res = 0;
+	struct kz_service *svc;
+	struct kz_transaction *tr;
+	char *service_name = NULL;
+	struct nf_nat_ipv4_range src, dst, map;
+
+	if (!info->attrs[KZNL_ATTR_SERVICE_NAME] || !info->attrs[KZNL_ATTR_SERVICE_NAT_SRC] ||
+	    !info->attrs[KZNL_ATTR_SERVICE_NAT_MAP]) {
+		kz_err("required attributes missing\n");
+		res = -EINVAL;
+		goto error;
+	}
+
+	/* parse attributes */
+	res = kznl_parse_name_alloc(info->attrs[KZNL_ATTR_SERVICE_NAME], &service_name);
+	if (res < 0) {
+		kz_err("failed to parse service name\n");
+		goto error;
+	}
+
+	memset(&src, 0, sizeof(src));
+	res = kznl_parse_service_nat_params(info->attrs[KZNL_ATTR_SERVICE_NAT_SRC], &src);
+	if (res < 0) {
+		kz_err("failed to parse source IP range\n");
+		goto error;
+	}
+
+	memset(&dst, 0, sizeof(dst));
+	if (info->attrs[KZNL_ATTR_SERVICE_NAT_DST]) {
+		res = kznl_parse_service_nat_params(info->attrs[KZNL_ATTR_SERVICE_NAT_DST], &dst);
+		if (res < 0) {
+			kz_err("failed to parse destination IP range\n");
+			goto error;
+		}
+	}
+
+	memset(&map, 0, sizeof(map));
+	res = kznl_parse_service_nat_params(info->attrs[KZNL_ATTR_SERVICE_NAT_MAP], &map);
+	if (res < 0) {
+		kz_err("failed to parse IP range to map to\n");
+		goto error;
+	}
+
+	/* look up transaction */
+	LOCK_TRANSACTIONS();
+
+	tr = transaction_lookup(info->snd_pid);
+	if (tr == NULL) {
+		kz_err("no transaction found; pid='%u'\n", info->snd_pid);
+		res = -ENOENT;
+		goto error_unlock_tr;
+	}
+
+	/* look up service */
+	svc = transaction_service_lookup(tr, service_name);
+	if (svc == NULL) {
+		kz_err("no such service found; name='%s'\n", service_name);
+		res = -ENOENT;
+		goto error_unlock_svc;
+	}
+
+	if (snat)
+		res = kz_service_add_nat_entry(&svc->a.fwd.snat, &src,
+					       info->attrs[KZNL_ATTR_SERVICE_NAT_DST] ? &dst : NULL,
+					       &map);
+	else
+		res = kz_service_add_nat_entry(&svc->a.fwd.dnat, &src,
+					       info->attrs[KZNL_ATTR_SERVICE_NAT_DST] ? &dst : NULL,
+					       &map);
+
+error_unlock_svc:
+error_unlock_tr:
+	UNLOCK_TRANSACTIONS();
+
+	if (service_name != NULL)
+		kfree(service_name);
+
+error:
+	return res;
+}
+
+static int
+kznl_recv_add_service_nat_src(struct sk_buff *skb, struct genl_info *info)
+{
+	return kznl_recv_add_service_nat(skb, info, true);
+}
+
+static int
+kznl_recv_add_service_nat_dst(struct sk_buff *skb, struct genl_info *info)
+{
+	return kznl_recv_add_service_nat(skb, info, false);
+}
+
+static int
+kznl_build_service_add_nat(struct sk_buff *skb, netlink_port_t pid, u_int32_t seq, int flags,
+			   enum kznl_msg_types msg,
+			   const struct kz_service *svc, struct kz_service_nat_entry *entry)
+{
+	void *hdr;
+	struct kza_service_nat_params nat;
+
+	memset(&nat, 0, sizeof(nat));
+
+	hdr = genlmsg_put(skb, pid, seq, &kznl_family, flags, msg);
+	if (!hdr)
+		goto nla_put_failure;
+
+	if (kznl_dump_name(skb, KZNL_ATTR_SERVICE_NAME, svc->name) < 0)
+		goto nlmsg_failure;
+
+	if (kznl_dump_service_nat_entry(&nat, &entry->src) < 0)
+		goto nlmsg_failure;
+	NLA_PUT(skb, KZNL_ATTR_SERVICE_NAT_SRC, sizeof(nat), &nat);
+
+	if (entry->dst.min_ip != 0) {
+		if (kznl_dump_service_nat_entry(&nat, &entry->dst) < 0)
+			goto nlmsg_failure;
+		NLA_PUT(skb, KZNL_ATTR_SERVICE_NAT_DST, sizeof(nat), &nat);
+	}
+
+	if (kznl_dump_service_nat_entry(&nat, &entry->map) < 0)
+		goto nlmsg_failure;
+	NLA_PUT(skb, KZNL_ATTR_SERVICE_NAT_MAP, sizeof(nat), &nat);
+
+	return genlmsg_end(skb, hdr);
+
+nlmsg_failure:
+nla_put_failure:
+	genlmsg_cancel(skb, hdr);
+	return -1;
+}
+
+static int
+kznl_build_service_add(struct sk_buff *skb, netlink_port_t pid, u_int32_t seq, int flags,
+		       enum kznl_msg_types msg, const struct kz_service *svc)
+{
+	void *hdr;
+	struct kza_service_params params;
+	struct kza_service_session_cnt cnt;
+
+	hdr = genlmsg_put(skb, pid, seq, &kznl_family, flags, msg);
+	if (!hdr)
+		goto nla_put_failure;
+
+	params.type = svc->type;
+	params.flags = htonl(svc->flags & KZF_SERVICE_PUBLIC_FLAGS);
+	NLA_PUT(skb, KZNL_ATTR_SERVICE_PARAMS, sizeof(params), &params);
+
+	if (kznl_dump_name(skb, KZNL_ATTR_SERVICE_NAME, svc->name) < 0)
+		goto nla_put_failure;
+
+	switch (svc->type) {
+	case KZ_SERVICE_PROXY:
+		/* no extra attributes for proxy services */
+		break;
+
+	case KZ_SERVICE_FORWARD:
+		if (!(svc->flags & KZF_SERVICE_TRANSPARENT)) {
+			if (kznl_dump_inet_addr(skb, KZNL_ATTR_SERVICE_ROUTER_DST_ADDR,
+						svc->a.fwd.router_dst_addr_family,
+						&svc->a.fwd.router_dst_addr) < 0)
+				goto nla_put_failure;
+			if (kznl_dump_port(skb, KZNL_ATTR_SERVICE_ROUTER_DST_PORT,
+					   svc->a.fwd.router_dst_port) < 0)
+				goto nla_put_failure;
+		}
+		break;
+
+	case KZ_SERVICE_DENY:
+		if (kznl_dump_service_deny_method(skb, KZNL_ATTR_SERVICE_DENY_IPV4_METHOD,
+						  svc->a.deny.ipv4_reject_method) < 0)
+			goto nla_put_failure;
+		if (kznl_dump_service_deny_method(skb, KZNL_ATTR_SERVICE_DENY_IPV6_METHOD,
+						  svc->a.deny.ipv6_reject_method) < 0)
+			goto nla_put_failure;
+		break;
+
+	case KZ_SERVICE_INVALID:
+	case KZ_SERVICE_TYPE_COUNT:
+		BUG();
+		break;
+	}
+
+	cnt.count = htonl(atomic_read(&svc->session_cnt));
+	NLA_PUT(skb, KZNL_ATTR_SERVICE_SESSION_CNT, sizeof(cnt), &cnt);
+
+	return genlmsg_end(skb, hdr);
+
+nla_put_failure:
+	genlmsg_cancel(skb, hdr);
+	return -1;
+}
+
+static int
+kznl_build_service(struct sk_buff *skb, netlink_port_t pid, u_int32_t seq, int flags,
+		   const struct kz_service *svc)
+{
+	struct kz_service_nat_entry *entry;
+	unsigned char *msg_start;
+
+	msg_start = skb_tail_pointer(skb);
+
+	if (kznl_build_service_add(skb, pid, seq, flags, KZNL_MSG_ADD_SERVICE, svc) < 0)
+		goto nlmsg_failure;
+
+	/* NAT entries */
+	if (svc->type == KZ_SERVICE_FORWARD) {
+		/* source */
+		list_for_each_entry(entry, &svc->a.fwd.snat, list)
+			if (kznl_build_service_add_nat(skb, pid, seq, flags,
+						       KZNL_MSG_ADD_SERVICE_NAT_SRC,
+						       svc, entry) < 0)
+				goto nlmsg_failure;
+		/* destination */
+		list_for_each_entry(entry, &svc->a.fwd.dnat, list)
+			if (kznl_build_service_add_nat(skb, pid, seq, flags,
+						       KZNL_MSG_ADD_SERVICE_NAT_DST,
+						       svc, entry) < 0)
+				goto nlmsg_failure;
+	}
+
+	return skb_tail_pointer(skb) - msg_start;
+
+nlmsg_failure:
+	skb_trim(skb, msg_start - skb->data);
+	return -1;
+}
+
+/* callback argument allocation for service dump */
+enum {
+	SERVICE_DUMP_CURRENT_SERVICE = 0,
+	SERVICE_DUMP_STATE = 3,
+	SERVICE_DUMP_CONFIG_GEN = 4,
+} kznl_service_dump_args;
+
+/* service dump states */
+enum {
+	SERVICE_DUMP_STATE_FIRST_CALL = 0,
+	SERVICE_DUMP_STATE_HAVE_CONFIG_GEN = 1,
+	SERVICE_DUMP_STATE_NO_MORE_WORK = 2,
+} kznl_service_dump_state;
+
+static int
+kznl_dump_services(struct sk_buff *skb, struct netlink_callback *cb)
+{
+	const struct kz_service *i, *last;
+	const struct kz_config * cfg;
+
+	/*
+	 * race condition recovery: restart dump
+	 * (if this turns to be a problem, cfg shall be refcounted!)
+	 *
+	 * on first entry cb->args is all-0
+	 */
+
+	/* check if we've finished the dump */
+	if (cb->args[SERVICE_DUMP_STATE] == SERVICE_DUMP_STATE_NO_MORE_WORK)
+		return skb->len;
+
+	rcu_read_lock();
+	cfg = rcu_dereference(kz_config_rcu);
+	if (cb->args[SERVICE_DUMP_STATE] == SERVICE_DUMP_STATE_FIRST_CALL ||
+	    !kz_generation_valid(cfg, cb->args[SERVICE_DUMP_CONFIG_GEN])) {
+		cb->args[SERVICE_DUMP_CONFIG_GEN] = kz_generation_get(cfg);
+		cb->args[SERVICE_DUMP_STATE] = SERVICE_DUMP_STATE_HAVE_CONFIG_GEN;
+		cb->args[SERVICE_DUMP_CURRENT_SERVICE] = 0;
+	}
+
+restart:
+	last = (const struct kz_service *)cb->args[SERVICE_DUMP_CURRENT_SERVICE];
+	list_for_each_entry(i, &cfg->services.head, list) {
+		/* check if we're continuing from a given entry */
+		if (last != NULL) {
+			if (i == last) {
+				/* ok, this was the last entry we've tried to dump */
+				cb->args[SERVICE_DUMP_CURRENT_SERVICE] = 0;
+				last = NULL;
+			} else
+				continue;
+		}
+
+		if (kznl_build_service(skb, NETLINK_CB(cb->skb).pid,
+				       cb->nlh->nlmsg_seq, NLM_F_MULTI, i) < 0) {
+			/* service dump failed, try to continue from here next time */
+			cb->args[SERVICE_DUMP_CURRENT_SERVICE] = (long) i;
+			goto out;
+		}
+	}
+
+	if (last != NULL) {
+		/* we've tried to continue an interrupted dump but did not find the
+		 * restart point. cannot do any better but start again. */
+		cb->args[SERVICE_DUMP_CURRENT_SERVICE] = 0;
+		goto restart;
+	}
+
+	/* done */
+	cb->args[SERVICE_DUMP_STATE] = SERVICE_DUMP_STATE_NO_MORE_WORK;;
+
+out:
+	rcu_read_unlock();
+	return skb->len;
+}
+
+static int
+kznl_recv_get_service(struct sk_buff *skb, struct genl_info *info)
+{
+	int res = 0;
+	char *service_name = NULL;
+	struct kz_service *svc;
+	struct sk_buff *nskb = NULL;
+
+	/* parse attributes */
+	if (!info->attrs[KZNL_ATTR_SERVICE_NAME]) {
+		kz_err("required name attribute missing\n");
+		res = -EINVAL;
+		goto error;
+	}
+
+	res = kznl_parse_name_alloc(info->attrs[KZNL_ATTR_SERVICE_NAME], &service_name);
+	if (res < 0) {
+		kz_err("failed to parse service name\n");
+		goto error;
+	}
+
+	rcu_read_lock();
+
+	svc = kz_service_lookup_name(rcu_dereference(kz_config_rcu), service_name);
+	if (svc == NULL) {
+		kz_debug("no such service found; name='%s'\n", service_name);
+		res = -ENOENT;
+		goto error_unlock_svc;
+	}
+
+	/* create skb and dump */
+	nskb = genlmsg_new(NLMSG_GOODSIZE, GFP_KERNEL);
+	if (!nskb) {
+		kz_err("failed to allocate reply message\n");
+		res = -ENOMEM;
+		goto error_unlock_svc;
+	}
+
+	if (kznl_build_service(nskb, info->snd_pid,
+			       info->snd_seq, 0, svc) < 0) {
+		kz_err("failed to create service messages\n");
+		res = -ENOMEM;
+		goto error_free_skb;
+	}
+
+	rcu_read_unlock();
+
+	return genlmsg_reply(nskb, info);
+
+error_free_skb:
+	nlmsg_free(nskb);
+
+error_unlock_svc:
+	rcu_read_unlock();
+
+	if (service_name != NULL)
+		kfree(service_name);
+
+error:
+	return res;
+}
+
+static int
+kznl_recv_add_dispatcher(struct sk_buff *skb, struct genl_info *info)
+{
+	int res = 0;
+	struct kz_dispatcher *dpt, *p;
+	struct kz_transaction *tr;
+
+	if (!info->attrs[KZNL_ATTR_DISPATCHER_NAME]) {
+		kz_err("required attribtues missing\n");
+		res = -EINVAL;
+		goto error;
+	}
+
+	/* allocate dispatcher structure */
+	dpt = kz_dispatcher_new();
+	if (dpt == NULL) {
+		kz_err("failed to allocate dispatcher structure\n");
+		res = -ENOMEM;
+		goto error;
+	}
+
+	/* fill fields */
+	res = kznl_parse_name_alloc(info->attrs[KZNL_ATTR_DISPATCHER_NAME], &dpt->name);
+	if (res < 0) {
+		kz_err("failed to parse dispatcher name\n");
+		goto error_put_dpt;
+	}
+
+	if (!info->attrs[KZNL_ATTR_DISPATCHER_N_DIMENSION_PARAMS]) {
+		kz_err("required attribute missing: n dimension info\n");
+		res = -EINVAL;
+		goto error_put_dpt;
+	}
+
+	res = kznl_parse_dispatcher_n_dimension(info->attrs[KZNL_ATTR_DISPATCHER_N_DIMENSION_PARAMS], dpt);
+	if (res < 0) {
+		kz_err("failed to parse n dimension attribute\n");
+		goto error_put_dpt;
+	}
+
+	/* look up transaction */
+	LOCK_TRANSACTIONS();
+
+	tr = transaction_lookup(info->snd_pid);
+	if (tr == NULL) {
+		kz_err("no transaction found; pid='%d'\n", info->snd_pid);
+		res = -ENOENT;
+		goto error_unlock_tr;
+	}
+
+	dpt->instance = kz_instance_lookup_id(tr->instance_id);
+
+	/* check that we don't yet have a dispatcher with the same name */
+	p = transaction_dispatcher_lookup(tr, dpt->name);
+	if (p != NULL) {
+		kz_err("dispatcher with the same name already present; name='%s'\n", dpt->name);
+		res = -EEXIST;
+		goto error_unlock_op;
+	}
+
+	res = transaction_add_op(tr, KZNL_OP_DISPATCHER, kz_dispatcher_get(dpt), transaction_destroy_dispatcher);
+	if (res < 0) {
+		kz_err("failed to queue transaction operation\n");
+	}
+
+error_unlock_op:
+error_unlock_tr:
+	UNLOCK_TRANSACTIONS();
+
+error_put_dpt:
+	kz_dispatcher_put(dpt);
+
+error:
+	return res;
+}
+
+static int
+kznl_recv_add_n_dimension_rule(struct sk_buff *skb, struct genl_info *info)
+{
+	int res = 0;
+	char *dpt_name = NULL;
+	char *svc_name = NULL;
+	struct kz_service *svc;
+	enum kznl_attr_types attr_type;
+	struct kz_dispatcher *dpt;
+	struct kz_transaction *tr;
+	struct kz_dispatcher_n_dimension_rule rule;
+
+	if (!info->attrs[KZNL_ATTR_N_DIMENSION_RULE_ID]) {
+		kz_err("required attribtues missing; attr='rule id'\n");
+		res = -EINVAL;
+		goto error;
+	}
+
+	if (!info->attrs[KZNL_ATTR_DISPATCHER_NAME]) {
+		kz_err("required attribtues missing; attr='dispatcher name'\n");
+		res = -EINVAL;
+		goto error;
+	}
+
+	if (!info->attrs[KZNL_ATTR_N_DIMENSION_RULE_SERVICE]) {
+		kz_err("required attribtues missing; attr='service name'\n");
+		res = -EINVAL;
+		goto error;
+	}
+
+	res = kznl_parse_name_alloc(info->attrs[KZNL_ATTR_DISPATCHER_NAME], &dpt_name);
+	if (res < 0) {
+		kz_err("failed to parse dispatcher name\n");
+		goto error;
+	}
+
+	res = kznl_parse_name_alloc(info->attrs[KZNL_ATTR_N_DIMENSION_RULE_SERVICE], &svc_name);
+	if (res < 0) {
+		kz_err("failed to parse service name\n");
+		goto error_free_dpt_name;
+	}
+
+	/* parse attributes */
+	memset(&rule, 0, sizeof(struct kz_dispatcher_n_dimension_rule));
+
+	res = kznl_parse_dispatcher_n_dimension_rule(info->attrs[KZNL_ATTR_N_DIMENSION_RULE_ID], &rule);
+	if (res < 0) {
+		kz_err("failed to parse rule id\n");
+		goto error_free_svc_name;
+	}
+
+	for (attr_type = KZNL_ATTR_INVALID; attr_type < KZNL_ATTR_TYPE_COUNT; attr_type++) {
+		if (!info->attrs[attr_type])
+			continue;
+
+		switch (attr_type) {
+#define GENERATE_case_n_dimension_rule_alloc_value_set(DIM_NAME, NL_ATTR_NAME, _, NL_TYPE, ...) \
+		case KZNL_ATTR_N_DIMENSION_##NL_ATTR_NAME: \
+			rule.alloc_##DIM_NAME = ntohl(*(__be32 *) nla_data(info->attrs[attr_type])); \
+			break;
+
+		KZORP_DIM_LIST(GENERATE_case_n_dimension_rule_alloc_value_set, ;);
+
+#undef GENERATE_case_n_dimension_rule_alloc_value_set
+
+		case KZNL_ATTR_DISPATCHER_NAME:
+		case KZNL_ATTR_N_DIMENSION_RULE_ID:
+		case KZNL_ATTR_N_DIMENSION_RULE_SERVICE:
+			/* Skip attribute types handled above. */
+			break;
+		case KZNL_ATTR_INVALID:
+		case KZNL_ATTR_INSTANCE_NAME:
+		case KZNL_ATTR_ZONE_NAME:
+		case KZNL_ATTR_ZONE_UNAME:
+		case KZNL_ATTR_ZONE_PNAME:
+		case KZNL_ATTR_ZONE_RANGE:
+		case KZNL_ATTR_SERVICE_PARAMS:
+		case KZNL_ATTR_SERVICE_NAME:
+		case KZNL_ATTR_SERVICE_NAT_SRC:
+		case KZNL_ATTR_SERVICE_NAT_DST:
+		case KZNL_ATTR_SERVICE_NAT_MAP:
+		case KZNL_ATTR_SERVICE_SESSION_CNT:
+		case KZNL_ATTR_QUERY_PARAMS:
+		case KZNL_ATTR_QUERY_REPLY_CLIENT_ZONE:
+		case KZNL_ATTR_QUERY_REPLY_SERVER_ZONE:
+		case KZNL_ATTR_DISPATCHER_N_DIMENSION_PARAMS:
+		case KZNL_ATTR_CONFIG_COOKIE:
+		case KZNL_ATTR_INET_ADDR:
+		case KZNL_ATTR_INET_SUBNET:
+		case KZNL_ATTR_INET6_ADDR:
+		case KZNL_ATTR_INET6_SUBNET:
+		case KZNL_ATTR_QUERY_PARAMS_SRC_IP:
+		case KZNL_ATTR_QUERY_PARAMS_DST_IP:
+		case KZNL_ATTR_QUERY_PARAMS_REQID:
+		case KZNL_ATTR_QUERY_PARAMS_SRC_PORT:
+		case KZNL_ATTR_QUERY_PARAMS_DST_PORT:
+		case KZNL_ATTR_QUERY_PARAMS_PROTO_TYPE:
+		case KZNL_ATTR_QUERY_PARAMS_PROTO_SUBTYPE:
+		case KZNL_ATTR_SERVICE_ROUTER_DST_ADDR:
+		case KZNL_ATTR_SERVICE_ROUTER_DST_PORT:
+		case KZNL_ATTR_BIND_PROTO:
+		case KZNL_ATTR_BIND_PORT:
+		case KZNL_ATTR_BIND_ADDR:
+		case KZNL_ATTR_MAJOR_VERSION:
+		case KZNL_ATTR_COMPAT_VERSION:
+		case KZNL_ATTR_SERVICE_DENY_IPV4_METHOD:
+		case KZNL_ATTR_SERVICE_DENY_IPV6_METHOD:
+		case KZNL_ATTR_TYPE_COUNT:
+			kz_err("invalid attribute type; attr_type='%d'", attr_type);
+			res = -EINVAL;
+			goto error_free_svc_name;
+		}
+	}
+
+	/* look up transaction */
+	LOCK_TRANSACTIONS();
+
+	tr = transaction_lookup(info->snd_pid);
+	if (tr == NULL) {
+		kz_err("no transaction found; pid='%d'\n", info->snd_pid);
+		res = -ENOENT;
+		goto error_unlock_tr;
+	}
+
+	/* check that we have a dispatcher with the same name */
+	dpt = transaction_dispatcher_lookup(tr, dpt_name);
+	if (dpt == NULL) {
+		kz_err("dispatcher not found for the rule; name='%s'\n", dpt_name);
+		res = -ENOENT;
+		goto error_unlock_tr;
+	}
+
+	if (transaction_rule_lookup(tr, dpt_name, rule.id) != NULL) {
+		kz_err("rule with the same id already present; id='%u'\n", rule.id);
+		res = -EEXIST;
+		goto error_unlock_tr;
+	}
+
+	svc = lookup_service_merged(tr, svc_name);
+	if (svc == NULL) {
+		kz_err("service not found; name='%s'\n", svc_name);
+		res = -ENOENT;
+		goto error_unlock_svc;
+	}
+
+	res = kz_dispatcher_add_rule(dpt, svc, &rule);
+	if (res < 0) {
+		kz_err("failed to add rule; dpt_name='%s', rule_id='%d'\n",
+		       dpt_name, rule.id);
+		goto error_unlock_svc;
+	}
+
+error_unlock_svc:
+error_unlock_tr:
+	UNLOCK_TRANSACTIONS();
+
+error_free_svc_name:
+	kfree(svc_name);
+
+error_free_dpt_name:
+	kfree(dpt_name);
+
+error:
+	return res;
+}
+
+#define KZNL_PARSE_DIMENSION(NAME, TYPE, CONVERTER) \
+			TYPE *NAME = nla_data(info->attrs[attr_type]); \
+			rule_entry.NAME = CONVERTER(*NAME); \
+			rule_entry.has_##NAME = true; \
+
+static int
+kznl_recv_add_n_dimension_rule_entry(struct sk_buff *skb, struct genl_info *info)
+{
+	int res = 0;
+	char *dpt_name = NULL, *src_zone_name = NULL, *dst_zone_name = NULL;
+	enum kznl_attr_types attr_type;
+	struct kz_dispatcher *dpt;
+	struct kz_transaction *tr;
+	struct kz_dispatcher_n_dimension_rule *rule;
+	struct kz_dispatcher_n_dimension_rule_entry_params rule_entry;
+
+	if (!info->attrs[KZNL_ATTR_DISPATCHER_NAME]) {
+		kz_err("required attribtues missing; attr='dispatcher name'\n");
+		res = -EINVAL;
+		goto error;
+	}
+
+	if (!info->attrs[KZNL_ATTR_N_DIMENSION_RULE_ID]) {
+		kz_err("required attribtues missing; attr='rule id'\n");
+		res = -EINVAL;
+		goto error;
+	}
+
+	res = kznl_parse_name_alloc(info->attrs[KZNL_ATTR_DISPATCHER_NAME], &dpt_name);
+	if (res < 0) {
+		kz_err("failed to parse dispatcher name\n");
+		goto error;
+	}
+
+	memset(&rule_entry, 0, sizeof(rule_entry));
+
+	res = kznl_parse_dispatcher_n_dimension_rule_entry(info->attrs[KZNL_ATTR_N_DIMENSION_RULE_ID], &rule_entry);
+	if (res < 0) {
+		kz_err("failed to parse rule id\n");
+		goto error_free_names;
+	}
+
+	for (attr_type = KZNL_ATTR_INVALID; attr_type < KZNL_ATTR_TYPE_COUNT; attr_type++) {
+		if (!info->attrs[attr_type])
+			continue;
+
+		switch (attr_type) {
+		case KZNL_ATTR_N_DIMENSION_IFACE: {
+			res = kznl_parse_name(info->attrs[attr_type], (char *) &rule_entry.ifname, sizeof(rule_entry.ifname));
+			if (res < 0) {
+				kz_err("failed to parse interface name\n");
+				goto error_free_names;
+			}
+			rule_entry.has_ifname = true;
+			break;
+		}
+		case KZNL_ATTR_N_DIMENSION_IFGROUP: {
+			__be32 *ifgroup = nla_data(info->attrs[attr_type]);
+			rule_entry.ifgroup = ntohl(*ifgroup);
+			rule_entry.has_ifgroup = true;
+			break;
+		}
+		case KZNL_ATTR_N_DIMENSION_PROTO: {
+			u_int8_t *proto = nla_data(info->attrs[attr_type]);
+			rule_entry.proto = *proto;
+			rule_entry.has_proto = true;
+			break;
+		}
+		case KZNL_ATTR_N_DIMENSION_PROTO_TYPE: {
+			KZNL_PARSE_DIMENSION(proto_type, __be32, ntohl);
+			break;
+		}
+		case KZNL_ATTR_N_DIMENSION_PROTO_SUBTYPE: {
+			KZNL_PARSE_DIMENSION(proto_subtype, __be32, ntohl);
+			break;
+		}
+		case KZNL_ATTR_N_DIMENSION_SRC_PORT: {
+			res = kznl_parse_port_range(info->attrs[attr_type], &rule_entry.src_port.from, &rule_entry.src_port.to);
+			if (res < 0) {
+				kz_err("failed to parse source port range\n");
+				goto error_free_names;
+			}
+			rule_entry.has_src_port = true;
+			break;
+		}
+		case KZNL_ATTR_N_DIMENSION_DST_PORT: {
+			res = kznl_parse_port_range(info->attrs[attr_type], &rule_entry.dst_port.from, &rule_entry.dst_port.to);
+			if (res < 0) {
+				kz_err("failed to parse source port range\n");
+				goto error_free_names;
+			}
+			rule_entry.has_dst_port = true;
+			break;
+		}
+		case KZNL_ATTR_N_DIMENSION_SRC_IP: {
+			res = kznl_parse_in_subnet(info->attrs[attr_type], &rule_entry.src_in_subnet.addr, &rule_entry.src_in_subnet.mask);
+			if (res < 0) {
+				kz_err("failed to parse source subnet\n");
+				goto error_free_names;
+			}
+			rule_entry.has_src_in_subnet = true;
+			break;
+		}
+		case KZNL_ATTR_N_DIMENSION_SRC_ZONE: {
+			res = kznl_parse_name_alloc(info->attrs[attr_type], &src_zone_name);
+			if (res < 0) {
+				kz_err("failed to parse source zone name\n");
+				goto error_free_names;
+			}
+			rule_entry.has_src_zone = true;
+			break;
+		}
+		case KZNL_ATTR_N_DIMENSION_DST_IP: {
+			res = kznl_parse_in_subnet(info->attrs[attr_type], &rule_entry.dst_in_subnet.addr, &rule_entry.dst_in_subnet.mask);
+			if (res < 0) {
+				kz_err("failed to parse destination subnet\n");
+				goto error_free_names;
+			}
+			rule_entry.has_dst_in_subnet = true;
+			break;
+		}
+		case KZNL_ATTR_N_DIMENSION_DST_ZONE: {
+			res = kznl_parse_name_alloc(info->attrs[attr_type], &dst_zone_name);
+			if (res < 0) {
+				kz_err("failed to parse destination zone name\n");
+				goto error_free_names;
+			}
+			rule_entry.has_dst_zone = true;
+			break;
+		}
+		case KZNL_ATTR_N_DIMENSION_SRC_IP6: {
+			res = kznl_parse_in6_subnet(info->attrs[attr_type], &rule_entry.src_in6_subnet.addr, &rule_entry.src_in6_subnet.mask);
+			if (res < 0) {
+				kz_err("failed to parse source IPv6 subnet\n");
+				goto error_free_names;
+			}
+			rule_entry.has_src_in6_subnet = true;
+			break;
+		}
+		case KZNL_ATTR_N_DIMENSION_DST_IP6: {
+			res = kznl_parse_in6_subnet(info->attrs[attr_type], &rule_entry.dst_in6_subnet.addr, &rule_entry.dst_in6_subnet.mask);
+			if (res < 0) {
+				kz_err("failed to parse destination IPv6 subnet\n");
+				goto error_free_names;
+			}
+			rule_entry.has_dst_in6_subnet = true;
+			break;
+		}
+		case KZNL_ATTR_N_DIMENSION_DST_IFACE: {
+			res = kznl_parse_name(info->attrs[attr_type], (char *) &rule_entry.dst_ifname, sizeof(rule_entry.dst_ifname));
+			if (res < 0) {
+				kz_err("failed to parse interface name\n");
+				goto error_free_names;
+			}
+			rule_entry.has_dst_ifname = true;
+			break;
+		}
+		case KZNL_ATTR_N_DIMENSION_DST_IFGROUP: {
+			__be32 *dst_ifgroup = nla_data(info->attrs[attr_type]);
+			rule_entry.dst_ifgroup = ntohl(*dst_ifgroup);
+			rule_entry.has_dst_ifgroup = true;
+			break;
+		}
+		case KZNL_ATTR_N_DIMENSION_REQID: {
+			res = kznl_parse_reqid(info->attrs[attr_type], &rule_entry.reqid);
+			if (res < 0) {
+				kz_err("failed to parse request id\n");
+				goto error_free_names;
+			}
+			rule_entry.has_reqid = true;
+			break;
+		}
+		case KZNL_ATTR_DISPATCHER_NAME:
+		case KZNL_ATTR_N_DIMENSION_RULE_ID:
+		case KZNL_ATTR_N_DIMENSION_RULE_SERVICE:
+			/* Skip attribute types handled above. */
+			break;
+		case KZNL_ATTR_INVALID:
+		case KZNL_ATTR_INSTANCE_NAME:
+		case KZNL_ATTR_ZONE_NAME:
+		case KZNL_ATTR_ZONE_UNAME:
+		case KZNL_ATTR_ZONE_PNAME:
+		case KZNL_ATTR_ZONE_RANGE:
+		case KZNL_ATTR_SERVICE_PARAMS:
+		case KZNL_ATTR_SERVICE_NAME:
+		case KZNL_ATTR_SERVICE_NAT_SRC:
+		case KZNL_ATTR_SERVICE_NAT_DST:
+		case KZNL_ATTR_SERVICE_NAT_MAP:
+		case KZNL_ATTR_SERVICE_SESSION_CNT:
+		case KZNL_ATTR_QUERY_PARAMS:
+		case KZNL_ATTR_QUERY_REPLY_CLIENT_ZONE:
+		case KZNL_ATTR_QUERY_REPLY_SERVER_ZONE:
+		case KZNL_ATTR_DISPATCHER_N_DIMENSION_PARAMS:
+		case KZNL_ATTR_CONFIG_COOKIE:
+		case KZNL_ATTR_INET_ADDR:
+		case KZNL_ATTR_INET_SUBNET:
+		case KZNL_ATTR_INET6_ADDR:
+		case KZNL_ATTR_INET6_SUBNET:
+		case KZNL_ATTR_QUERY_PARAMS_SRC_IP:
+		case KZNL_ATTR_QUERY_PARAMS_DST_IP:
+		case KZNL_ATTR_QUERY_PARAMS_REQID:
+		case KZNL_ATTR_QUERY_PARAMS_SRC_PORT:
+		case KZNL_ATTR_QUERY_PARAMS_DST_PORT:
+		case KZNL_ATTR_QUERY_PARAMS_PROTO_TYPE:
+		case KZNL_ATTR_QUERY_PARAMS_PROTO_SUBTYPE:
+		case KZNL_ATTR_SERVICE_ROUTER_DST_ADDR:
+		case KZNL_ATTR_SERVICE_ROUTER_DST_PORT:
+		case KZNL_ATTR_BIND_PROTO:
+		case KZNL_ATTR_BIND_PORT:
+		case KZNL_ATTR_BIND_ADDR:
+		case KZNL_ATTR_MAJOR_VERSION:
+		case KZNL_ATTR_COMPAT_VERSION:
+		case KZNL_ATTR_SERVICE_DENY_IPV4_METHOD:
+		case KZNL_ATTR_SERVICE_DENY_IPV6_METHOD:
+		case KZNL_ATTR_TYPE_COUNT:
+			kz_err("invalid attribute type; attr_type='%d'", attr_type);
+			res = -EINVAL;
+			goto error_free_names;
+		}
+	}
+
+	/* look up transaction */
+	LOCK_TRANSACTIONS();
+
+	tr = transaction_lookup(info->snd_pid);
+	if (tr == NULL) {
+		kz_err("no transaction found; pid='%d'\n", info->snd_pid);
+		res = -ENOENT;
+		goto error_unlock_tr;
+	}
+
+	rule = transaction_rule_lookup(tr, dpt_name, rule_entry.rule_id);
+	if (rule == NULL) {
+		kz_err("rule not found; id='%d'\n", rule_entry.rule_id);
+		res = -ENOENT;
+		goto error_unlock_tr;
+	}
+
+	/* look up zones */
+	if (src_zone_name != NULL) {
+		rule_entry.src_zone = lookup_zone_merged(tr, src_zone_name);
+		if (rule_entry.src_zone == NULL) {
+			kz_err("source zone not found; name='%s'\n", src_zone_name);
+			res = -ENOENT;
+			goto error_unlock_zone;
+		}
+	}
+	if (dst_zone_name != NULL) {
+		rule_entry.dst_zone = lookup_zone_merged(tr, dst_zone_name);
+		if (rule_entry.dst_zone == NULL) {
+			kz_err("destination zone not found; name='%s'\n", dst_zone_name);
+			res = -ENOENT;
+			goto error_unlock_zone;
+		}
+	}
+
+	/* check that we have a dispatcher with the same name */
+	dpt = transaction_dispatcher_lookup(tr, dpt_name);
+	if (dpt == NULL) {
+		kz_err("dispatcher not found for the rule; name='%s'\n", dpt_name);
+		res = -ENOENT;
+		goto error_unlock_dpt;
+	}
+
+	res = kz_dispatcher_add_rule_entry(rule, &rule_entry);
+	if (res < 0) {
+		kz_err("failed to add rule; dpt_name='%s', rule_id='%d'\n",
+		       dpt_name, rule_entry.rule_id);
+		goto error_unlock_dpt;
+	}
+
+error_unlock_dpt:
+error_unlock_zone:
+error_unlock_tr:
+	UNLOCK_TRANSACTIONS();
+
+error_free_names:
+	kfree(dpt_name);
+	if (src_zone_name)
+		kfree(src_zone_name);
+	if (dst_zone_name)
+		kfree(dst_zone_name);
+
+error:
+	return res;
+}
+
+/* !!! must be called with the instance mutex held !!! */
+struct kz_bind *
+kz_bind_lookup_instance(const struct kz_instance *instance, const struct kz_bind *bind)
+{
+	struct kz_bind *i;
+
+	kz_bind_debug(bind, "lookup item");
+	list_for_each_entry(i, &instance->bind_lookup->list_bind, list) {
+		kz_bind_debug(i, "check item");
+
+		if (kz_bind_eq(i, bind))
+			return i;
+	}
+
+	return NULL;
+}
+
+static inline int
+kznl_parse_bind_alloc(struct nlattr *attrs[], unsigned int instance_id, struct kz_instance **instance, struct kz_bind **_bind)
+{
+	int res = 0;
+	struct kz_bind *bind;
+	char *instance_name = NULL;
+
+	if (!attrs[KZNL_ATTR_INSTANCE_NAME]) {
+		kz_err("required attribtues missing; attr='instance'\n");
+		res = -EINVAL;
+		goto error;
+	}
+
+	if (!attrs[KZNL_ATTR_BIND_PROTO]) {
+		kz_err("required attribtues missing; attr='protocol'\n");
+		res = -EINVAL;
+		goto error;
+	}
+
+	if (!attrs[KZNL_ATTR_BIND_ADDR]) {
+		kz_err("required attribtues missing; attr='bind addr'\n");
+		res = -EINVAL;
+		goto error;
+	}
+
+	if (!attrs[KZNL_ATTR_BIND_PORT]) {
+		kz_err("required attribtues missing; attr='bind port'\n");
+		res = -EINVAL;
+		goto error;
+	}
+
+	res = kznl_parse_name_alloc(attrs[KZNL_ATTR_INSTANCE_NAME], &instance_name);
+	if (res < 0) {
+		kz_err("failed to parse instance name\n");
+		goto error;
+	}
+
+	*instance = kz_instance_lookup(instance_name);
+	if (*instance == NULL) {
+		kz_debug("no such instance found; name='%s'\n", instance_name);
+		res = -ENOENT;
+		goto error_free_name;
+	}
+
+	if ((*instance)->id != instance_id) {
+		kz_debug("transaction instance id and instance id differs; instance_id='%d' tr_instance_id'%d'\n", (*instance)->id, instance_id);
+		res = -EINVAL;
+		goto error_free_name;
+	}
+
+	bind = kz_bind_new();
+
+	if (kznl_parse_proto(attrs[KZNL_ATTR_BIND_PROTO], &bind->proto) < 0) {
+		res = -EINVAL;
+		goto error_free_bind;
+	}
+
+	if (bind->proto != IPPROTO_TCP && bind->proto != IPPROTO_UDP) {
+		kz_err("only TCP and UDP protocols are supported; proto='%d'\n", bind->proto);
+		res = -EINVAL;
+		goto error_free_bind;
+	}
+
+	if (kznl_parse_port(attrs[KZNL_ATTR_BIND_PORT], &bind->port) < 0) {
+		res = -EINVAL;
+		goto error_free_bind;
+	}
+
+	if (kznl_parse_inet_addr(attrs[KZNL_ATTR_BIND_ADDR], &bind->addr, &bind->family) < 0) {
+		res = -EINVAL;
+		goto error_free_bind;
+	}
+
+	*_bind = bind;
+	kfree(instance_name);
+
+	return 0;
+
+error_free_bind:
+	kfree(bind);
+error_free_name:
+	kfree(instance_name);
+error:
+	return res;
+}
+
+static int
+kznl_recv_add_bind(struct sk_buff *skb, struct genl_info *info)
+{
+	int res = 0;
+	struct kz_transaction *tr;
+	struct kz_instance *instance;
+	struct kz_bind *bind = NULL, *found_bind;
+
+	/* look up transaction */
+	LOCK_TRANSACTIONS();
+
+	tr = transaction_lookup(info->snd_pid);
+	if (tr == NULL) {
+		kz_err("no transaction found; pid='%d'\n", info->snd_pid);
+		res = -ENOENT;
+		goto error_unlock_tr;
+	}
+
+	res = kznl_parse_bind_alloc(info->attrs, tr->instance_id, &instance, &bind);
+	if (res < 0)
+		goto error_unlock_tr;
+	bind->peer_pid = info->snd_pid;
+
+	found_bind = kz_bind_lookup_instance(instance, bind);
+	if (found_bind && !(found_bind->peer_pid == bind->peer_pid && (tr->flags & KZF_TRANSACTION_FLUSH_BIND))) {
+		kz_bind_debug(bind, "bind with the same parameters already present in the instance");
+		res = -EEXIST;
+		goto error_free_bind;
+	}
+
+	if (transaction_bind_lookup(tr, bind)) {
+		kz_bind_debug(bind, "bind with the same parameters already present in the transaction");
+		res = -EEXIST;
+		goto error_free_bind;
+	}
+
+	res = transaction_add_op(tr, KZNL_OP_BIND, bind, transaction_destroy_bind);
+	if (res < 0) {
+		kz_err("failed to queue transaction operation\n");
+		goto error_free_bind;
+	} else {
+		kz_bind_debug(bind, "bind added to transaction operation queue");
+	}
+
+error_free_bind:
+	if (res < 0)
+		kfree(bind);
+error_unlock_tr:
+	UNLOCK_TRANSACTIONS();
+
+	return res;
+}
+
+
+static int
+kznl_dump_bind(struct sk_buff *skb, netlink_port_t pid, u_int32_t seq, int flags,
+	       enum kznl_msg_types msg_type, const struct kz_instance *instance, const struct kz_bind *bind)
+{
+	void *hdr;
+
+	hdr = genlmsg_put(skb, pid, seq, &kznl_family, flags, msg_type);
+	if (!hdr)
+		goto nla_put_failure;
+
+	kz_bind_debug(bind, "dump bind");
+
+	NLA_PUT_U8(skb, KZNL_ATTR_BIND_PROTO, bind->proto);
+	NLA_PUT_BE16(skb, KZNL_ATTR_BIND_PORT, htons(bind->port));
+
+	if (kznl_dump_name(skb, KZNL_ATTR_INSTANCE_NAME, instance->name) < 0)
+		goto nla_put_failure;
+
+	if (kznl_dump_inet_addr(skb, KZNL_ATTR_BIND_ADDR, bind->family, &bind->addr) < 0)
+		goto nla_put_failure;
+
+	return genlmsg_end(skb, hdr);
+
+nla_put_failure:
+	genlmsg_cancel(skb, hdr);
+	return -1;
+}
+
+
+static int
+kznl_build_instance_bind(struct sk_buff *skb, u_int32_t pid, u_int32_t seq, int flags,
+			 const struct kz_instance **instance, const struct kz_bind **bind)
+{
+	const struct kz_instance *last_instance;
+	const struct kz_bind *last_bind;
+
+	last_instance = *instance;
+	if (last_instance) {
+		list_for_each_entry((*instance), &kz_instances, list) {
+			if (*instance == last_instance)
+				break;
+		}
+	}
+	if (!*instance)
+		*instance = list_first_entry(&kz_instances, struct kz_instance, list);
+
+	last_bind = *bind;
+	if (last_bind) {
+		list_for_each_entry((*bind), &(*instance)->bind_lookup->list_bind, list) {
+			if (*bind == last_bind)
+				break;
+		}
+	}
+	if (!*bind)
+		*bind = list_first_entry(&(*instance)->bind_lookup->list_bind, struct kz_bind, list);
+
+	last_instance = *instance;
+	list_for_each_entry_from((*instance), &kz_instances, list) {
+		if (*instance != last_instance)
+			*bind = list_first_entry(&(*instance)->bind_lookup->list_bind, struct kz_bind, list);
+
+		list_for_each_entry_from((*bind), &(*instance)->bind_lookup->list_bind, list) {
+			if (kznl_dump_bind(skb, pid, seq, false,
+					   KZNL_MSG_ADD_BIND, *instance, *bind) < 0) {
+				goto error;
+			}
+
+		}
+	}
+
+	return 0;
+
+error:
+	return -1;
+}
+
+enum kz_bind_dump_arg {
+	BIND_DUMP_ARG_INSTANCE,
+	BIND_DUMP_ARG_BIND,
+	BIND_DUMP_ARG_STATE,
+	BIND_DUMP_ARG_CONFIG_GENERATION
+};
+
+enum kz_dump_state {
+	BIND_DUMP_STATE_FIRST_CALL,
+        BIND_DUMP_STATE_HAVE_CONFIG_GEN,
+	BIND_DUMP_STATE_LAST_CALL
+};
+
+static int
+kznl_dump_binds(struct sk_buff *skb, struct netlink_callback *cb)
+{
+	const struct kz_config *config;
+	const struct kz_instance **instance;
+	const struct kz_bind **bind;
+
+	/* check if we've finished the dump */
+	if (cb->args[BIND_DUMP_ARG_STATE] == BIND_DUMP_STATE_LAST_CALL)
+		return skb->len;
+
+	rcu_read_lock();
+	config = rcu_dereference(kz_config_rcu);
+	if (cb->args[BIND_DUMP_ARG_STATE] == BIND_DUMP_STATE_FIRST_CALL ||
+	    !kz_generation_valid(config, cb->args[BIND_DUMP_ARG_CONFIG_GENERATION])) {
+		cb->args[BIND_DUMP_ARG_INSTANCE] = 0;
+		cb->args[BIND_DUMP_ARG_BIND] = 0;
+		cb->args[BIND_DUMP_ARG_STATE] = BIND_DUMP_STATE_HAVE_CONFIG_GEN;
+		cb->args[BIND_DUMP_ARG_CONFIG_GENERATION] = kz_generation_get(config);
+	}
+
+	instance = (const struct kz_instance **) &cb->args[BIND_DUMP_ARG_INSTANCE];
+	bind = (const struct kz_bind **) &cb->args[BIND_DUMP_ARG_BIND];
+	if (kznl_build_instance_bind(skb, NETLINK_CB(cb->skb).pid,
+				     cb->nlh->nlmsg_seq, NLM_F_MULTI,
+				     instance, bind) >= 0)
+		cb->args[BIND_DUMP_ARG_STATE] = BIND_DUMP_STATE_LAST_CALL;
+
+	rcu_read_unlock();
+	return skb->len;
+}
+
+#define kznl_build_dispatcher_rule_entry_value(dim_name, attr_name)	\
+	if (rule->num_##dim_name > entry_num) {				\
+		if (sizeof(rule->dim_name[entry_num]) == 1) {		\
+			NLA_PUT_U8(skb, KZNL_ATTR_N_DIMENSION_##attr_name, \
+				   rule->dim_name[entry_num]);		\
+		}							\
+		else if (sizeof(rule->dim_name[entry_num]) == 2) {	\
+			NLA_PUT_BE16(skb, KZNL_ATTR_N_DIMENSION_##attr_name, \
+				     htons(rule->dim_name[entry_num]));	\
+		}							\
+		else if (sizeof(rule->dim_name[entry_num]) == 4) {	\
+			NLA_PUT_BE32(skb, KZNL_ATTR_N_DIMENSION_##attr_name, \
+				     htonl(rule->dim_name[entry_num]));	\
+		}							\
+		else {							\
+			BUG();						\
+		}							\
+	}
+
+#define kznl_build_dispatcher_rule_entry_string(dim_name, attr_name)	\
+	if (rule->num_##dim_name > entry_num)				\
+		if (kznl_dump_name(skb, KZNL_ATTR_N_DIMENSION_##attr_name, \
+				   rule->dim_name[entry_num]->name) < 0) \
+			goto nla_put_failure;
+
+#define kznl_build_dispatcher_rule_entry_portrange(dim_name, attr_name) \
+	if (rule->num_##dim_name > entry_num)				\
+		if (kznl_dump_port_range(skb, KZNL_ATTR_N_DIMENSION_##attr_name, \
+					 &rule->dim_name[entry_num]) < 0) \
+			goto nla_put_failure;
+
+#define kznl_build_dispatcher_rule_entry_in_subnet(dim_name, attr_name)	\
+	if (rule->num_##dim_name > entry_num)				\
+		if (kznl_dump_in_subnet(skb, KZNL_ATTR_N_DIMENSION_##attr_name, \
+				     &rule->dim_name[entry_num].addr, &rule->dim_name[entry_num].mask) < 0)	\
+			goto nla_put_failure;
+
+#define kznl_build_dispatcher_rule_entry_in6_subnet(dim_name, attr_name)	\
+	if (rule->num_##dim_name > entry_num)				\
+		if (kznl_dump_in6_subnet(skb, KZNL_ATTR_N_DIMENSION_##attr_name, \
+				     &rule->dim_name[entry_num].addr, &rule->dim_name[entry_num].mask) < 0)	\
+			goto nla_put_failure;
+
+#define kznl_build_dispatcher_rule_entry_ifname(dim_name, attr_name) \
+	if (rule->num_##dim_name > entry_num)				\
+		if (kznl_dump_name(skb, KZNL_ATTR_N_DIMENSION_##attr_name, \
+				   rule->dim_name[entry_num]) < 0)	\
+			goto nla_put_failure;
+
+static int
+kznl_build_dispatcher_add_rule_entry(struct sk_buff *skb, u_int32_t pid, u_int32_t seq,
+				     int flags, enum kznl_msg_types msg,
+				     const struct kz_dispatcher * const dpt,
+				     const struct kz_dispatcher_n_dimension_rule *rule,
+				     u_int32_t entry_num)
+{
+	void *hdr;
+
+	hdr = genlmsg_put(skb, pid, seq, &kznl_family, flags, msg);
+	if (!hdr)
+		goto nla_put_failure;
+
+	if (kznl_dump_name(skb, KZNL_ATTR_DISPATCHER_NAME, dpt->name) < 0)
+		goto nla_put_failure;
+
+	NLA_PUT_BE32(skb, KZNL_ATTR_N_DIMENSION_RULE_ID, htonl(rule->id));
+
+#define CALL_kznl_build_dispatcher_rule_entry(DIM_NAME, NL_ATTR_NAME, _, NL_TYPE, ...) \
+	kznl_build_dispatcher_rule_entry_##NL_TYPE(DIM_NAME, NL_ATTR_NAME)
+
+	KZORP_DIM_LIST(CALL_kznl_build_dispatcher_rule_entry, ;);
+
+#undef CALL_kznl_build_dispatcher_rule_entry
+
+	return genlmsg_end(skb, hdr);
+
+nla_put_failure:
+	genlmsg_cancel(skb, hdr);
+	return -1;
+}
+
+static int
+kznl_build_dispatcher_add_rule(struct sk_buff *skb, u_int32_t pid, u_int32_t seq,
+			       int flags, enum kznl_msg_types msg,
+			       const struct kz_dispatcher *dpt,
+			       const struct kz_dispatcher_n_dimension_rule *rule)
+{
+	void *hdr;
+
+	hdr = genlmsg_put(skb, pid, seq, &kznl_family, flags, msg);
+	if (!hdr)
+		goto nla_put_failure;
+
+	if (kznl_dump_name(skb, KZNL_ATTR_DISPATCHER_NAME, dpt->name) < 0)
+		goto nla_put_failure;
+
+	NLA_PUT_BE32(skb, KZNL_ATTR_N_DIMENSION_RULE_ID, htonl(rule->id));
+
+	if (kznl_dump_name(skb, KZNL_ATTR_N_DIMENSION_RULE_SERVICE, rule->service->name) < 0)
+		goto nla_put_failure;
+
+#define KZNL_BUILD_DISPATCHER_RULE_DIMENSION(DIM_NAME, NL_ATTR_NAME, ...)	\
+	if (rule->num_##DIM_NAME > 0)	\
+		NLA_PUT_BE32(skb, KZNL_ATTR_N_DIMENSION_##NL_ATTR_NAME, htonl(rule->num_##DIM_NAME))
+
+	KZORP_DIM_LIST(KZNL_BUILD_DISPATCHER_RULE_DIMENSION, ;);
+
+#undef KZNL_BUILD_DISPATCHER_RULE_DIMENSION
+
+	return genlmsg_end(skb, hdr);
+
+nla_put_failure:
+	genlmsg_cancel(skb, hdr);
+	return -1;
+}
+
+static int
+kznl_build_dispatcher_add(struct sk_buff *skb, u_int32_t pid, u_int32_t seq, int flags,
+			  enum kznl_msg_types msg, const struct kz_dispatcher *dpt)
+{
+	void *hdr;
+	struct kza_dispatcher_n_dimension_params n_dimension;
+
+	hdr = genlmsg_put(skb, pid, seq, &kznl_family, flags, msg);
+
+	if (kznl_dump_name(skb, KZNL_ATTR_DISPATCHER_NAME, dpt->name) < 0)
+		goto nla_put_failure;
+
+	n_dimension.num_rules = htonl(dpt->num_rule);
+	NLA_PUT(skb, KZNL_ATTR_DISPATCHER_N_DIMENSION_PARAMS, sizeof(n_dimension), &n_dimension);
+
+	return genlmsg_end(skb, hdr);
+
+nla_put_failure:
+	genlmsg_cancel(skb, hdr);
+	return -1;
+}
+
+static int
+kznl_build_dispatcher(struct sk_buff *skb, u_int32_t pid, u_int32_t seq, int flags,
+		      const struct kz_dispatcher *dpt, long *part_idx, long *rule_entry_idx)
+{
+	unsigned char *msg_start, *msg_rollback;
+
+	/*
+		part_idx: inout param; must be set to item to resume on next call or 0 for completion
+		  if dispatcher is N_DIMENSION
+			0: means the dispatcher head
+			1..: means the rule index
+		  else
+			0: means the dispatcher head
+			1..: means the CSS index
+		rule_entry_idx: inout param; must be set to item to resume on next call or 0 for completion
+			0: means n_dimension rule
+			1..: means the rule entry index
+
+	*/
+
+	msg_start = skb_tail_pointer(skb);
+	msg_rollback = msg_start;
+
+	if(*part_idx == 0) {
+		msg_rollback = skb_tail_pointer(skb);
+		if (kznl_build_dispatcher_add(skb, pid, seq, flags, KZNL_MSG_ADD_DISPATCHER, dpt) < 0)
+			goto nlmsg_failure;
+		*part_idx = 1;
+	}
+
+	/* dump rule structures */
+	for (; (*part_idx) <= (long) dpt->num_rule; ++(*part_idx)) {
+		u_int32_t max_entry_num = 0;
+		const struct kz_dispatcher_n_dimension_rule *rule = &dpt->rule[(*part_idx) - 1];
+		kz_debug("part_idx=%ld, rule_entry_idx=%ld", *part_idx, *rule_entry_idx);
+
+		if (*rule_entry_idx == 0) {
+			msg_rollback = skb_tail_pointer(skb);
+			if (kznl_build_dispatcher_add_rule(skb, pid, seq, flags,
+							   KZNL_MSG_ADD_RULE,
+							   dpt, rule) < 0)
+				goto nlmsg_failure;
+			*rule_entry_idx = 1;
+		}
+
+#define UPDATE_MAX_ENTRY_NUM(DIM_NAME, ...) \
+	max_entry_num = max(max_entry_num, rule->num_##DIM_NAME)
+
+	KZORP_DIM_LIST(UPDATE_MAX_ENTRY_NUM, ;);
+
+#undef UPDATE_MAX_ENTRY_NUM
+
+		for (; (*rule_entry_idx) <= max_entry_num; ++(*rule_entry_idx)) {
+			kz_debug("rule_entry_idx=%ld", *rule_entry_idx);
+			msg_rollback = skb_tail_pointer(skb);
+			if (kznl_build_dispatcher_add_rule_entry(skb, pid, seq, flags,
+								 KZNL_MSG_ADD_RULE_ENTRY,
+								 dpt, rule, (*rule_entry_idx) - 1) < 0)
+				goto nlmsg_failure;
+		}
+
+		*rule_entry_idx = 0;
+
+	}
+
+	*part_idx = 0;
+	*rule_entry_idx = 0;
+	return skb_tail_pointer(skb) - msg_start;
+
+nlmsg_failure:
+	/* *part_idx is left pointing the failed item */
+	skb_trim(skb, msg_rollback - skb->data);
+	return -1;
+}
+
+enum {
+	DISPATCHER_DUMP_ARG_CURRENT_DISPATCHER,
+	DISPATCHER_DUMP_ARG_SUBPART,
+	DISPATCHER_DUMP_ARG_RULE_ENTRY_SUBPART,
+	DISPATCHER_DUMP_ARG_STATE,
+	DISPATCHER_DUMP_ARG_CONFIG_GENERATION,
+};
+
+enum {
+	DISPATCHER_DUMP_STATE_FIRST_CALL,
+	DISPATCHER_DUMP_STATE_HAVE_CONFIG,
+	DISPATCHER_DUMP_STATE_NO_MORE_WORK,
+};
+
+static int
+kznl_dump_dispatchers(struct sk_buff *skb, struct netlink_callback *cb)
+{
+	const struct kz_dispatcher *i, *last;
+	const struct kz_config * cfg;
+
+/*
+cb->args allocation:
+  [0]: pointer to dispatcher item to be sent; stability from config
+  [1]:  index of dispatcher subpart to send:
+	if dispatcher is N_DIMENSION (0: head, 1..n: rules 0..n-1)
+	else (0: head, 1..n: CSS entries 0..n-1)
+  [2]: if [1] is N_DIMENSION dispatcher, index of rule entry subpart to send (0: rule, 1..n: rule entries)
+  [3]: 0: first call, 1: have config generation, 2: no more work
+  [4]: config generation
+
+race condition recovery: restart dump
+  (if this turns to be a problem, cfg shall be refcounted!)
+
+on first entry cb->args is all-0
+*/
+
+	/* check if we've finished the dump */
+	if (cb->args[DISPATCHER_DUMP_ARG_STATE] == DISPATCHER_DUMP_STATE_NO_MORE_WORK)
+		return skb->len;
+
+	rcu_read_lock();
+
+	/* check config generation and re-get config if necessary */
+	cfg = rcu_dereference(kz_config_rcu);
+	if (cb->args[DISPATCHER_DUMP_ARG_STATE] == DISPATCHER_DUMP_STATE_FIRST_CALL ||
+	    !kz_generation_valid(cfg, cb->args[DISPATCHER_DUMP_ARG_CONFIG_GENERATION])) {
+		cb->args[DISPATCHER_DUMP_ARG_CONFIG_GENERATION] = kz_generation_get(cfg);
+		cb->args[DISPATCHER_DUMP_ARG_STATE] = DISPATCHER_DUMP_STATE_HAVE_CONFIG;
+		cb->args[DISPATCHER_DUMP_ARG_CURRENT_DISPATCHER] = 0;
+		cb->args[DISPATCHER_DUMP_ARG_SUBPART] = 0;
+		cb->args[DISPATCHER_DUMP_ARG_RULE_ENTRY_SUBPART] = 0;
+	}
+
+restart:
+	last = (const struct kz_dispatcher *) cb->args[DISPATCHER_DUMP_ARG_CURRENT_DISPATCHER];
+	list_for_each_entry(i, &cfg->dispatchers.head, list) {
+		/* check if we're continuing the dump from a given entry */
+		if (last != NULL) {
+			if (i == last) {
+				/* ok, this was the last entry we've tried to dump */
+				cb->args[DISPATCHER_DUMP_ARG_CURRENT_DISPATCHER] = 0;
+				/* cb->args[1] is left as found to resume! */
+				last = NULL;
+			} else /* seek over start */
+				continue;
+		}
+
+		if (kznl_build_dispatcher(skb, NETLINK_CB(cb->skb).pid,
+					  cb->nlh->nlmsg_seq, NLM_F_MULTI, i,
+					  &cb->args[DISPATCHER_DUMP_ARG_SUBPART],
+					  &cb->args[DISPATCHER_DUMP_ARG_RULE_ENTRY_SUBPART]) < 0) {
+			/* dispatcher dump failed, try to continue from here next time */
+			cb->args[DISPATCHER_DUMP_ARG_CURRENT_DISPATCHER] = (long) i;
+			/* cb->args[DISPATCHER_DUMP_ARG_SUBPART] was set by the call! */
+			goto out;
+		}
+	}
+
+	if (last != NULL) {
+		/* we've tried to continue an interrupted dump but did not found the
+		 * restart point. cannot do any better but start again. */
+		cb->args[DISPATCHER_DUMP_ARG_CURRENT_DISPATCHER] =
+			cb->args[DISPATCHER_DUMP_ARG_SUBPART] =
+			cb->args[DISPATCHER_DUMP_ARG_RULE_ENTRY_SUBPART] = 0;
+		goto restart;
+	}
+
+	/* done */
+	cb->args[DISPATCHER_DUMP_ARG_STATE] = DISPATCHER_DUMP_STATE_NO_MORE_WORK;
+
+out:
+	rcu_read_unlock();
+	return skb->len;
+}
+
+static int
+kznl_recv_get_dispatcher(struct sk_buff *skb, struct genl_info *info)
+{
+	int res = 0;
+	int ret = 0;
+	int netlink_return = 0;
+	char *dpt_name = NULL;
+	struct kz_dispatcher *dpt;
+	struct sk_buff *nskb = NULL;
+	long dpt_item_idx = 0;
+	long rule_entry_idx = 0;
+
+	/* parse attributes */
+	if (!info->attrs[KZNL_ATTR_DISPATCHER_NAME]) {
+		kz_err("required name attribute missing\n");
+		res = -EINVAL;
+		goto error;
+	}
+
+	res = kznl_parse_name_alloc(info->attrs[KZNL_ATTR_DISPATCHER_NAME], &dpt_name);
+	if (res < 0) {
+		kz_err("failed to parse dispatcher name\n");
+		goto error;
+	}
+
+	rcu_read_lock();
+
+	dpt = kz_dispatcher_lookup_name(rcu_dereference(kz_config_rcu), dpt_name);
+	if (dpt == NULL) {
+		kz_debug("no such dispatcher found; name='%s'\n", dpt_name);
+		res = -ENOENT;
+		goto error_unlock_dpt;
+	}
+
+	/* NOTE: this loops always terminates because one single
+	 * message is guaranteed to fit an NLMSG_GOODSIZE-sized
+	 * buffer. This means that kznl_build_dispatcher() will always
+	 * output at least one netlink message and thus we must
+	 * always call netlink_unicast() on nskb.
+	 */
+	do {
+		kz_debug("dpt_item_idx=%ld, rule_entry_idx=%ld", dpt_item_idx, rule_entry_idx);
+		/* create skb and dump */
+		nskb = genlmsg_new(NLMSG_GOODSIZE, GFP_KERNEL);
+		if (!nskb) {
+			kz_err("failed to allocate reply message\n");
+			res = -ENOMEM;
+			goto error_unlock_dpt;
+		}
+
+		ret = kznl_build_dispatcher(nskb, info->snd_pid,
+					    info->snd_seq, 0,
+					    dpt, &dpt_item_idx, &rule_entry_idx);
+		netlink_return = genlmsg_reply(nskb, info);
+
+	} while ((ret < 0) && (netlink_return >= 0));
+
+	rcu_read_unlock();
+
+	return netlink_return;
+
+error_unlock_dpt:
+	rcu_read_unlock();
+
+	if (dpt_name != NULL)
+		kfree(dpt_name);
+
+error:
+	return res;
+}
+
+static int
+kznl_build_query_resp(struct sk_buff *skb, u_int32_t pid, u_int32_t seq, int flags,
+		      enum kznl_msg_types msg, struct kz_dispatcher *dispatcher,
+		      struct kz_zone *client_zone,
+		      struct kz_zone *server_zone, struct kz_service *service)
+{
+	void *hdr;
+
+	hdr = genlmsg_put(skb, pid, seq, &kznl_family, flags, msg);
+
+	if (dispatcher && kznl_dump_name(skb, KZNL_ATTR_DISPATCHER_NAME, dispatcher->name) < 0)
+		goto nfattr_failure;
+	if (client_zone && kznl_dump_name(skb, KZNL_ATTR_QUERY_REPLY_CLIENT_ZONE, client_zone->name) < 0)
+		goto nfattr_failure;
+	if (server_zone && kznl_dump_name(skb, KZNL_ATTR_QUERY_REPLY_SERVER_ZONE, server_zone->name) < 0)
+		goto nfattr_failure;
+	if (service && kznl_dump_name(skb, KZNL_ATTR_SERVICE_NAME, service->name) < 0)
+		goto nfattr_failure;
+
+	return genlmsg_end(skb, hdr);
+
+nfattr_failure:
+	genlmsg_cancel(skb, hdr);
+	return -1;
+}
+
+#define kznl_query_check_param_existence(PARAM_TYPE, PARAM_NAME) \
+if (!info->attrs[PARAM_TYPE]) { \
+	kz_err("required attribute missing: attr='%s'\n", #PARAM_NAME); \
+	res = -EINVAL; \
+	goto error; \
+}
+
+static int
+kznl_recv_query(struct sk_buff *skb, struct genl_info *info)
+{
+	int res = 0;
+	struct kz_traffic_props traffic_props;
+	union nf_inet_addr src_addr;
+	union nf_inet_addr dst_addr;
+	char ifname[IFNAMSIZ];
+	struct kz_reqids reqids;
+	struct net_device *dev;
+	struct sk_buff *nskb = NULL;
+	struct kz_dispatcher *dispatcher;
+	struct kz_zone *client_zone;
+	struct kz_zone *server_zone;
+	struct kz_service *service;
+
+	kznl_query_check_param_existence(KZNL_ATTR_QUERY_PARAMS, params);
+	kznl_query_check_param_existence(KZNL_ATTR_QUERY_PARAMS_SRC_IP, src_ip);
+	kznl_query_check_param_existence(KZNL_ATTR_QUERY_PARAMS_DST_IP, dst_ip);
+
+	kz_traffic_props_init(&traffic_props);
+	traffic_props.src_addr = &src_addr;
+	traffic_props.dst_addr = &dst_addr;
+
+	/* fill fields */
+	res = kznl_parse_inet_addr(info->attrs[KZNL_ATTR_QUERY_PARAMS_SRC_IP], &src_addr, &traffic_props.l3proto);
+	if (res < 0) {
+		kz_err("failed to parse src ip nested attribute\n");
+		goto error;
+	}
+
+	res = kznl_parse_inet_addr(info->attrs[KZNL_ATTR_QUERY_PARAMS_DST_IP], &dst_addr, &traffic_props.l3proto);
+	if (res < 0) {
+		kz_err("failed to parse src ip nested attribute\n");
+		goto error;
+	}
+
+	res = kznl_parse_query_params(info->attrs[KZNL_ATTR_QUERY_PARAMS], &traffic_props.proto, ifname);
+	if (res < 0) {
+		kz_err("failed to parse query parameters\n");
+		goto error;
+	}
+
+	if (traffic_props.proto == IPPROTO_TCP || traffic_props.proto == IPPROTO_UDP) {
+		kznl_query_check_param_existence(KZNL_ATTR_QUERY_PARAMS_SRC_PORT, src_port);
+		res = kznl_parse_port(info->attrs[KZNL_ATTR_QUERY_PARAMS_SRC_PORT], &traffic_props.src_port);
+		if (res < 0) {
+			kz_err("failed to parse query attribute; attr='src_port'\n");
+			goto error;
+		}
+
+		kznl_query_check_param_existence(KZNL_ATTR_QUERY_PARAMS_DST_PORT, dst_port);
+		res = kznl_parse_port(info->attrs[KZNL_ATTR_QUERY_PARAMS_DST_PORT], &traffic_props.dst_port);
+		if (res < 0) {
+			kz_err("failed to parse query attribute; attr='dst_port'\n");
+			goto error;
+		}
+	}
+
+	if (traffic_props.proto == IPPROTO_ICMP || traffic_props.proto == IPPROTO_ICMPV6) {
+		kznl_query_check_param_existence(KZNL_ATTR_QUERY_PARAMS_PROTO_TYPE, proto_type);
+		res = kznl_parse_proto_type(info->attrs[KZNL_ATTR_QUERY_PARAMS_PROTO_TYPE], traffic_props.proto, &traffic_props.proto_type);
+		if (res < 0) {
+			kz_err("failed to parse query attribute; attr='proto_type'\n");
+			goto error;
+		}
+
+		kznl_query_check_param_existence(KZNL_ATTR_QUERY_PARAMS_PROTO_SUBTYPE, proto_subtype);
+		res = kznl_parse_proto_subtype(info->attrs[KZNL_ATTR_QUERY_PARAMS_PROTO_SUBTYPE], traffic_props.proto, &traffic_props.proto_subtype);
+		if (res < 0) {
+			kz_err("failed to parse query attribute; attr='proto_subtype'\n");
+			goto error;
+		}
+	}
+
+	/* look up interface */
+	dev = dev_get_by_name(&init_net, ifname);
+	if (dev == NULL) {
+		kz_err("failed to look up network device; ifname='%s'\n", ifname);
+		res = -ENOENT;
+		goto error;
+	}
+	traffic_props.iface = dev;
+
+	if (info->attrs[KZNL_ATTR_QUERY_PARAMS_REQID]) {
+		traffic_props.reqids = &reqids;
+		reqids.len = 1;
+		res = kznl_parse_reqid(info->attrs[KZNL_ATTR_QUERY_PARAMS_REQID], &reqids.vec[0]);
+		if (res < 0) {
+			kz_err("failed to parse query attribute\n");
+			goto error;
+		}
+	}
+
+	/* create reply skb */
+	nskb = genlmsg_new(NLMSG_GOODSIZE, GFP_KERNEL);
+	if (!nskb) {
+		kz_err("failed to allocate reply message\n");
+		res = -ENOMEM;
+		goto error_put_dev;
+	}
+
+	rcu_read_lock();
+	/* lookup uses per-cpu data mutating it, we must make sure no interruptions on a CPU */
+	local_bh_disable();
+
+	kz_lookup_session(rcu_dereference(kz_config_rcu),
+			  &traffic_props,
+			  &dispatcher, &client_zone, &server_zone, &service,
+			  0);
+
+	local_bh_enable();
+	rcu_read_unlock();
+
+	if (kznl_build_query_resp(nskb, info->snd_pid,
+				  info->snd_seq, 0,
+				  KZNL_MSG_QUERY_REPLY,
+				  dispatcher, client_zone, server_zone,
+				  service) < 0) {
+		res = -ENOMEM;
+		goto error_put_dev;
+	}
+
+	dev_put(dev);
+	return genlmsg_reply(nskb, info);
+
+error_put_dev:
+	dev_put(dev);
+
+error:
+	nlmsg_free(nskb);
+
+	return res;
+}
+
+static int
+kznl_build_get_version_resp(struct sk_buff *skb, u_int32_t pid, u_int32_t seq, int flags,
+			    enum kznl_msg_types msg)
+{
+	void *hdr;
+
+	hdr = genlmsg_put(skb, pid, seq, &kznl_family, flags, msg);
+	if (!hdr)
+		goto nla_put_failure;
+
+	NLA_PUT_U8(skb, KZNL_ATTR_MAJOR_VERSION, KZ_MAJOR_VERSION);
+	NLA_PUT_U8(skb, KZNL_ATTR_COMPAT_VERSION, KZ_COMPAT_VERSION);
+
+	return genlmsg_end(skb, hdr);
+
+nla_put_failure:
+	genlmsg_cancel(skb, hdr);
+	return -1;
+}
+
+static int
+kznl_recv_get_version(struct sk_buff *skb, struct genl_info *info)
+{
+	int res = 0;
+	struct sk_buff *nskb = NULL;
+
+	/* create skb and dump */
+	nskb = genlmsg_new(NLMSG_GOODSIZE, GFP_KERNEL);
+	if (!nskb) {
+		kz_err("failed to allocate reply message\n");
+		res = -ENOMEM;
+		goto error;
+	}
+
+	if (kznl_build_get_version_resp(nskb, info->snd_pid, info->snd_seq, 0,
+					KZNL_MSG_GET_VERSION) < 0) {
+		res = -ENOMEM;
+		goto error;
+	}
+
+	return genlmsg_reply(nskb, info);
+
+error:
+	nlmsg_free(nskb);
+	return res;
+}
+
+/***********************************************************
+ * Netlink event handler
+ ***********************************************************/
+
+static int
+kznl_netlink_event(struct notifier_block *n, unsigned long event, void *v)
+{
+	struct netlink_notify *notify = v;
+	struct kz_transaction *tr;
+	struct kz_instance *instance;
+
+	if (event == NETLINK_URELEASE &&
+	    notify->protocol == NETLINK_GENERIC &&
+	    notify->pid != 0) {
+		kz_debug("netlink release event received, pid='%d'\n",
+			 notify->pid);
+
+		/* remove pending transaction */
+		LOCK_TRANSACTIONS();
+
+		tr = transaction_lookup(notify->pid);
+		if (tr != NULL) {
+			kz_debug("transaction found, removing\n");
+
+			instance = kz_instance_lookup_id(tr->instance_id);
+			if (instance != NULL)
+				instance->flags &= ~KZF_INSTANCE_TRANS;
+
+			transaction_destroy(tr);
+		}
+
+		/* NOTE: removal of any instance-specific data should be here,
+		 *       as it is the place where the release of netlink event
+		 *       is handled.
+		 *
+		 * It must also be noted that instances are never freed.
+		 */
+		list_for_each_entry(instance, &kz_instances, list) {
+			if (instance->id == 0) {
+				kz_debug("no cleanup for global instance\n");
+			} else {
+				kz_debug("cleaning up instance; id='%d'\n", instance->id);
+			}
+			kz_instance_remove_bind(instance, notify->pid, NULL);
+		}
+
+		UNLOCK_TRANSACTIONS();
+	}
+
+	return NOTIFY_DONE;
+}
+
+/***********************************************************
+ * Initialization
+ ***********************************************************/
+
+static struct genl_ops kznl_ops[] = {
+	{
+		.cmd = KZNL_MSG_GET_VERSION,
+		.doit = kznl_recv_get_version,
+		.flags = GENL_ADMIN_PERM,
+	},
+	{
+		.cmd = KZNL_MSG_START,
+		.doit = kznl_recv_start,
+		.flags = GENL_ADMIN_PERM,
+	},
+	{
+		.cmd = KZNL_MSG_COMMIT,
+		.doit = kznl_recv_commit,
+		.flags = GENL_ADMIN_PERM,
+	},
+	{
+		.cmd = KZNL_MSG_FLUSH_ZONE,
+		.doit = kznl_recv_flush_z,
+		.flags = GENL_ADMIN_PERM,
+	},
+	{
+		.cmd = KZNL_MSG_ADD_ZONE,
+		.doit = kznl_recv_add_zone,
+		.flags = GENL_ADMIN_PERM,
+	},
+	{
+		.cmd = KZNL_MSG_GET_ZONE,
+		.doit = kznl_recv_get_zone,
+		.dumpit = kznl_dump_zones,
+		.flags = GENL_ADMIN_PERM,
+	},
+	{
+		.cmd = KZNL_MSG_FLUSH_SERVICE,
+		.doit = kznl_recv_flush_s,
+		.flags = GENL_ADMIN_PERM,
+	},
+	{
+		.cmd = KZNL_MSG_ADD_SERVICE,
+		.doit = kznl_recv_add_service,
+		.flags = GENL_ADMIN_PERM,
+	},
+	{
+		.cmd = KZNL_MSG_ADD_SERVICE_NAT_SRC,
+		.doit = kznl_recv_add_service_nat_src,
+		.flags = GENL_ADMIN_PERM,
+	},
+	{
+		.cmd = KZNL_MSG_ADD_SERVICE_NAT_DST,
+		.doit = kznl_recv_add_service_nat_dst,
+		.flags = GENL_ADMIN_PERM,
+	},
+	{
+		.cmd = KZNL_MSG_GET_SERVICE,
+		.doit = kznl_recv_get_service,
+		.dumpit = kznl_dump_services,
+		.flags = GENL_ADMIN_PERM,
+	},
+	{
+		.cmd = KZNL_MSG_FLUSH_DISPATCHER,
+		.doit = kznl_recv_flush_d,
+		.flags = GENL_ADMIN_PERM,
+	},
+	{
+		.cmd = KZNL_MSG_ADD_DISPATCHER,
+		.doit = kznl_recv_add_dispatcher,
+		.flags = GENL_ADMIN_PERM,
+	},
+	{
+		.cmd = KZNL_MSG_GET_DISPATCHER,
+		.doit = kznl_recv_get_dispatcher,
+		.dumpit = kznl_dump_dispatchers,
+		.flags = GENL_ADMIN_PERM,
+	},
+	{
+		.cmd = KZNL_MSG_QUERY,
+		.doit = kznl_recv_query,
+		.flags = GENL_ADMIN_PERM,
+	},
+	{
+		.cmd = KZNL_MSG_ADD_RULE,
+		.doit = kznl_recv_add_n_dimension_rule,
+		.flags = GENL_ADMIN_PERM,
+	},
+	{
+		.cmd = KZNL_MSG_ADD_RULE_ENTRY,
+		.doit = kznl_recv_add_n_dimension_rule_entry,
+		.flags = GENL_ADMIN_PERM,
+	},
+	{
+		.cmd = KZNL_MSG_ADD_BIND,
+		.doit = kznl_recv_add_bind,
+		.flags = GENL_ADMIN_PERM,
+	},
+	{
+		.cmd = KZNL_MSG_GET_BIND,
+		.dumpit = kznl_dump_binds,
+		.flags = GENL_ADMIN_PERM,
+	},
+	{
+		.cmd = KZNL_MSG_FLUSH_BIND,
+		.doit = kznl_recv_flush_b,
+		.flags = GENL_ADMIN_PERM,
+	},
+};
+
+static struct notifier_block kz_rtnl_notifier = {
+	.notifier_call	= kznl_netlink_event,
+};
+
+int __init kz_netlink_init(void)
+{
+	int res = -ENOMEM;
+
+	/* initialize data structures */
+	transaction_init();
+
+	/* register netlink notifier and genetlink family */
+	netlink_register_notifier(&kz_rtnl_notifier);
+	res = genl_register_family_with_ops(&kznl_family, kznl_ops, ARRAY_SIZE(kznl_ops));
+	if (res < 0) {
+		kz_err("failed to register generic netlink family\n");
+		goto cleanup_notifier;
+	}
+
+	return res;
+
+cleanup_notifier:
+	netlink_unregister_notifier(&kz_rtnl_notifier);
+
+	return res;
+}
+
+void kz_netlink_cleanup(void)
+{
+	genl_unregister_family(&kznl_family);
+	netlink_unregister_notifier(&kz_rtnl_notifier);
+
+	/* FIXME: free all data structures */
+}
+
+MODULE_ALIAS("net-pf-" __stringify(PF_NETLINK) "-proto-" \
+             __stringify(NETLINK_GENERIC) "-type-" "l2tp");
Index: linux-3.3.8/net/netfilter/kzorp_sockopt.c
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ linux-3.3.8/net/netfilter/kzorp_sockopt.c	2013-11-18 17:12:30.159285808 +0100
@@ -0,0 +1,190 @@
+/*
+ * KZorp getsockopt() interface
+ *
+ * Copyright (C) 2010, BalaBit IT Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#include <net/inet_sock.h>
+#include <linux/ipv6.h>
+#include <net/ipv6.h>
+#include <linux/netfilter.h>
+#include <net/netfilter/nf_conntrack.h>
+#include <linux/netfilter/kzorp.h>
+#include <linux/netfilter/kzorp_sockopt.h>
+#include <net/netfilter/nf_conntrack.h>
+#include <net/netfilter/nf_conntrack_tuple.h>
+#include <net/netfilter/nf_conntrack_core.h>
+#include <linux/export.h>
+#include <net/netfilter/nf_conntrack_zones.h>
+
+static const char *const kz_log_null = "(NULL)";
+
+#define COPY_NAME_TO_USER(dst, field, string)				\
+	if (string != NULL) {						\
+		size_t len = strlen(string) + 1;			\
+		if (copy_to_user(dst + offsetof(struct kz_lookup_result, field), string, len) != 0) { \
+			res = -EFAULT;					\
+			goto error_put_ct;				\
+		}							\
+	}
+
+static int
+kzorp_getsockopt_results(u8 family, struct sock *sk, int optval, void __user *user, int *len)
+{
+	const struct nf_conntrack_tuple_hash *h;
+	struct nf_conntrack_tuple tuple;
+
+	if (sk->sk_protocol != IPPROTO_TCP && sk->sk_protocol != IPPROTO_UDP) {
+		kz_debug("not a TCP or UDP socket; proto='%u'\n", sk->sk_protocol);
+		return -ENOPROTOOPT;
+	}
+
+	switch (family) {
+	case PF_INET:
+		kz_debug("getting results; proto='%u', src='%pI4:%hu', dst='%pI4:%hu'\n", sk->sk_protocol,
+			 &inet_sk(sk)->inet_rcv_saddr, ntohs(inet_sk(sk)->inet_sport), &inet_sk(sk)->inet_daddr, ntohs(inet_sk(sk)->inet_dport));
+		break;
+	case PF_INET6:
+		kz_debug("getting results; proto='%u', src='%pI6:%hu', dst='%pI6:%hu'\n", sk->sk_protocol,
+			 &inet6_sk(sk)->rcv_saddr, ntohs(inet_sk(sk)->inet_sport), &inet6_sk(sk)->daddr, ntohs(inet_sk(sk)->inet_dport));
+		break;
+	default:
+		BUG();
+	}
+
+	if ((unsigned int) *len < sizeof(struct kz_lookup_result)) {
+		kz_debug("buffer size is too small for the result; len='%d', required='%lu'\n", *len, sizeof(struct kz_lookup_result));
+		return -EINVAL;
+	}
+
+	memset(&tuple, 0, sizeof(tuple));
+	switch (family) {
+	case PF_INET:
+		tuple.src.u3.ip = inet_sk(sk)->inet_rcv_saddr;
+		tuple.src.u.tcp.port = inet_sk(sk)->inet_sport;
+		tuple.dst.u3.ip = inet_sk(sk)->inet_daddr;
+		tuple.dst.u.tcp.port = inet_sk(sk)->inet_dport;
+		tuple.src.l3num = AF_INET;
+		tuple.dst.protonum = sk->sk_protocol;
+		break;
+	case PF_INET6:
+		ipv6_addr_copy(&tuple.src.u3.in6, &inet6_sk(sk)->rcv_saddr);
+		tuple.src.u.tcp.port = inet_sk(sk)->inet_sport;
+		ipv6_addr_copy(&tuple.dst.u3.in6, &inet6_sk(sk)->daddr);
+		tuple.dst.u.tcp.port = inet_sk(sk)->inet_dport;
+		tuple.src.l3num = AF_INET6;
+		tuple.dst.protonum = sk->sk_protocol;
+		break;
+	default:
+		BUG();
+	}
+
+	h = nf_conntrack_find_get(sock_net(sk), NF_CT_DEFAULT_ZONE, &tuple);
+	if (h) {
+		struct nf_conn *ct = nf_ct_tuplehash_to_ctrack(h);
+		struct nf_conntrack_kzorp *kzorp = nfct_kz(ct);
+		u_int64_t cookie;
+		int res = 0;
+
+		if (kzorp == NULL) {
+			kz_debug("no kzorp extension structure found\n");
+			res = -ENOENT;
+			goto error_put_ct;
+		}
+
+		rcu_read_lock();
+		{
+			/* we could waste space to store the coolie in kzorp but user is really interested
+			   whether it is the current one, 0 indicates obsolete  */
+			const struct kz_config *cfg = rcu_dereference(kz_config_rcu);
+			cookie = kz_generation_valid(cfg, kzorp->generation) ? cfg->cookie : 0;
+		}
+		rcu_read_unlock();
+
+		kz_debug("found kzorp results; client_zone='%s', server_zone='%s', dispatcher='%s', service='%s'\n",
+			 kzorp->czone ? kzorp->czone->unique_name : kz_log_null,
+			 kzorp->szone ? kzorp->szone->unique_name : kz_log_null,
+			 kzorp->dpt ? kzorp->dpt->name : kz_log_null,
+			 kzorp->svc ? kzorp->svc->name : kz_log_null);
+
+		if (copy_to_user(user, &cookie, sizeof(cookie)) != 0) {
+			res = -EFAULT;
+			goto error_put_ct;
+		}
+
+		if (kzorp->czone)
+			COPY_NAME_TO_USER(user, czone_name, kzorp->czone->unique_name);
+		if (kzorp->szone)
+			COPY_NAME_TO_USER(user, szone_name, kzorp->szone->unique_name);
+		if (kzorp->dpt)
+			COPY_NAME_TO_USER(user, dispatcher_name, kzorp->dpt->name);
+		if (kzorp->svc)
+			COPY_NAME_TO_USER(user, service_name, kzorp->svc->name);
+
+error_put_ct:
+		nf_ct_put(ct);
+
+		return res;
+	}
+
+	kz_debug("conntrack entry not found\n");
+
+	return -ENOENT;
+}
+
+static int
+kzorp_getsockopt_results_v4(struct sock *sk, int optval, void __user *user, int *len)
+{
+	return kzorp_getsockopt_results(PF_INET, sk, optval, user, len);
+}
+
+static int
+kzorp_getsockopt_results_v6(struct sock *sk, int optval, void __user *user, int *len)
+{
+	return kzorp_getsockopt_results(PF_INET6, sk, optval, user, len);
+}
+
+static struct nf_sockopt_ops so_kzorpresult[] = {
+	{
+		.pf		= PF_INET,
+		.get_optmin	= SO_KZORP_RESULT,
+		.get_optmax	= SO_KZORP_RESULT + 1,
+		.get		= &kzorp_getsockopt_results_v4,
+		.owner		= THIS_MODULE,
+	},
+	{
+		.pf		= PF_INET6,
+		.get_optmin	= SO_KZORP_RESULT,
+		.get_optmax	= SO_KZORP_RESULT + 1,
+		.get		= &kzorp_getsockopt_results_v6,
+		.owner		= THIS_MODULE,
+	},
+};
+
+int __init
+kz_sockopt_init(void)
+{
+	int res;
+
+	res = nf_register_sockopt(&so_kzorpresult[0]);
+	if (res < 0)
+		return res;
+
+	res = nf_register_sockopt(&so_kzorpresult[1]);
+	if (res < 0)
+		nf_unregister_sockopt(&so_kzorpresult[0]);
+
+	return res;
+}
+
+void
+kz_sockopt_cleanup(void)
+{
+	nf_unregister_sockopt(&so_kzorpresult[1]);
+	nf_unregister_sockopt(&so_kzorpresult[0]);
+}
Index: linux-3.3.8/net/netfilter/xt_KZORP.c
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ linux-3.3.8/net/netfilter/xt_KZORP.c	2013-11-18 17:12:30.159285808 +0100
@@ -0,0 +1,1416 @@
+/*
+ * KZorp support for Linux/iptables
+ *
+ * Copyright (c) 2011-2011 BalaBit IT Ltd.
+ * Author: Krisztian Kovacs
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/skbuff.h>
+#include <linux/ip.h>
+#include <net/checksum.h>
+#include <net/tcp.h>
+#include <net/udp.h>
+#include <net/icmp.h>
+#include <net/route.h>
+#include <net/flow.h>
+#include <net/dst.h>
+#include <net/inet_sock.h>
+#include <net/if_inet6.h>
+#include <net/addrconf.h>
+#include <net/ip6_checksum.h>
+#include <net/ip6_fib.h>
+#include <net/ip6_route.h>
+#include <net/xfrm.h>
+
+#include <linux/inetdevice.h>
+#include <linux/netfilter.h>
+#include <linux/netfilter/x_tables.h>
+#include <linux/netfilter_ipv4/ip_tables.h>
+#include <linux/netfilter/xt_KZORP.h>
+
+#include <net/netfilter/nf_conntrack.h>
+#include <net/netfilter/nf_conntrack_core.h>
+#include <net/netfilter/nf_nat_protocol.h>
+#include <net/netfilter/nf_nat_core.h>
+#include <net/netfilter/nf_conntrack_acct.h>
+
+#include <net/netfilter/ipv4/nf_defrag_ipv4.h>
+
+#include <linux/netfilter/kzorp.h>
+
+#include <net/netfilter/nf_tproxy_core.h>
+
+#ifdef CONFIG_BRIDGE_NETFILTER
+#include <linux/netfilter_bridge.h>
+#endif
+
+static const char *const kz_log_null = "(NULL)";
+
+static struct kz_zone *
+kz_zone_lookup(const struct kz_config *cfg, __be32 _addr)
+{
+	struct in_addr addr = { _addr };
+	return kz_head_zone_ipv4_lookup(&cfg->zones, &addr);
+}
+
+#define L4PROTOCOL_STRING_SIZE 4 /* "100" plus trailing zero */
+
+/**
+ * l4proto_as_string() - return name of protocol from number
+ * @protocol: protocol number
+ * @buf: temporary buffer to use if no interned string representation is known
+ *
+ * Return a string representation of the protocol number: either the
+ * protocol name for well-known protocols or the number itself
+ * converted to a string.
+ */
+static char *
+l4proto_as_string(u8 protocol, char buf[])
+{
+	switch (protocol) {
+	case IPPROTO_TCP:
+		return "TCP";
+		break;
+	case IPPROTO_UDP:
+		return "UDP";
+		break;
+	case IPPROTO_ICMP:
+		return "ICMP";
+		break;
+	default:
+		snprintf(buf, L4PROTOCOL_STRING_SIZE, "%hhu", protocol);
+		return buf;
+	}
+}
+
+/**
+ * v4_get_instance_bind_address() - look up the matching listener socket of the instance
+ * @dpt: The dispatcher we've found.
+ * @skb: The incoming frame.
+ * @l4proto: L4 protocol ID.
+ * @sport: L4 protocol source port.
+ * @dport: L4 protocol destination port.
+ *
+ * Since more than one bind could be present for an instance, this
+ * function looks up the appropriate bind address and looks up the
+ * listener socket bound to that address.
+ */
+static inline struct sock *
+v4_lookup_instance_bind_address(const struct kz_dispatcher *dpt,
+				const struct sk_buff *skb, u8 l4proto,
+				__be16 sport, __be16 dport)
+{
+	const struct iphdr *iph = ip_hdr(skb);
+	struct sock *sk = NULL;
+	const struct kz_bind const *bind = kz_instance_bind_lookup_v4(dpt->instance, l4proto,
+								      iph->saddr, sport,
+								      iph->daddr, dport);
+	if (bind) {
+		__be16 proxy_port = htons(bind->port);
+		__be32 proxy_addr = bind->addr.in.s_addr;
+
+		sk = nf_tproxy_get_sock_v4(&init_net, l4proto,
+					   iph->saddr, proxy_addr,
+					   sport, proxy_port,
+					   skb->dev, NFT_LOOKUP_LISTENER);
+		if (sk)
+			kz_debug("found instance bind socket; l4proto='%hhu', bind_address='%pI4:%hu'",
+				 l4proto, &proxy_addr, proxy_port);
+	}
+
+	return sk;
+}
+
+static inline struct sock *
+v4_get_socket_to_redirect_to(const struct kz_dispatcher *dpt,
+			     const struct sk_buff *skb, u8 l4proto,
+			     __be16 sport, __be16 dport)
+{
+	const struct iphdr *iph = ip_hdr(skb);
+	const struct net_device *in = skb->dev;
+	struct sock *sk;
+
+	/* lookup established first */
+	sk = nf_tproxy_get_sock_v4(&init_net, iph->protocol, iph->saddr, iph->daddr,
+				   sport, dport, in, NFT_LOOKUP_ESTABLISHED);
+
+	if (sk == NULL || sk->sk_state == TCP_TIME_WAIT)
+	{
+		struct sock *listener_sk = NULL;
+		struct tcphdr _tcp_header;
+		const struct tcphdr *tcp_header = skb_header_pointer(skb, ip_hdrlen(skb), sizeof(_tcp_header), &_tcp_header);
+
+		/* N-dimension dispatchers use the bind addresses registered for the instance */
+		listener_sk = v4_lookup_instance_bind_address(dpt, skb, l4proto, sport, dport);
+		if (listener_sk) {
+			if (sk) {
+				if (sk->sk_state == TCP_TIME_WAIT &&
+				    tcp_header->syn && !tcp_header->rst && !tcp_header->ack && !tcp_header->fin)
+					inet_twsk_deschedule(inet_twsk(sk), &tcp_death_row);
+
+				if (sk->sk_state == TCP_TIME_WAIT)
+					inet_twsk_put(inet_twsk(sk));
+				else
+					sock_put(sk);
+			}
+
+			sk = listener_sk;
+		}
+	} else {
+		/* non-TW established socket */
+		kz_debug("found established socket");
+	}
+
+	return sk;
+}
+
+static inline unsigned int
+redirect_v4(struct sk_buff *skb, u8 l4proto,
+	    __be16 sport, __be16 dport,
+	    const struct kz_dispatcher *dpt,
+	    const struct xt_kzorp_target_info * tgi)
+{
+	unsigned int verdict = NF_DROP;
+	struct sock *sk = NULL;
+	const struct iphdr * const iph = ip_hdr(skb);
+
+	kz_debug("transparent dispatcher, trying to redirect; dpt='%s'\n", dpt->name);
+
+	sk = v4_get_socket_to_redirect_to(dpt, skb, l4proto, sport, dport);
+	if (sk != NULL) {
+		nf_tproxy_assign_sock(skb, sk);
+		skb->mark = (skb->mark & ~tgi->mark_mask) ^ tgi->mark_value;
+
+		kz_debug("transparent proxy session redirected; socket='%p'\n", sk);
+		verdict = NF_ACCEPT;
+	} else {
+		/* FIXME: we've found no socket to divert to,
+		   so we simply drop the packet.  We should
+		   really implement the possibility of
+		   REJECT-ing the packet instead of silently
+		   dropping it.
+		*/
+		kz_debug("socket not found, dropped packet; src='%pI4:%u', dst='%pI4:%u'\n",
+			 &iph->saddr, ntohs(sport), &iph->daddr, ntohs(dport));
+		verdict = NF_DROP;
+	}
+
+	return verdict;
+}
+
+static inline const struct in6_addr *
+tproxy_laddr6(struct sk_buff *skb, const struct in6_addr *daddr)
+{
+	struct inet6_dev *indev;
+	struct inet6_ifaddr *ifa;
+	struct in6_addr *laddr;
+
+	laddr = NULL;
+
+	rcu_read_lock();
+	indev = __in6_dev_get(skb->dev);
+	if (indev)
+		list_for_each_entry(ifa, &indev->addr_list, if_list) {
+			if (ifa->flags & (IFA_F_TENTATIVE | IFA_F_DEPRECATED))
+				continue;
+
+			laddr = &ifa->addr;
+			break;
+		}
+	rcu_read_unlock();
+
+	return laddr ? laddr : daddr;
+}
+
+/**
+ * relookup_time_wait6() - handle IPv6 TCP TIME_WAIT reopen redirections
+ * @skb:	The skb being processed.
+ * @tproto:	Transport protocol.
+ * @thoff:	Transport protocol header offset.
+ * @par:	Iptables target parameters.
+ * @sk:		The TIME_WAIT TCP socket found by the lookup.
+ *
+ * We have to handle SYN packets arriving to TIME_WAIT sockets
+ * differently: instead of reopening the connection we should rather
+ * redirect the new connection to the proxy if there's a listener
+ * socket present.
+ *
+ * relookup_time_wait6() consumes the socket reference passed in.
+ *
+ * Returns the listener socket if there's one, the TIME_WAIT socket if
+ * no such listener is found, or NULL if the TCP header is incomplete.
+ */
+static struct sock *
+relookup_time_wait6(struct sk_buff *skb, int l4proto, int thoff,
+			 const struct in6_addr *proxy_addr, __be16 proxy_port,
+			 struct sock *sk)
+{
+	const struct ipv6hdr *iph = ipv6_hdr(skb);
+	struct tcphdr _hdr, *hp;
+
+	hp = skb_header_pointer(skb, thoff, sizeof(_hdr), &_hdr);
+	if (hp == NULL) {
+		inet_twsk_put(inet_twsk(sk));
+		return NULL;
+	}
+
+	if (hp->syn && !hp->rst && !hp->ack && !hp->fin) {
+		/* SYN to a TIME_WAIT socket, we'd rather redirect it
+		 * to a listener socket if there's one */
+		struct sock *sk2;
+
+		sk2 = nf_tproxy_get_sock_v6(dev_net(skb->dev), l4proto,
+					    &iph->saddr,
+					    tproxy_laddr6(skb, proxy_addr),
+					    hp->source,
+					    proxy_port,
+					    skb->dev, NFT_LOOKUP_LISTENER);
+		if (sk2) {
+			inet_twsk_deschedule(inet_twsk(sk), &tcp_death_row);
+			inet_twsk_put(inet_twsk(sk));
+			sk = sk2;
+		}
+	}
+
+	return sk;
+}
+
+static inline unsigned int
+redirect_v6(struct sk_buff *skb, u8 l4proto,
+	    __be16 sport, __be16 dport,
+	    const struct kz_dispatcher *dpt,
+	    const struct xt_kzorp_target_info * tgi)
+{
+	const struct ipv6hdr * const iph = ipv6_hdr(skb);
+	int thoff;
+	u8 tproto = iph->nexthdr;
+	struct udphdr _hdr, *hp;
+	__be16 proxy_port = 0;
+	const struct in6_addr *proxy_addr = NULL;
+	struct sock *sk = NULL;
+	__be16 frag_offp;
+
+	/* find transport header */
+	thoff = ipv6_skip_exthdr(skb, sizeof(*iph), &tproto, &frag_offp);
+	if (unlikely(thoff < 0)) {
+		kz_debug("unable to find transport header in IPv6 packet, dropped; src='%pI6', dst='%pI6'\n",
+			 &iph->saddr, &iph->daddr);
+		return NF_DROP;
+	}
+
+	hp = skb_header_pointer(skb, thoff, sizeof(_hdr), &_hdr);
+	if (hp == NULL) {
+		kz_debug("unable to grab transport header contents in IPv6 packet, dropping\n");
+		return NF_DROP;
+	}
+
+	/* check if there's an ongoing connection on the packet
+	 * addresses, this happens if the redirect already happened
+	 * and the current packet belongs to an already established
+	 * connection */
+	sk = nf_tproxy_get_sock_v6(dev_net(skb->dev), tproto,
+				   &iph->saddr, &iph->daddr,
+				   hp->source, hp->dest,
+				   skb->dev, NFT_LOOKUP_ESTABLISHED);
+	if (sk == NULL || sk->sk_state == TCP_TIME_WAIT) {
+
+		const struct kz_bind const *bind = kz_instance_bind_lookup_v6(dpt->instance, l4proto,
+									      &iph->saddr, sport,
+									      &iph->daddr, dport);
+		if (bind) {
+			proxy_port = htons(bind->port);
+			proxy_addr = &bind->addr.in6;
+			/* UDP has no TCP_TIME_WAIT state, so we never enter here */
+			if (sk == NULL)
+				/* no there's no established connection, check if
+				 * there's a listener on the redirected addr/port */
+				sk = nf_tproxy_get_sock_v6(dev_net(skb->dev), tproto,
+							   &iph->saddr, proxy_addr,
+							   hp->source, proxy_port,
+							   skb->dev, NFT_LOOKUP_LISTENER);
+			else /* sk->sk_state == TIME_WAIT */
+				/* reopening a TIME_WAIT connection needs special handling */
+				sk = relookup_time_wait6(skb, tproto, thoff, proxy_addr, proxy_port, sk);
+		} else {
+			sk = NULL;
+		}
+	}
+
+	/* NOTE: assign_sock consumes our sk reference */
+	if (sk) {
+		/* This should be in a separate target, but we don't do multiple
+		   targets on the same rule yet */
+		skb->mark = (skb->mark & ~tgi->mark_mask) ^ tgi->mark_value;
+
+		if (proxy_addr) {
+			pr_debug("redirecting: proto %hhu %pI6:%hu -> %pI6:%hu, mark: %x\n",
+				 tproto, &iph->daddr, ntohs(hp->dest),
+				 proxy_addr, ntohs(proxy_port), skb->mark);
+		} else {
+			pr_debug("redirecting: proto %hhu %pI6:%hu -> %pI6:%hu, mark: %x\n",
+				 tproto, &iph->daddr, ntohs(hp->dest),
+				 &inet6_sk(sk)->rcv_saddr, inet_sk(sk)->inet_num, skb->mark);
+		}
+
+		nf_tproxy_assign_sock(skb, sk);
+		return NF_ACCEPT;
+	}
+
+	pr_debug("no socket, dropping: proto %hhu %pI6:%hu -> %pI6:%hu, mark: %x\n",
+		 tproto, &iph->saddr, ntohs(hp->source),
+		 &iph->daddr, ntohs(hp->dest), skb->mark);
+
+	return NF_DROP;
+}
+
+static inline unsigned int
+process_proxy_session(unsigned int hooknum, struct sk_buff *skb, const struct net_device *in,
+		      u8 l3proto, u8 l4proto,
+		      __be16 sport, __be16 dport, const struct kz_dispatcher *dpt,
+		      const struct xt_kzorp_target_info * tgi)
+{
+	unsigned int verdict = NF_DROP;
+
+	if (unlikely((l4proto != IPPROTO_TCP) && (l4proto != IPPROTO_UDP))) {
+		/* This is an internal error: we should never call process_proxy_session() for
+		   non TCP/UDP frames. */
+		char _buf[L4PROTOCOL_STRING_SIZE];
+
+		kz_debug("non TCP or UDP frame, dropping; protocol='%s'\n", l4proto_as_string(l4proto, _buf));
+		return NF_DROP;
+	}
+
+	switch (l3proto) {
+	case NFPROTO_IPV4:
+		verdict = redirect_v4(skb, l4proto, sport, dport, dpt, tgi);
+		break;
+	case NFPROTO_IPV6:
+		verdict = redirect_v6(skb, l4proto, sport, dport, dpt, tgi);
+		break;
+	default:
+		BUG();
+	}
+
+	return verdict;
+}
+
+static inline unsigned int
+process_forwarded_session(unsigned int hooknum, struct sk_buff *skb,
+			  const struct net_device *in, const struct net_device *out,
+			  const struct kz_config *cfg,
+			  u8 l3proto, u8 l4proto,
+			  __be16  sport, __be16 dport,
+			  struct nf_conn * const ct,
+			  const enum ip_conntrack_info ctinfo,
+			  struct kz_zone ** const szone,
+			  struct kz_service *svc)
+{
+	unsigned int verdict = NF_ACCEPT;
+	const struct nf_nat_ipv4_range *map;
+	struct nf_nat_ipv4_range fakemap;
+	__be32 raddr;
+	__be16 rport;
+	const struct list_head *head = NULL;
+
+	/* new IPv4 connections only */
+	if (l3proto == NFPROTO_IPV4 && ct && (ctinfo == IP_CT_NEW) &&
+	    !nf_nat_initialized(ct, HOOK2MANIP(hooknum))) {
+
+		const struct iphdr * const iph = ip_hdr(skb);
+
+		/* destination address:
+		 *   - original destination if the service is transparent
+		 *   - specified destination otherwise */
+		if (svc->flags & KZF_SERVICE_TRANSPARENT) {
+			raddr = ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple.dst.u3.ip;
+			rport = ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple.dst.u.udp.port;
+		} else {
+			raddr = svc->a.fwd.router_dst_addr.ip;
+			rport = htons(svc->a.fwd.router_dst_port);
+		}
+
+		kz_debug("processing forwarded session; remote_address='%pI4:%u'\n", &raddr, ntohs(rport));
+
+		switch (hooknum) {
+		case NF_INET_PRE_ROUTING:
+			/* we apply DNAT rules on PREROUTING */
+			head = &svc->a.fwd.dnat;
+			break;
+		case NF_INET_POST_ROUTING:
+			/* and SNAT rules on POSTROUTING */
+			head = &svc->a.fwd.snat;
+			break;
+		default:
+			verdict = NF_DROP;
+			BUG();
+		}
+
+		map = kz_service_nat_lookup(head, iph->saddr, raddr,
+					sport, rport, l4proto);
+		kz_debug("NAT rule lookup done; map='%p'\n", map);
+
+		if (hooknum == NF_INET_PRE_ROUTING) {
+			if (map == NULL) {
+				if (!(svc->flags & KZF_SERVICE_TRANSPARENT)) {
+					/* PFService with DirectedRouter, we have to DNAT to
+					 * the specified address */
+					fakemap.flags = NF_NAT_RANGE_MAP_IPS | NF_NAT_RANGE_PROTO_SPECIFIED;
+					fakemap.min_ip = fakemap.max_ip = raddr;
+					fakemap.min.udp.port = fakemap.max.udp.port = rport;
+					map = &fakemap;
+					kz_debug("setting up destination NAT for DirectedRouter; new_dst='%pI4:%u'\n",
+						 &raddr, ntohs(rport));
+				}
+			} else {
+				/* DNAT entry with no specified destination port */
+				if (!(map->flags & NF_NAT_RANGE_PROTO_SPECIFIED)) {
+					fakemap.flags = NF_NAT_RANGE_MAP_IPS | NF_NAT_RANGE_PROTO_SPECIFIED;
+					fakemap.min_ip = map->min_ip;
+					fakemap.max_ip = map->max_ip;
+					fakemap.min.udp.port = fakemap.max.udp.port = rport;
+					map = &fakemap;
+				}
+			}
+		}
+
+		if (map != NULL) {
+			struct kz_zone *fzone = NULL;
+
+			/* mapping found */
+			kz_debug("NAT rule found; hooknum='%d', min_ip='%pI4', max_ip='%pI4', min_port='%u', max_port='%u'\n",
+				 hooknum, &map->min_ip, &map->max_ip,
+				 ntohs(map->min.udp.port), ntohs(map->max.udp.port));
+
+			if (hooknum == NF_INET_PRE_ROUTING) {
+				/* XXX: Assumed: map->min_ip == map->max_ip */
+				fzone = kz_zone_lookup(cfg, ntohl(map->min_ip));
+
+				kz_debug("re-lookup zone after NAT; old_zone='%s', new_zone='%s'\n",
+					 *szone ? (*szone)->name : kz_log_null,
+					 fzone ? fzone->name : kz_log_null);
+
+				if (fzone != *szone) {
+					*szone = fzone;
+					if (*szone)
+						*szone = kz_zone_get(*szone);
+				}
+			}
+
+			verdict = nf_nat_setup_info(ct, map, HOOK2MANIP(hooknum));
+		} else {
+			kz_debug("no NAT rule found; hooknum='%d'\n", hooknum);
+
+			/* we have to SNAT the session if the service
+			 * has no FORGE flag */
+			if ((hooknum == NF_INET_POST_ROUTING) &&
+			    !(svc->flags & KZF_SERVICE_FORGE_ADDR)) {
+				struct rtable *rt;
+				struct nf_nat_ipv4_range range;
+				__be32 laddr;
+
+				rt = skb_rtable(skb);
+				laddr = inet_select_addr(out, rt->rt_gateway, RT_SCOPE_UNIVERSE);
+				if (!laddr) {
+					kz_debug("failed to select source address; out_iface='%s'\n",
+						 out ? out->name : kz_log_null);
+					goto done;
+				}
+
+				range.flags = NF_NAT_RANGE_MAP_IPS;
+				range.min_ip = range.max_ip = laddr;
+
+				kz_debug("setting up implicit SNAT as FORGE_ADDR is off; new_src='%pI4'\n", &laddr);
+				verdict = nf_nat_setup_info(ct, &range, HOOK2MANIP(hooknum));
+			}
+		}
+	}
+
+done:
+	kz_debug("verdict='%d'\n", verdict);
+	return verdict;
+}
+
+static inline void
+kz_session_log(const char *msg,
+	       const char *svc_name,
+	       const u8 l3proto, const u8 l4proto,
+	       const struct kz_zone *client_zone, const struct kz_zone *server_zone,
+	       const struct sk_buff *skb,
+	       const __be16 src_port, const __be16 dst_port)
+{
+	const char *client_zone_name = (client_zone && client_zone->name) ? client_zone->name : kz_log_null;
+	const char *server_zone_name = (server_zone && server_zone->name) ? server_zone->name : kz_log_null;
+
+	if (kz_log_ratelimit()) {
+		char _buf[L4PROTOCOL_STRING_SIZE];
+
+		switch (l3proto) {
+		case NFPROTO_IPV4:
+		{
+			const struct iphdr * const iph = ip_hdr(skb);
+			if (svc_name)
+				printk(KERN_INFO "kzorp (svc/%s): %s; service='%s', "
+						 "client_zone='%s', server_zone='%s', "
+						 "client_address='%pI4:%u', "
+						 "server_address='%pI4:%u', protocol='%s'\n",
+						 svc_name, msg, svc_name,
+						 client_zone_name,
+						 server_zone_name,
+						 &iph->saddr, ntohs(src_port),
+						 &iph->daddr, ntohs(dst_port),
+						 l4proto_as_string(l4proto, _buf));
+
+			else
+				printk(KERN_INFO "kzorp: %s; "
+						 "client_zone='%s', server_zone='%s', "
+						 "client_address='%pI4:%u', "
+						 "server_address='%pI4:%u', protocol='%s'\n",
+						 msg,
+						 client_zone_name,
+						 server_zone_name,
+						 &iph->saddr, ntohs(src_port),
+						 &iph->daddr, ntohs(dst_port),
+						 l4proto_as_string(l4proto, _buf));
+		}
+			break;
+		case NFPROTO_IPV6:
+		{
+			const struct ipv6hdr *iph = ipv6_hdr(skb);
+			if (svc_name)
+				printk(KERN_INFO "kzorp (svc/%s): %s; service='%s', "
+						 "client_zone='%s', server_zone='%s', "
+						 "client_address='%pI6:%u', "
+						 "server_address='%pI6:%u', protocol='%s'\n",
+						 svc_name, msg, svc_name,
+						 client_zone_name,
+						 server_zone_name,
+						 &iph->saddr, ntohs(src_port),
+						 &iph->daddr, ntohs(dst_port),
+						 l4proto_as_string(l4proto, _buf));
+			else
+				printk(KERN_INFO "kzorp: %s; "
+						 "client_zone='%s', server_zone='%s', "
+						 "client_address='%pI6:%u', "
+						 "server_address='%pI6:%u', protocol='%s'\n",
+						 msg,
+						 client_zone_name,
+						 server_zone_name,
+						 &iph->saddr, ntohs(src_port),
+						 &iph->daddr, ntohs(dst_port),
+						 l4proto_as_string(l4proto, _buf));
+		}
+			break;
+		default:
+			BUG();
+		}
+	}
+}
+
+/* Send RST reply: copied from net/ipv4/netfilter/ipt_REJECT.c
+ * change: if (ip_route_me_harder(nskb, RTN_UNICAST))
+ * RTN_UNICAST is used instead of RTN_UNSPEC, this is needed
+ * for ip_route_me_harder to set the FLOWI_FLAG_ANYSRC flag.
+ */
+static void
+send_reset_v4(struct sk_buff *oldskb, int hook)
+{
+	struct sk_buff *nskb;
+	const struct iphdr *oiph;
+	struct iphdr *niph;
+	const struct tcphdr *oth;
+	struct tcphdr _otcph, *tcph;
+
+	/* IP header checks: fragment. */
+	if (ip_hdr(oldskb)->frag_off & htons(IP_OFFSET))
+		return;
+
+	oth = skb_header_pointer(oldskb, ip_hdrlen(oldskb),
+				 sizeof(_otcph), &_otcph);
+	if (oth == NULL)
+		return;
+
+	/* No RST for RST. */
+	if (oth->rst)
+		return;
+
+	if (skb_rtable(oldskb)->rt_flags & (RTCF_BROADCAST | RTCF_MULTICAST))
+		return;
+
+	/* Check checksum */
+	if (nf_ip_checksum(oldskb, hook, ip_hdrlen(oldskb), IPPROTO_TCP))
+		return;
+	oiph = ip_hdr(oldskb);
+
+	nskb = alloc_skb(sizeof(struct iphdr) + sizeof(struct tcphdr) +
+			 LL_MAX_HEADER, GFP_ATOMIC);
+	if (!nskb)
+		return;
+
+	skb_reserve(nskb, LL_MAX_HEADER);
+
+	skb_reset_network_header(nskb);
+	niph = (struct iphdr *)skb_put(nskb, sizeof(struct iphdr));
+	niph->version	= 4;
+	niph->ihl	= sizeof(struct iphdr) / 4;
+	niph->tos	= 0;
+	niph->id	= 0;
+	niph->frag_off	= htons(IP_DF);
+	niph->protocol	= IPPROTO_TCP;
+	niph->check	= 0;
+	niph->saddr	= oiph->daddr;
+	niph->daddr	= oiph->saddr;
+
+	tcph = (struct tcphdr *)skb_put(nskb, sizeof(struct tcphdr));
+	memset(tcph, 0, sizeof(*tcph));
+	tcph->source	= oth->dest;
+	tcph->dest	= oth->source;
+	tcph->doff	= sizeof(struct tcphdr) / 4;
+
+	if (oth->ack)
+		tcph->seq = oth->ack_seq;
+	else {
+		tcph->ack_seq = htonl(ntohl(oth->seq) + oth->syn + oth->fin +
+				      oldskb->len - ip_hdrlen(oldskb) -
+				      (oth->doff << 2));
+		tcph->ack = 1;
+	}
+
+	tcph->rst	= 1;
+	tcph->check = ~tcp_v4_check(sizeof(struct tcphdr), niph->saddr,
+				    niph->daddr, 0);
+	nskb->ip_summed = CHECKSUM_PARTIAL;
+	nskb->csum_start = (unsigned char *)tcph - nskb->head;
+	nskb->csum_offset = offsetof(struct tcphdr, check);
+
+	/* ip_route_me_harder expects skb->dst to be set */
+	skb_dst_set_noref(nskb, skb_dst(oldskb));
+
+	nskb->protocol = htons(ETH_P_IP);
+	if (ip_route_me_harder(nskb, RTN_UNICAST))
+		goto free_nskb;
+
+	niph->ttl	= ip4_dst_hoplimit(skb_dst(nskb));
+
+	/* "Never happens" */
+	if (nskb->len > dst_mtu(skb_dst(nskb)))
+		goto free_nskb;
+
+	nf_ct_attach(nskb, oldskb);
+
+	ip_local_out(nskb);
+	return;
+
+ free_nskb:
+	kfree_skb(nskb);
+}
+
+static void
+send_unreach_v4(struct sk_buff *skb_in, unsigned char code)
+{
+	kz_debug("sending ICMP destination unreachable; code='%hhu'\n", code);
+	icmp_send(skb_in, ICMP_DEST_UNREACH, code, 0);
+}
+
+static void
+send_reset_v6(struct net *net, struct sk_buff *oldskb)
+{
+	struct sk_buff *nskb;
+	struct tcphdr otcph, *tcph;
+	unsigned int otcplen, hh_len;
+	int tcphoff, needs_ack;
+	const struct ipv6hdr *oip6h = ipv6_hdr(oldskb);
+	struct ipv6hdr *ip6h;
+#define DEFAULT_TOS_VALUE	0x0U
+	const __u8 tclass = DEFAULT_TOS_VALUE;
+	struct dst_entry *dst = NULL;
+	u8 proto;
+	struct flowi6 fl6;
+	__be16 frag_offp;
+
+	if ((!(ipv6_addr_type(&oip6h->saddr) & IPV6_ADDR_UNICAST)) ||
+	    (!(ipv6_addr_type(&oip6h->daddr) & IPV6_ADDR_UNICAST))) {
+		pr_debug("addr is not unicast.\n");
+		return;
+	}
+
+	proto = oip6h->nexthdr;
+	tcphoff = ipv6_skip_exthdr(oldskb, ((u8*)(oip6h+1) - oldskb->data), &proto, &frag_offp);
+
+	if ((tcphoff < 0) || (tcphoff > oldskb->len)) {
+		pr_debug("Cannot get TCP header.\n");
+		return;
+	}
+
+	otcplen = oldskb->len - tcphoff;
+
+	/* IP header checks: fragment, too short. */
+	if (proto != IPPROTO_TCP || otcplen < sizeof(struct tcphdr)) {
+		pr_debug("proto(%d) != IPPROTO_TCP, "
+			 "or too short. otcplen = %d\n",
+			 proto, otcplen);
+		return;
+	}
+
+	if (skb_copy_bits(oldskb, tcphoff, &otcph, sizeof(struct tcphdr)))
+		BUG();
+
+	/* No RST for RST. */
+	if (otcph.rst) {
+		pr_debug("RST is set\n");
+		return;
+	}
+
+	/* Check checksum. */
+	if (csum_ipv6_magic(&oip6h->saddr, &oip6h->daddr, otcplen, IPPROTO_TCP,
+			    skb_checksum(oldskb, tcphoff, otcplen, 0))) {
+		pr_debug("TCP checksum is invalid\n");
+		return;
+	}
+
+	memset(&fl6, 0, sizeof(fl6));
+	fl6.flowi6_proto = IPPROTO_TCP;
+	ipv6_addr_copy(&fl6.saddr, &oip6h->daddr);
+	ipv6_addr_copy(&fl6.daddr, &oip6h->saddr);
+	fl6.fl6_sport = otcph.dest;
+	fl6.fl6_dport = otcph.source;
+	security_skb_classify_flow(oldskb, flowi6_to_flowi(&fl6));
+	dst = ip6_route_output(net, NULL, &fl6);
+	if (dst == NULL || dst->error) {
+		dst_release(dst);
+		return;
+	}
+	dst = xfrm_lookup(net, dst, flowi6_to_flowi(&fl6), NULL, 0);
+	if (IS_ERR(dst))
+		return;
+
+	hh_len = (dst->dev->hard_header_len + 15)&~15;
+	nskb = alloc_skb(hh_len + 15 + dst->header_len + sizeof(struct ipv6hdr)
+			 + sizeof(struct tcphdr) + dst->trailer_len,
+			 GFP_ATOMIC);
+
+	if (!nskb) {
+		if (net_ratelimit())
+			pr_debug("cannot alloc skb\n");
+		dst_release(dst);
+		return;
+	}
+
+	skb_dst_set(nskb, dst);
+
+	skb_reserve(nskb, hh_len + dst->header_len);
+
+	skb_put(nskb, sizeof(struct ipv6hdr));
+	skb_reset_network_header(nskb);
+	ip6h = ipv6_hdr(nskb);
+	*(__be32 *)ip6h =  htonl(0x60000000 | (tclass << 20));
+	ip6h->hop_limit = ip6_dst_hoplimit(dst);
+	ip6h->nexthdr = IPPROTO_TCP;
+	ipv6_addr_copy(&ip6h->saddr, &oip6h->daddr);
+	ipv6_addr_copy(&ip6h->daddr, &oip6h->saddr);
+
+	tcph = (struct tcphdr *)skb_put(nskb, sizeof(struct tcphdr));
+	/* Truncate to length (no data) */
+	tcph->doff = sizeof(struct tcphdr)/4;
+	tcph->source = otcph.dest;
+	tcph->dest = otcph.source;
+
+	if (otcph.ack) {
+		needs_ack = 0;
+		tcph->seq = otcph.ack_seq;
+		tcph->ack_seq = 0;
+	} else {
+		needs_ack = 1;
+		tcph->ack_seq = htonl(ntohl(otcph.seq) + otcph.syn + otcph.fin
+				      + otcplen - (otcph.doff<<2));
+		tcph->seq = 0;
+	}
+
+	/* Reset flags */
+	((u_int8_t *)tcph)[13] = 0;
+	tcph->rst = 1;
+	tcph->ack = needs_ack;
+	tcph->window = 0;
+	tcph->urg_ptr = 0;
+	tcph->check = 0;
+
+	/* Adjust TCP checksum */
+	tcph->check = csum_ipv6_magic(&ipv6_hdr(nskb)->saddr,
+				      &ipv6_hdr(nskb)->daddr,
+				      sizeof(struct tcphdr), IPPROTO_TCP,
+				      csum_partial(tcph,
+						   sizeof(struct tcphdr), 0));
+
+	nf_ct_attach(nskb, oldskb);
+
+	ip6_local_out(nskb);
+}
+
+static void
+send_unreach_v6(struct net *net, struct sk_buff *skb_in, unsigned char code,
+		unsigned int hooknum)
+{
+	kz_debug("sending ICMPv6 destination unreachable; code='%hhu'\n", code);
+
+	if (hooknum == NF_INET_LOCAL_OUT && skb_in->dev == NULL)
+		skb_in->dev = net->loopback_dev;
+
+	icmpv6_send(skb_in, ICMPV6_DEST_UNREACH, code, 0);
+}
+
+static unsigned int
+process_denied_session(unsigned int hooknum, struct sk_buff *skb,
+		       const struct net_device *in,
+		       u8 l3proto, u8 l4proto,
+		       u16 sport, u16 dport,
+		       const struct nf_conntrack_kzorp *kzorp)
+{
+	struct kz_service *svc = kzorp->svc;
+	struct net *net = dev_net(in);
+
+	if (svc->flags & KZF_SERVICE_LOGGING) {
+		kz_session_log("Rejecting session", svc->name, l3proto, l4proto,
+			       kzorp->czone, kzorp->szone, skb, sport, dport);
+	}
+
+	switch (l3proto) {
+	case NFPROTO_IPV4:
+		switch (svc->a.deny.ipv4_reject_method) {
+		case KZ_SERVICE_DENY_METHOD_V4_DROP:
+			/* do nothing, just drop the packet */
+			break;
+
+		case KZ_SERVICE_DENY_METHOD_V4_TCP_RESET:
+			if (l4proto == IPPROTO_TCP)
+				send_reset_v4(skb, hooknum);
+			break;
+
+		case KZ_SERVICE_DENY_METHOD_ICMP_NET_UNREACHABLE:
+			send_unreach_v4(skb, ICMP_NET_UNREACH);
+			break;
+
+		case KZ_SERVICE_DENY_METHOD_ICMP_HOST_UNREACHABLE:
+			send_unreach_v4(skb, ICMP_HOST_UNREACH);
+			break;
+
+		case KZ_SERVICE_DENY_METHOD_ICMP_PROTO_UNREACHABLE:
+			send_unreach_v4(skb, ICMP_PROT_UNREACH);
+			break;
+
+		case KZ_SERVICE_DENY_METHOD_ICMP_PORT_UNREACHABLE:
+			send_unreach_v4(skb, ICMP_PORT_UNREACH);
+			break;
+
+		case KZ_SERVICE_DENY_METHOD_ICMP_NET_PROHIBITED:
+			send_unreach_v4(skb, ICMP_NET_ANO);
+			break;
+
+		case KZ_SERVICE_DENY_METHOD_ICMP_HOST_PROHIBITED:
+			send_unreach_v4(skb, ICMP_HOST_ANO);
+			break;
+
+		case KZ_SERVICE_DENY_METHOD_ICMP_ADMIN_PROHIBITED:
+			send_unreach_v4(skb, ICMP_PKT_FILTERED);
+			break;
+
+		case KZ_SERVICE_DENY_METHOD_V4_COUNT:
+			BUG();
+			break;
+		}
+		break;
+
+	case NFPROTO_IPV6:
+		switch (svc->a.deny.ipv6_reject_method) {
+		case KZ_SERVICE_DENY_METHOD_V6_DROP:
+			break;
+
+		case KZ_SERVICE_DENY_METHOD_V6_TCP_RESET:
+			if (l4proto == IPPROTO_TCP)
+				send_reset_v6(net, skb);
+			break;
+
+		case KZ_SERVICE_DENY_METHOD_ICMPV6_NO_ROUTE:
+			send_unreach_v6(net, skb, ICMPV6_NOROUTE, hooknum);
+			break;
+
+		case KZ_SERVICE_DENY_METHOD_ICMPV6_ADMIN_PROHIBITED:
+			send_unreach_v6(net, skb, ICMPV6_ADM_PROHIBITED, hooknum);
+			break;
+
+		case KZ_SERVICE_DENY_METHOD_ICMPV6_ADDR_UNREACHABLE:
+			send_unreach_v6(net, skb, ICMPV6_ADDR_UNREACH, hooknum);
+			break;
+
+		case KZ_SERVICE_DENY_METHOD_ICMPV6_PORT_UNREACHABLE:
+			send_unreach_v6(net, skb, ICMPV6_PORT_UNREACH, hooknum);
+			break;
+
+		case KZ_SERVICE_DENY_METHOD_V6_COUNT:
+			BUG();
+			break;
+		}
+		break;
+	}
+
+	return NF_DROP;
+}
+
+/* cast away constness */
+static inline struct nf_conntrack_kzorp *
+patch_kzorp(const struct nf_conntrack_kzorp *kzorp)
+{
+	return (struct nf_conntrack_kzorp *) kzorp;
+}
+
+static bool
+service_assign_session_id(struct sk_buff *skb,
+			  u8 l3proto, u8 l4proto,
+			  u16 sport, u16 dport,
+			  const struct nf_conntrack_kzorp *kzorp)
+{
+	struct kz_service *svc = kzorp->svc;
+
+	if  (svc->flags & KZF_SERVICE_CNT_LOCKED) {
+		kz_session_log("Service is locked during reload, dropping packet",
+			       svc->name, l3proto, l4proto, NULL, NULL, skb, sport, dport);
+		return false;
+	}
+	else
+		patch_kzorp(kzorp)->sid = atomic_add_return(1, &svc->session_cnt);
+
+	return true;
+}
+
+static unsigned int
+kz_prerouting_verdict(struct sk_buff *skb,
+		      const struct net_device *in,
+		      const struct net_device *out,
+		      const struct kz_config *cfg,
+		      const u8 l3proto,
+		      const u8 l4proto,
+		      __be16 sport, __be16 dport,
+		      enum ip_conntrack_info ctinfo,
+		      struct nf_conn *ct,
+		      const struct nf_conntrack_kzorp *kzorp,
+		      const struct xt_kzorp_target_info *tgi)
+{
+	struct kz_dispatcher *dpt = kzorp->dpt;
+	struct kz_service *svc = kzorp->svc;
+	struct kz_zone *czone = kzorp->czone;
+	struct kz_zone *szone = kzorp->szone;
+
+	unsigned int verdict = NF_ACCEPT;
+	/* do session id assignment for new connections */
+	if (ctinfo == IP_CT_NEW) {
+		/* proxy sessions have their session id assigned on prerouting */
+		if ((svc != NULL) && (svc->type == KZ_SERVICE_PROXY) && (kzorp->sid == 0))
+			if (!service_assign_session_id(skb, l3proto, l4proto, sport, dport, kzorp))
+				return NF_DROP;
+	}
+
+	if (dpt != NULL) {
+		if (svc != NULL) {
+			/* process actions:
+			 *   - for forwarded sessions:
+			 *     - DNAT + ACCEPT
+			 *   - for proxied sessions:
+			 *     - transparent: redirect + ACCEPT
+			 *     - non-transparent: ACCEPT
+			 */
+
+			switch (svc->type) {
+			case KZ_SERVICE_PROXY:
+
+				if ((l4proto != IPPROTO_TCP) && (l4proto != IPPROTO_UDP)) {
+					/* this is a config problem: a proxy service configured for
+					 * non TCP/UDP traffic -> we cannot do much but drop the packet */
+					verdict = NF_DROP;
+
+					kz_session_log("Proxy service found for non TCP/UDP traffic, dropping packet",
+						       NULL, l3proto, l4proto, czone, szone, skb, sport, dport);
+				} else
+					verdict = process_proxy_session(NF_INET_PRE_ROUTING, skb, in,
+									l3proto, l4proto, sport, dport,
+									dpt, tgi);
+				break;
+
+			case KZ_SERVICE_FORWARD:
+				verdict = process_forwarded_session(NF_INET_PRE_ROUTING, skb, in, out, cfg,
+								    l3proto, l4proto, sport, dport,
+								    ct, ctinfo, &szone, svc);
+				if ( szone != kzorp->szone) {
+					kz_zone_put(kzorp->szone);
+					patch_kzorp(kzorp)->szone = szone;
+				}
+				break;
+
+			case KZ_SERVICE_DENY:
+				/* do nothing: deny services are processed either on INPUT or FORWARD */
+				break;
+
+			case KZ_SERVICE_INVALID:
+			case KZ_SERVICE_TYPE_COUNT:
+				BUG();
+			}
+		} else {
+			/* no service was found, log and drop packet */
+			if (!czone || !szone) {
+				kz_session_log("Dispatcher found without valid (client zone, server zone, service) triplet; dropping packet",
+					       NULL, l3proto, l4proto, NULL, NULL, skb, sport, dport);
+				} else  {
+				if (kz_log_ratelimit()) {
+					kz_session_log("No applicable service found for this client & server zone, dropping packet",
+						       NULL, l3proto, l4proto, czone, szone, skb, sport, dport);
+				}
+			}
+
+			verdict = NF_DROP;
+		}
+	}
+
+	return verdict;
+}
+
+static unsigned int
+kz_input_newconn_verdict(struct sk_buff *skb,
+			 const struct net_device *in,
+			 u8 l3proto, u8 l4proto,
+			 u16 sport, u16 dport,
+			 struct nf_conn *ct,
+			 const struct nf_conntrack_kzorp *kzorp)
+{
+	unsigned int verdict = NF_ACCEPT;
+	struct kz_service *svc = kzorp->svc;
+
+	if (svc != NULL && svc->type == KZ_SERVICE_DENY) {
+		/* Only deny services are processed on INPUT */
+		verdict = process_denied_session(NF_INET_PRE_ROUTING, skb, in, l3proto, l4proto, sport, dport, kzorp);
+	}
+
+	return verdict;
+}
+
+static unsigned int
+kz_forward_newconn_verdict(struct sk_buff *skb,
+			   const struct net_device *in,
+			   u8 l3proto, u8 l4proto,
+			   u16 sport, u16 dport,
+			   struct nf_conn *ct,
+			   const struct nf_conntrack_kzorp *kzorp)
+{
+	unsigned int verdict = NF_ACCEPT;
+	struct kz_service *svc = kzorp->svc;
+
+	bool new_session = false;
+
+	if (svc != NULL) {
+
+		/* forwarded and denied session have their session id assigned on forward */
+		if (kzorp->sid == 0) {
+			if (!service_assign_session_id(skb, l3proto, l4proto, sport, dport, kzorp))
+				return NF_DROP;
+
+			new_session = true;
+		}
+
+		switch (svc->type) {
+		case KZ_SERVICE_FORWARD:
+			/* log new sessions */
+			if (new_session && kz_log_ratelimit()) {
+				char _buf[L4PROTOCOL_STRING_SIZE];
+
+				switch (l3proto) {
+				case NFPROTO_IPV4:
+				{
+					const struct iphdr * const iph = ip_hdr(skb);
+					printk(KERN_INFO "kzorp (svc/%s:%lu): Starting forwarded session; "
+					       "client_address='%pI4:%u', client_zone='%s', "
+					       "server_address='%pI4:%u', server_zone='%s', "
+					       "protocol='%s'\n",
+					       kzorp->svc->name, kzorp->sid,
+					       &iph->saddr, ntohs(sport),
+					       (kzorp->czone != NULL) ? kzorp->czone->name : kz_log_null,
+					       &iph->daddr, ntohs(dport),
+					       (kzorp->szone != NULL) ? kzorp->szone->name : kz_log_null,
+					       l4proto_as_string(l4proto, _buf));
+				}
+					break;
+				case NFPROTO_IPV6:
+				{
+					const struct ipv6hdr * const iph = ipv6_hdr(skb);
+					printk(KERN_INFO "kzorp (svc/%s:%lu): Starting forwarded session; "
+					       "client_address='%pI6:%u', client_zone='%s', "
+					       "server_address='%pI6:%u', server_zone='%s', "
+					       "protocol='%s'\n",
+					       kzorp->svc->name, kzorp->sid,
+					       &iph->saddr, ntohs(sport),
+					       (kzorp->czone != NULL) ? kzorp->czone->name : kz_log_null,
+					       &iph->daddr, ntohs(dport),
+					       (kzorp->szone != NULL) ? kzorp->szone->name : kz_log_null,
+					       l4proto_as_string(l4proto, _buf));
+				}
+					break;
+				default:
+					BUG();
+				}
+			}
+			break;
+
+		case KZ_SERVICE_DENY:
+			verdict = process_denied_session(NF_INET_FORWARD, skb, in, l3proto, l4proto,
+							 sport, dport, kzorp);
+			break;
+
+		default:
+			/* do nothing */
+			break;
+		}
+	}
+
+	return verdict;
+}
+
+
+static unsigned int
+kz_postrouting_newconn_verdict(struct sk_buff *skb,
+			       const struct net_device *in,
+			       const struct net_device *out,
+			       const struct kz_config *cfg,
+			       u8 l3proto,
+			       u8 l4proto,
+			       u16 sport, u16 dport,
+			       struct nf_conn *ct,
+			       const struct nf_conntrack_kzorp *kzorp,
+			       const struct xt_kzorp_target_info *tgi)
+{
+	struct kz_dispatcher *dpt = kzorp->dpt;
+	struct kz_service *svc = kzorp->svc;
+	struct kz_zone *szone = kzorp->szone;
+
+	/* assign session id and do SNAT on new connections */
+	if ((svc != NULL) && (kzorp->sid == 0))
+		if (!service_assign_session_id(skb, l3proto, l4proto, sport, dport, kzorp))
+			return NF_DROP;
+
+	if (dpt != NULL && svc != NULL) {
+		if (svc->type == KZ_SERVICE_FORWARD)
+			return process_forwarded_session(NF_INET_POST_ROUTING, skb, in, out, cfg,
+							 l3proto, l4proto, sport, dport,
+							 ct, IP_CT_NEW,
+							 &szone, svc);
+	}
+
+	return NF_ACCEPT;
+}
+
+static unsigned int
+kzorp_tg(struct sk_buff *skb, const struct xt_action_param *par)
+{
+	const struct xt_kzorp_target_info * const tgi = par->targinfo;
+	const struct net_device * const in = par->in;
+	const struct net_device * const out = par->out;
+
+	unsigned int verdict = NF_ACCEPT;
+	enum ip_conntrack_info ctinfo;
+	struct nf_conn *ct;
+	const struct nf_conntrack_kzorp *kzorp;
+	struct nf_conntrack_kzorp local_kzorp;
+	const struct kz_config *cfg = NULL;
+	u_int8_t l4proto = 0;
+	struct {
+		u16 src;
+		u16 dst;
+	} __attribute__((packed)) *ports, _ports = { .src = 0, .dst = 0, };
+
+	ports = &_ports;
+
+	switch (par->family) {
+	case NFPROTO_IPV4:
+	{
+		const struct iphdr * const iph = ip_hdr(skb);
+
+		l4proto = iph->protocol;
+
+		if ((l4proto == IPPROTO_TCP) || (l4proto == IPPROTO_UDP)) {
+			ports = skb_header_pointer(skb, ip_hdrlen(skb), sizeof(_ports), &_ports);
+			if (unlikely(ports == NULL)) {
+				/* unexpected ill case */
+				kz_debug("failed to get ports, dropped packet; src='%pI4', dst='%pI4'\n",
+					 &iph->saddr, &iph->daddr);
+				return NF_DROP;
+			}
+		}
+
+		kz_debug("kzorp hook processing packet: hook='%u', protocol='%u', src='%pI4:%u', dst='%pI4:%u'\n",
+			 par->hooknum, l4proto, &iph->saddr, ntohs(ports->src), &iph->daddr, ntohs(ports->dst));
+	}
+		break;
+	case NFPROTO_IPV6:
+	{
+		const struct ipv6hdr * const iph = ipv6_hdr(skb);
+		int thoff;
+		u8 tproto = iph->nexthdr;
+		__be16 frag_offp;
+
+		/* find transport header */
+		thoff = ipv6_skip_exthdr(skb, sizeof(*iph), &tproto, &frag_offp);
+		if (unlikely(thoff < 0)) {
+			kz_debug("unable to find transport header in IPv6 packet, dropped; src='%pI6', dst='%pI6'\n",
+				 &iph->saddr, &iph->daddr);
+			return NF_DROP;
+		}
+
+		l4proto = tproto;
+
+		if ((l4proto == IPPROTO_TCP) || (l4proto == IPPROTO_UDP)) {
+			/* get info from transport header */
+			ports = skb_header_pointer(skb, thoff, sizeof(_ports), &_ports);
+			if (unlikely(ports == NULL)) {
+				kz_debug("failed to get ports, dropped packet; src='%pI6', dst='%pI6'\n",
+					 &iph->saddr, &iph->daddr);
+				return NF_DROP;
+			}
+		}
+
+		kz_debug("kzorp hook processing packet: hook='%u', protocol='%u', src='%pI6:%u', dst='%pI6:%u'\n",
+			 par->hooknum, l4proto, &iph->saddr, ntohs(ports->src), &iph->daddr, ntohs(ports->dst));
+	}
+		break;
+	default:
+		BUG();
+	}
+
+	ct = nf_ct_get(skb, &ctinfo);
+	/* no conntrack or this is a reply packet: we simply accept it
+	   we don't want to mark the reply packages with tproxy mark
+	   in iptables there could be a condition so reply does not get here
+	   at all -- for that here a warning could be emitted, preferably
+	   only once.  but that means slightly worse performance, so
+	   the former bahavior is kept.*/
+	if (ct == NULL || ctinfo >= IP_CT_IS_REPLY)
+		return NF_ACCEPT;
+
+	rcu_read_lock();
+	kzorp = nfct_kzorp_cached_lookup_rcu(ct, ctinfo, skb, in, par->family, &cfg);
+
+	if (kzorp == NULL)
+	{
+		kzorp = &local_kzorp;
+		memset(&local_kzorp, 0, sizeof(local_kzorp));
+		nfct_kzorp_lookup_rcu(&local_kzorp, ctinfo, skb, in, par->family, &cfg);
+	}
+
+	kz_debug("lookup data for kzorp hook; dpt='%s', client_zone='%s', server_zone='%s', svc='%s'\n",
+		 kzorp->dpt ? kzorp->dpt->name : kz_log_null,
+		 kzorp->czone ? kzorp->czone->name : kz_log_null,
+		 kzorp->szone ? kzorp->szone->name : kz_log_null,
+		 kzorp->svc ? kzorp->svc->name : kz_log_null);
+
+	switch (par->hooknum)
+	{
+	case NF_INET_PRE_ROUTING:
+		verdict = kz_prerouting_verdict(skb, in, out, cfg,
+						par->family, l4proto,
+						ports->src, ports->dst,
+						ctinfo, ct, kzorp, tgi);
+		break;
+	case NF_INET_LOCAL_IN:
+		if (ctinfo == IP_CT_NEW)
+			verdict = kz_input_newconn_verdict(skb, in, par->family, l4proto,
+							   ports->src, ports->dst,
+							   ct, kzorp);
+		break;
+	case NF_INET_FORWARD:
+		if (ctinfo == IP_CT_NEW)
+			verdict = kz_forward_newconn_verdict(skb, in, par->family, l4proto,
+							     ports->src, ports->dst,
+							     ct, kzorp);
+		break;
+	case NF_INET_POST_ROUTING:
+		if (ctinfo == IP_CT_NEW)
+			verdict = kz_postrouting_newconn_verdict(skb, in, out, cfg,
+								 par->family, l4proto,
+								 ports->src, ports->dst,
+								 ct, kzorp, tgi);
+		break;
+	default:
+		BUG();
+		break;
+	}
+
+	if (kzorp == &local_kzorp)
+		kz_destroy_kzorp(&local_kzorp);
+	rcu_read_unlock();
+
+	return verdict;
+}
+
+
+static int kzorp_tg_check(const struct xt_tgchk_param *par)
+{
+	const struct xt_kzorp_target_info * const tgi = par->targinfo;
+
+	/* flags can be used in the future to support extension vithout versioning */
+	if (tgi->flags != 0)
+		return -EINVAL;
+
+/* it would be better to check for -p (TCP | UDP)
+   but that switch only supports a single protocol
+
+   we accept everything here until a more suitable check emerges
+*/
+	return 0;
+}
+
+static struct xt_target kzorp_tg_reg[] __read_mostly = {
+	{
+		.name		= "KZORP",
+		.family		= AF_INET,
+		.table		= "mangle",
+		.target		= kzorp_tg,
+		.targetsize	= sizeof(struct xt_kzorp_target_info),
+		.checkentry	= kzorp_tg_check,
+		.hooks		= (1 << NF_INET_PRE_ROUTING) |
+				  (1 << NF_INET_LOCAL_IN) |
+				  (1 << NF_INET_FORWARD) |
+				  (1 << NF_INET_POST_ROUTING),
+		.me		= THIS_MODULE,
+	},
+	{
+		.name		= "KZORP",
+		.family		= AF_INET6,
+		.table		= "mangle",
+		.target		= kzorp_tg,
+		.targetsize	= sizeof(struct xt_kzorp_target_info),
+		.checkentry	= kzorp_tg_check,
+		.hooks		= (1 << NF_INET_PRE_ROUTING) |
+				  (1 << NF_INET_LOCAL_IN) |
+				  (1 << NF_INET_FORWARD) |
+				  (1 << NF_INET_POST_ROUTING),
+		.me		= THIS_MODULE,
+	},
+};
+
+static int __init kzorp_tg_init(void)
+{
+	nf_defrag_ipv4_enable();
+	return xt_register_targets(kzorp_tg_reg, ARRAY_SIZE(kzorp_tg_reg));
+}
+
+static void __exit kzorp_tg_exit(void)
+{
+	xt_unregister_targets(kzorp_tg_reg, ARRAY_SIZE(kzorp_tg_reg));
+}
+
+module_init(kzorp_tg_init);
+module_exit(kzorp_tg_exit);
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Krisztian Kovacs <hidden@balabit.com>");
+MODULE_DESCRIPTION("Netfilter KZorp target module.");
+MODULE_ALIAS("ipt_KZORP");
+MODULE_ALIAS("ip6t_KZORP");
Index: linux-3.3.8/include/net/netfilter/nf_conntrack_extend.h
===================================================================
--- linux-3.3.8.orig/include/net/netfilter/nf_conntrack_extend.h	2012-06-01 09:16:13.000000000 +0200
+++ linux-3.3.8/include/net/netfilter/nf_conntrack_extend.h	2013-11-18 17:12:30.159285808 +0100
@@ -20,7 +20,8 @@
 #ifdef CONFIG_NF_CONNTRACK_TIMESTAMP
 	NF_CT_EXT_TSTAMP,
 #endif
-	NF_CT_EXT_NUM,
+	NF_CT_EXT_KZ,
+	NF_CT_EXT_NUM
 };
 
 #define NF_CT_EXT_HELPER_TYPE struct nf_conn_help
@@ -29,6 +30,7 @@
 #define NF_CT_EXT_ECACHE_TYPE struct nf_conntrack_ecache
 #define NF_CT_EXT_ZONE_TYPE struct nf_conntrack_zone
 #define NF_CT_EXT_TSTAMP_TYPE struct nf_conn_tstamp
+#define NF_CT_EXT_KZ_TYPE struct nf_conntrack_kzorp
 
 /* Extensions: optional stuff which isn't permanently in struct. */
 struct nf_ct_ext {
Index: linux-3.3.8/net/netfilter/xt_service.c
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ linux-3.3.8/net/netfilter/xt_service.c	2013-11-18 17:12:30.159285808 +0100
@@ -0,0 +1,170 @@
+/*
+ * KZorp `service' match
+ *
+ * Copyright (C) 2006-2011, BalaBit IT Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/skbuff.h>
+
+#include <linux/netfilter/x_tables.h>
+#include <linux/netfilter/xt_service.h>
+#include <linux/netfilter/kzorp.h>
+
+static bool
+service_mt(const struct sk_buff *skb, struct xt_action_param *par)
+{
+	struct ipt_service_info *info = (struct ipt_service_info *) par->matchinfo;
+	enum ip_conntrack_info ctinfo;
+	struct nf_conn *ct;
+	const struct kz_service *s_svc, *p_svc;
+	const struct nf_conntrack_kzorp *kzorp;
+	struct nf_conntrack_kzorp local_kzorp;
+	const struct kz_config *cfg = NULL;
+	bool res;
+
+	/* NOTE: unlike previous version, we provide match even for invalid and --notrack packets */
+
+	rcu_read_lock();
+	ct = nf_ct_get((struct sk_buff *)skb, &ctinfo);
+	if (ct == NULL) /* we're really only interested if REPLY or not... */
+		ctinfo = IP_CT_NEW;
+	kzorp = ct ? nfct_kzorp_cached_lookup_rcu(ct, ctinfo, skb, par->in, par->family, &cfg) : NULL;
+
+	if (kzorp == NULL)
+	{
+		kz_debug("cannot add kzorp extension, doing local lookup\n");
+		kzorp = &local_kzorp;
+		memset(&local_kzorp, 0, sizeof(local_kzorp));
+		nfct_kzorp_lookup_rcu(&local_kzorp, ctinfo, skb, par->in, par->family, &cfg);
+	}
+
+	if ((p_svc = kzorp->svc) == NULL) {
+		/* no service for this packet => no match */
+		rcu_read_unlock();
+		goto ret_false;
+	}
+
+	if (info->name_match == IPT_SERVICE_NAME_MATCH) {
+		/* check cached service id validity */
+		if (unlikely(!kz_generation_valid(cfg, info->generation))) {
+			kz_debug("looking up service id; name='%s'\n", info->name);
+			/* id invalid, try to look up again */
+			info->generation = kz_generation_get(cfg);
+			s_svc = kz_service_lookup_name(cfg, info->name);
+			if (s_svc != NULL)
+				info->service_id = s_svc->id;
+			else
+				info->service_id = 0;
+
+			kz_debug("lookup done; id='%u'\n", info->service_id);
+		}
+	}
+	rcu_read_unlock();
+
+	kz_debug("service lookup done; type='%d', id='%u'\n", p_svc->type, p_svc->id);
+
+	switch (info->type) {
+	case IPT_SERVICE_TYPE_PROXY:
+		if (p_svc->type != KZ_SERVICE_PROXY)
+			goto ret_false;
+		break;
+	case IPT_SERVICE_TYPE_FORWARD:
+		if (p_svc->type != KZ_SERVICE_FORWARD)
+			goto ret_false;
+		break;
+	default:
+		/* since info->type has been range-checked in
+		 * checkentry() default is equivalent to
+		 * IPT_SERVICE_TYPE_ANY */
+		break;
+	}
+
+	switch (info->name_match) {
+	case IPT_SERVICE_NAME_MATCH:
+		return (p_svc->id == info->service_id);
+		break;
+	case IPT_SERVICE_NAME_WILDCARD:
+	default:
+		goto ret_true;
+	}
+ret_false:
+	res = false;
+	goto done;
+ret_true:
+	res = true;
+done:
+	if (kzorp == &local_kzorp)
+		kz_destroy_kzorp(&local_kzorp);
+	return res;
+}
+
+static int
+service_mt_checkentry(const struct xt_mtchk_param *par)
+{
+	struct ipt_service_info *info = (struct ipt_service_info *) par->matchinfo;
+
+	info->name[IPT_SERVICE_NAME_LENGTH] = 0;
+
+	if ((info->name_match == IPT_SERVICE_NAME_MATCH) &&
+	    (info->name[0] == '\0'))
+		return -EINVAL;
+
+	if ((info->type == IPT_SERVICE_TYPE_ANY) &&
+	    (info->name_match == IPT_SERVICE_NAME_ANY))
+		return -EINVAL;
+
+	if (info->type > IPT_SERVICE_TYPE_FORWARD)
+		return -EINVAL;
+
+	if (info->name_match > IPT_SERVICE_NAME_MATCH)
+		return -EINVAL;
+
+	info->generation = -1;
+	info->service_id = 0;
+
+	return 0;
+}
+
+static struct xt_match service_match[] = {
+	{
+		.family		= NFPROTO_IPV4,
+		.name		= "service",
+		.match		= service_mt,
+		.matchsize	= sizeof(struct ipt_service_info),
+		.checkentry	= service_mt_checkentry,
+		.me		= THIS_MODULE,
+	},
+	{
+		.family		= NFPROTO_IPV6,
+		.name		= "service",
+		.match		= service_mt,
+		.matchsize	= sizeof(struct ipt_service_info),
+		.checkentry	= service_mt_checkentry,
+		.me		= THIS_MODULE,
+	},
+};
+
+static int __init service_mt_init(void)
+{
+	return xt_register_matches(service_match, ARRAY_SIZE(service_match));
+}
+
+static void __exit service_mt_exit(void)
+{
+	xt_unregister_matches(service_match, ARRAY_SIZE(service_match));
+}
+
+MODULE_AUTHOR("Krisztian Kovacs <hidden@balabit.hu>");
+MODULE_DESCRIPTION("kzorp service match");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("ipt_service");
+MODULE_ALIAS("ip6t_service");
+
+module_init(service_mt_init);
+module_exit(service_mt_exit);
Index: linux-3.3.8/include/linux/netfilter/xt_service.h
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ linux-3.3.8/include/linux/netfilter/xt_service.h	2013-11-18 17:12:30.159285808 +0100
@@ -0,0 +1,27 @@
+#ifndef _XT_SERVICE_H
+#define _XT_SERVICE_H
+
+enum {
+	IPT_SERVICE_TYPE_ANY = 0,
+	IPT_SERVICE_TYPE_PROXY,
+	IPT_SERVICE_TYPE_FORWARD,
+};
+
+enum {
+	IPT_SERVICE_NAME_ANY = 0,
+	IPT_SERVICE_NAME_WILDCARD,
+	IPT_SERVICE_NAME_MATCH,
+};
+
+#define IPT_SERVICE_NAME_LENGTH 117
+
+struct ipt_service_info {
+	u_int8_t type;
+	u_int8_t name_match;
+	unsigned char name[IPT_SERVICE_NAME_LENGTH + 1];
+
+	unsigned int generation;
+	unsigned int service_id;
+};
+
+#endif
Index: linux-3.3.8/include/linux/netfilter/xt_zone.h
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ linux-3.3.8/include/linux/netfilter/xt_zone.h	2013-11-18 17:22:23.457872951 +0100
@@ -0,0 +1,25 @@
+#ifndef _XT_ZONE_H
+#define _XT_ZONE_H
+
+/* flags */
+enum {
+	IPT_ZONE_SRC = 1,
+	IPT_ZONE_CHILDREN = 2,
+	IPT_ZONE_UMBRELLA = 4,
+};
+
+#define IPT_ZONE_NAME_LENGTH 126
+#define IPT_ZONE_NAME_COUNT 32
+
+struct ipt_zone_info {
+	u_int8_t flags;
+	unsigned char name[IPT_ZONE_NAME_LENGTH + 1];
+};
+
+struct ipt_zone_info_v1 {
+	u_int8_t flags;
+	u_int8_t count;
+	unsigned char names[IPT_ZONE_NAME_COUNT][IPT_ZONE_NAME_LENGTH + 1];
+};
+
+#endif
Index: linux-3.3.8/net/netfilter/xt_zone.c
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ linux-3.3.8/net/netfilter/xt_zone.c	2013-11-18 17:21:19.732736548 +0100
@@ -0,0 +1,138 @@
+/*
+ * KZorp `zone' match
+ *
+ * Copyright (C) 2006-2011, BalaBit IT Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+#include <linux/module.h>
+#include <linux/skbuff.h>
+#include <linux/netdevice.h>
+
+#include <linux/netfilter/x_tables.h>
+#include <linux/netfilter/xt_zone.h>
+#include <linux/netfilter/kzorp.h>
+
+static bool
+zone_mt_v1_eval(const struct sk_buff *skb, const struct ipt_zone_info_v1 *info, const struct xt_action_param *par)
+{
+	enum ip_conntrack_info ctinfo;
+	struct nf_conn *ct;
+	struct kz_zone *zone;
+	const struct nf_conntrack_kzorp *kzorp;
+	int reply;
+	struct nf_conntrack_kzorp local_kzorp;
+	bool res;
+
+	rcu_read_lock();
+	ct = nf_ct_get((struct sk_buff *)skb, &ctinfo);
+	if (ct == NULL) /* we're really only interested if REPLY or not... */
+		ctinfo = IP_CT_NEW;
+	kzorp = ct ? nfct_kzorp_cached_lookup_rcu(ct, ctinfo, skb, par->in, par->family, NULL) : NULL;
+
+	if (kzorp == NULL)
+	{
+		kzorp = &local_kzorp;
+		memset(&local_kzorp, 0, sizeof(local_kzorp));
+		nfct_kzorp_lookup_rcu(&local_kzorp, ctinfo, skb, par->in, par->family, NULL);
+	}
+	rcu_read_unlock();
+
+	reply = ctinfo >= IP_CT_IS_REPLY;
+	if (info->flags & IPT_ZONE_SRC)
+		zone = reply ? kzorp->szone : kzorp->czone;
+	else
+		zone = reply ? kzorp->czone : kzorp->szone;
+
+	while (zone != NULL) {
+		int i;
+
+		for (i = 0; i != info->count; ++i)
+			if (strcmp(zone->name, info->names[i]) == 0)
+				goto ret_true;
+
+		if (info->flags & IPT_ZONE_CHILDREN)
+			zone = zone->admin_parent;
+		else
+			zone = NULL;
+	}
+
+/* ret_false: */
+	res = false;
+	goto done;
+ret_true:
+	res = true;
+done:
+	if (kzorp == &local_kzorp)
+		kz_destroy_kzorp(&local_kzorp);
+	return res;
+}
+
+static bool
+zone_mt_v1(const struct sk_buff *skb, struct xt_action_param *par)
+{
+	return zone_mt_v1_eval(skb, (const struct ipt_zone_info_v1 *) par->matchinfo, par);
+}
+
+static bool
+zone_mt_v0(const struct sk_buff *skb, struct xt_action_param *par)
+{
+	const struct ipt_zone_info *oldinfo = (const struct ipt_zone_info *) par->matchinfo;
+	/* would be ipt_zone_info_v1 directly, but that may exceed stack limit; we only need 1 entry*/
+	unsigned char buf[16 + offsetof(struct ipt_zone_info_v1, names) + sizeof(oldinfo->name)];
+	struct ipt_zone_info_v1 *info = (struct ipt_zone_info_v1 *) &buf[0];
+
+	info->flags = oldinfo->flags;
+	info->count = 1;
+	memcpy(info->names[0], oldinfo->name, sizeof(info->names[0]));
+
+	return zone_mt_v1_eval(skb, info, par);
+}
+
+static struct xt_match xt_zone_match[] __read_mostly = {
+	{
+		.name		= "zone",
+		.family		= NFPROTO_IPV4,
+		.match		= zone_mt_v0,
+		.matchsize	= sizeof(struct ipt_zone_info),
+		.me		= THIS_MODULE,
+	},
+	{
+		.name		= "zone",
+		.revision	= 1,
+		.family		= NFPROTO_IPV4,
+		.match		= zone_mt_v1,
+		.matchsize	= sizeof(struct ipt_zone_info_v1),
+		.me		= THIS_MODULE,
+	},
+	{
+		.name		= "zone",
+		.revision	= 1,
+		.family		= NFPROTO_IPV6,
+		.match		= zone_mt_v1,
+		.matchsize	= sizeof(struct ipt_zone_info_v1),
+		.me		= THIS_MODULE,
+	},
+};
+
+static int __init zone_mt_init(void)
+{
+	return xt_register_matches(xt_zone_match, ARRAY_SIZE(xt_zone_match));
+}
+
+static void __exit zone_mt_exit(void)
+{
+	xt_unregister_matches(xt_zone_match, ARRAY_SIZE(xt_zone_match));
+}
+
+MODULE_AUTHOR("Krisztian Kovacs <hidden@balabit.hu>");
+MODULE_DESCRIPTION("kzorp zone match");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("ipt_zone");
+MODULE_ALIAS("ip6t_zone");
+
+module_init(zone_mt_init);
+module_exit(zone_mt_exit);
